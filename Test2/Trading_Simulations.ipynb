{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carresl/trade-ratings/blob/main/Trading_Simulations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-6IeV8sFAPH"
      },
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjAhmGPTQmtf",
        "outputId": "f1c8c8d4-a408-4132-95a6-9ce0d50de3db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ta in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ta) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from ta) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install ta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWZJUELGKycE",
        "outputId": "9feda7ae-9457-4b21-8ec1-ce09a2d1b82e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.65)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.8)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.18.1)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.4)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.11.4)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (5.29.5)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (4.14.1)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance) (2025.6.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2.4.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade yfinance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7mlZO9CIFCsw"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "from google.colab import files\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import datetime\n",
        "import pytz\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import numpy as np\n",
        "from ta.momentum import StochRSIIndicator as stoch_rsi\n",
        "from ta.momentum import RSIIndicator as rsi\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from numpy.lib.stride_tricks import sliding_window_view\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from numpy.lib.stride_tricks import sliding_window_view\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "# tf libraries\n",
        "from tensorflow.keras.layers import Dense, Concatenate, LSTM, Input, Embedding, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.initializers import HeNormal\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.losses import mean_squared_error as mse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nylg4V5CYIJ7"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMPplp5OSRY8"
      },
      "source": [
        "### Ticker list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QRyzTMBWSTYX"
      },
      "outputs": [],
      "source": [
        "# 1) Choose which ticker file to read\n",
        "ticker_file = 'NASDAQ100_2024.csv'\n",
        "# 2) Choose which ticker list to use\n",
        "ticker_list = 'Holding Ticker'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n4u86ANaMCK"
      },
      "source": [
        "### Simulation parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZRSoW-EwaORE"
      },
      "outputs": [],
      "source": [
        "# 1) Choose the length of the move which we want to predict (in trading days)\n",
        "resp_length = 45\n",
        "# 2) Choose the first date of the simulation\n",
        "sim_start = datetime.date(2024, 1, 1)\n",
        "# 3) Set the number of epochs\n",
        "epochs = 200\n",
        "# 4) Set the batch size\n",
        "batches = 64\n",
        "# 5) Set the regularization lambda value\n",
        "reg = 0.00005\n",
        "# 6) Set the patience for Early Stopping\n",
        "patience = 5\n",
        "# 7) Choose how often you want the model to be retrained in the simulation (in\n",
        "#    number of resp_length periods), set to 0 to only train once\n",
        "retrain_frequency = resp_length * 999999\n",
        "# 8) Set the starting capital for the simulaiton\n",
        "nav = 1_000_000\n",
        "# 9) Specify the risk free asset\n",
        "risk_free_asset = 'SPY'\n",
        "# 10) Specify the number of simulations to run\n",
        "num_sims = 10\n",
        "# 11) Rating cutoff (min rating needed)\n",
        "SR = 1\n",
        "# 12) Long short or long only\n",
        "long_short = False\n",
        "# 13) Choose number of daily candles\n",
        "num_day_candles = 200"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyONY-APANSf"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyvCyZ-LARiN"
      },
      "source": [
        "### Get ticker list from GCloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qnzBHnLBAbEV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "836e53d8-7969-4b16-8d45-8c42900104cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WARNING: gsutil rsync uses hashes when modification time is not available at\n",
            "both the source and destination. Your crcmod installation isn't using the\n",
            "module's C extension, so checksumming will run very slowly. If this is your\n",
            "first rsync since updating gsutil, this rsync can take significantly longer than\n",
            "usual. For help installing the extension, please see \"gsutil help crcmod\".\n",
            "\n",
            "Building synchronization state...\n",
            "Starting synchronization...\n"
          ]
        }
      ],
      "source": [
        "# authenticate user\n",
        "auth.authenticate_user()\n",
        "\n",
        "# command to copy the data from GCloud\n",
        "!gsutil -m rsync -r gs://first-aaai-data-bucket/V2_ticker_lists/ /content/\n",
        "\n",
        "# list of tickers\n",
        "ai90 = list(set(list(pd.read_csv(ticker_file)[ticker_list])))\n",
        "ai90 = [a for a in ai90 if isinstance(a, str)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEpwWyAUAWv3"
      },
      "source": [
        "### Get the chart data from YFinance\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# output the ticker list\n",
        "print('Tickers being traded:')\n",
        "print('')\n",
        "for i, ticker in enumerate(ai90):\n",
        "    print(f'{i+1}. {ticker}')"
      ],
      "metadata": {
        "id": "8IcCUy8yVqzE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cdc05ab-dcb3-4efd-96c1-8e414ca08f41"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tickers being traded:\n",
            "\n",
            "1. TEAM \n",
            "2. CTSH \n",
            "3. INTC \n",
            "4. GOOG \n",
            "5. CCEP \n",
            "6. COST \n",
            "7. KLAC \n",
            "8. VRSK \n",
            "9. AMAT \n",
            "10. ZS \n",
            "11. PANW \n",
            "12. ON \n",
            "13. MELI \n",
            "14. WDAY \n",
            "15. AMZN \n",
            "16. VRTX \n",
            "17. EA \n",
            "18. MDB \n",
            "19. QCOM \n",
            "20. ODFL \n",
            "21. ILMN \n",
            "22. SBUX \n",
            "23. KHC \n",
            "24. CSGP \n",
            "25. LIN \n",
            "26. CEG \n",
            "27. MAR \n",
            "28. EXC \n",
            "29. SNPS \n",
            "30. FTNT \n",
            "31. AZN \n",
            "32. MU \n",
            "33. PAYX \n",
            "34. GFS \n",
            "35. ROP \n",
            "36. MNST \n",
            "37. PYPL \n",
            "38. ARM \n",
            "39. ASML \n",
            "40. ADI \n",
            "41. AMD \n",
            "42. AAPL \n",
            "43. SMCI \n",
            "44. DXCM \n",
            "45. ISRG \n",
            "46. TTD \n",
            "47. CSCO \n",
            "48. NXPI \n",
            "49. LRCX \n",
            "50. ADP \n",
            "51. IDXX \n",
            "52. ADBE \n",
            "53. HON \n",
            "54. MSFT \n",
            "55. ROST \n",
            "56. CSX \n",
            "57. INTU \n",
            "58. TMUS \n",
            "59. BKNG \n",
            "60. BKR \n",
            "61. TXN \n",
            "62. MRVL \n",
            "63. ANSS \n",
            "64. DDOG \n",
            "65. DASH \n",
            "66. AVGO \n",
            "67. ADSK \n",
            "68. CDW \n",
            "69. CDNS \n",
            "70. GILD \n",
            "71. META \n",
            "72. TSLA \n",
            "73. ABNB \n",
            "74. WBD \n",
            "75. NVDA \n",
            "76. APP \n",
            "77. CPRT \n",
            "78. CHTR \n",
            "79. FAST \n",
            "80. AEP \n",
            "81. FANG \n",
            "82. MDLZ \n",
            "83. PDD \n",
            "84. XEL \n",
            "85. LULU \n",
            "86. CRWD \n",
            "87. GEHC \n",
            "88. NFLX \n",
            "89. BIIB \n",
            "90. CTAS \n",
            "91. REGN \n",
            "92. AMGN \n",
            "93. ORLY \n",
            "94. MCHP \n",
            "95. PEP \n",
            "96. MRNA \n",
            "97. TTWO \n",
            "98. CMCSA \n",
            "99. PCAR \n",
            "100. KDP \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ElOpnrCL_68S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2272e973-1c3b-4e24-d894-730bb734d15f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-8-2556899330.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "# download day, week, and month charts\n",
        "day_charts = [yf.download(ticker, period = 'max', interval = '1d') for ticker in ai90]\n",
        "\n",
        "# drop the multi-level\n",
        "for d in day_charts:\n",
        "    d['symbol'] = d.columns.get_level_values(1)[0]\n",
        "    d.columns = d.columns.droplevel(1)\n",
        "\n",
        "# reset index to get Date column\n",
        "day_charts = [d.reset_index() for d in day_charts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLxKZ8mPBEM2"
      },
      "source": [
        "### Function to preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "H09iebq22P_q"
      },
      "outputs": [],
      "source": [
        "def train_daily(data, length, resp_length, first_date=pd.to_datetime('2017-01-01')):\n",
        "    '''\n",
        "    Training data for daily candles\n",
        "\n",
        "    Params:\n",
        "        1. data: list of daily charts\n",
        "        2. length: number of daily candles in each time series\n",
        "        3. resp_length: number of days to hold each position\n",
        "        4. first_date: cutoff date for the training data\n",
        "    '''\n",
        "\n",
        "    # 0) get the final data after cutoff date and get y variable\n",
        "    data = [d[(d['Date'].dt.date >= first_date.date())] for i, d in enumerate(data)]\n",
        "    for i, d in enumerate(data):\n",
        "        dc = d.copy()\n",
        "        dc['price_final'] = dc['Open'].shift(-(resp_length+1))\n",
        "        dc['price_initial'] = dc['Open'].shift(-1)\n",
        "        dc = dc[dc['price_final'] > 0]\n",
        "        dc['Change'] = (dc['price_final'] - dc['price_initial']) / dc['price_initial']\n",
        "        dc = dc.drop(columns=['price_final', 'price_initial'])\n",
        "        data[i] = dc\n",
        "    total_obs = sum([len(d)-length+1 for d in data])\n",
        "    # 1) get the month_change, date and ticker information for each day of each ticker\n",
        "    dates = np.zeros(total_obs, dtype=object)\n",
        "    resp = np.zeros(total_obs)\n",
        "    tickers = np.zeros(total_obs)\n",
        "    ci = 0\n",
        "    for i, d in enumerate(data):\n",
        "        dates_vec = d['Date'].dt.date.values\n",
        "        resp_vec = d['Change'].values\n",
        "        tickers_vec = d['symbol'].values\n",
        "        tickers_vec = np.ones(shape=tickers_vec.shape)*i\n",
        "        fdv = dates_vec[length-1:]\n",
        "        frv = resp_vec[length-1:]\n",
        "        ftv = tickers_vec[length-1:]\n",
        "        dates[ci:ci+fdv.shape[0]] = fdv\n",
        "        resp[ci:ci+frv.shape[0]] = frv\n",
        "        tickers[ci:ci+ftv.shape[0]] = ftv\n",
        "        ci += fdv.shape[0]\n",
        "    dates = dates.reshape((-1,1))\n",
        "    resp = resp.reshape((-1,1))\n",
        "    tickers = tickers.reshape((-1,1))\n",
        "    # 2) put the data into SWV & normalize (the -3 here is for the 3 cols that we drop)\n",
        "    data_swv = np.zeros((total_obs, length, len(data[0].columns)-3))\n",
        "    # track the total number of entries\n",
        "    si = 0\n",
        "    # standard scaler\n",
        "    scaler = StandardScaler()\n",
        "    for k, d in enumerate(data):\n",
        "        d_numerical = d.drop(['Date', 'symbol', 'Change'], axis=1)\n",
        "        dnp = d_numerical.values\n",
        "        dnp = sliding_window_view(dnp, window_shape=length, axis=0)\n",
        "        dnp_fin = np.moveaxis(dnp, 2,1)\n",
        "        # normalize each 30 day window independently\n",
        "        for i in range(dnp_fin.shape[0]):\n",
        "            # separate the price columns\n",
        "            d_price = dnp_fin[i,:,:4]\n",
        "            # the volume column\n",
        "            d_vol = dnp_fin[i,:,4]\n",
        "            d_ema = dnp_fin[i,:,5:]\n",
        "            # normalize the volume\n",
        "            d_vol = scaler.fit_transform(d_vol.reshape(-1,1))\n",
        "            d_vol = d_vol.reshape(-1)\n",
        "            d_price = scaler.fit_transform(d_price.reshape(-1,1))\n",
        "            d_price = d_price.reshape((-1,4))\n",
        "            data_swv[si,:,:4] = d_price\n",
        "            data_swv[si,:,4] = d_vol\n",
        "            data_swv[si,:,5:] = d_ema\n",
        "            si += 1\n",
        "    return data_swv, resp, dates, tickers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGjl81wyZLw0"
      },
      "source": [
        "### Getting the final data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TFiISkfPble4"
      },
      "outputs": [],
      "source": [
        "# final chart data\n",
        "X, y, dates, tickers = train_daily(day_charts, num_day_candles, resp_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VNpW4JcESyp8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08577932-a604-4e3f-93b6-b7707c9918f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(178187, 200, 5) (178187, 1) (178187, 1) (178187, 1)\n"
          ]
        }
      ],
      "source": [
        "# verify the shapes are correct\n",
        "print(X.shape, y.shape, dates.shape, tickers.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yizKvhTyKCiE"
      },
      "source": [
        "## Simulation Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvO6cbmhvc8O"
      },
      "source": [
        "### Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "f6ic9VIIEDl6"
      },
      "outputs": [],
      "source": [
        "def define_model(daily_candles, daily_features, num_tickers, regularization):\n",
        "    '''\n",
        "    Defines the neural network model that will be used to make predictions\n",
        "\n",
        "    Params:\n",
        "        1. daily_candles: number of daily candles in each observation\n",
        "        2. daily_features: number of features per candle (includes EMAs)\n",
        "        3. num_tickers: number of tickers in the data set\n",
        "        4. regularization: lambda value for regularization\n",
        "    '''\n",
        "\n",
        "    # input layer\n",
        "    day_input = Input(shape=(daily_candles, daily_features), name='Daily Charts')\n",
        "    # LSTM layers\n",
        "    lo1 = LSTM(units=64,\n",
        "               return_sequences=True,\n",
        "               kernel_regularizer=l2(regularization),\n",
        "               recurrent_regularizer=l2(regularization)\n",
        "               )(day_input)\n",
        "    ls1 = LSTM(units=32,\n",
        "              return_sequences=False,\n",
        "              kernel_regularizer=l2(regularization),\n",
        "              recurrent_regularizer=l2(regularization)\n",
        "              )(lo1)\n",
        "    # hidden layers\n",
        "    initializer = HeNormal()\n",
        "    hidden1 = Dense(units=64,\n",
        "                    kernel_initializer=initializer,\n",
        "                    kernel_regularizer=l2(regularization),\n",
        "                    activation='leaky_relu')(ls1)\n",
        "    hidden2 = Dense(units=32,\n",
        "                    kernel_initializer=initializer,\n",
        "                    kernel_regularizer=l2(regularization),\n",
        "                    activation='leaky_relu')(hidden1)\n",
        "    # output layer\n",
        "    output = Dense(1,name='Output')(hidden2)\n",
        "    # define the model & compile\n",
        "    model = Model(inputs=day_input, outputs=output)\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqxS6qGWOJHu"
      },
      "source": [
        "### Function to get market return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mbAUnyWQ5zpe"
      },
      "outputs": [],
      "source": [
        "def get_risk_free(rfa, resp_length, di, df):\n",
        "    '''\n",
        "    Calculates a risk-free rate based on either a defined risk-free rate or\n",
        "    based on a specified asset\n",
        "\n",
        "    Params:\n",
        "        1. rfa: if str, then calculate the average return of the asset over the\n",
        "                specified holding period during the training period\n",
        "        2. resp_length: the holding period for each trade\n",
        "        3. di: the start date of the training data\n",
        "        4. df: the end date of the training data\n",
        "    '''\n",
        "\n",
        "    # if risk_free_asset is an asset rather than a constant value\n",
        "    if isinstance(rfa, str):\n",
        "        # download the chart\n",
        "        rf = yf.download(rfa, start=di, end=df)\n",
        "        rf.columns = rf.columns.droplevel(1)\n",
        "        # calculate the average gain over each resp_length period\n",
        "        rf['shifted'] = rf['Open'].shift(-resp_length)\n",
        "        rf['return'] = (rf['shifted'] - rf['Open']) / rf['Open']\n",
        "        rf = rf[rf.index.date <= df]\n",
        "        rf_return = rf['return'].mean()\n",
        "    else:\n",
        "        rf_return = rfa\n",
        "    print('\\n')\n",
        "    print(f'risk free return: {rf_return}')\n",
        "    return rf_return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlFWQwGlVYSB"
      },
      "source": [
        "### Simulation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PDN4xI4DKE1M"
      },
      "outputs": [],
      "source": [
        "def simulate_trades(dates, start_date, time_length, data_d,\n",
        "                    data_tick, resp, ticker_list, risk_free,\n",
        "                    rf, num_epochs, batches, reg, patience, sr_rating, l_s,\n",
        "                    start_nav = 1_000_000):\n",
        "    '''\n",
        "    Runs the full trade simulation\n",
        "\n",
        "    Params:\n",
        "        1. dates: np.array of all the dates for which we have data\n",
        "        2. start_date: the start date of the sim\n",
        "        3. time_length: the holding period for all trades\n",
        "        4. data_d: np.array of daily charts training data\n",
        "        5. data_tick: np.array of tickers corresponding to the charts\n",
        "        6. resp: np.array of the response variable data\n",
        "        7. ticker_list: list of all tickers in the training data set\n",
        "        8. risk_free: the risk free asset/return\n",
        "        9. rf: the frequency with which the model will be re-trained with updated data\n",
        "        10. num_epochs: number of epochs in training\n",
        "        11. batches: number of batches in training\n",
        "        12. reg: lambda value for regularization\n",
        "        13. patience: patience for early stopping in training\n",
        "        14. sr_rating: minimum rating needed to enter a trade\n",
        "        15. l_s: if True long/short strategy else long only\n",
        "        16. start_nav: starting net asset value for the simulation\n",
        "    '''\n",
        "\n",
        "    # get the trading days in order\n",
        "    trading_days = list(set(dates[dates >= start_date]))\n",
        "    trading_days.sort()\n",
        "    # starting nav and capital allocation\n",
        "    curr_nav = start_nav\n",
        "    prev_nav = start_nav\n",
        "    # early stopping\n",
        "    early_stopping = EarlyStopping(monitor='mse',\n",
        "            patience=patience, restore_best_weights=True,\n",
        "            verbose=1)\n",
        "    # MinMaxScaler\n",
        "    scaler = MinMaxScaler()\n",
        "    # ticker_specific_rmse\n",
        "    ticker_specific_rmse ={}\n",
        "    # if the df gets created\n",
        "    df_created = False\n",
        "    sim_report = pd.DataFrame()\n",
        "    # for retraining\n",
        "    train_min_day = None\n",
        "    for i, day in enumerate(trading_days):\n",
        "        # rebalance the port after each time step\n",
        "        if i % time_length != 0: continue\n",
        "        # mask the dates array\n",
        "        if not train_min_day: train_mask = (dates<day - datetime.timedelta((int(time_length*1.75)+time_length))) & (dates >= (day - datetime.timedelta(int(time_length*1.75)+(4*365)))) # within the past 4 years for training data\n",
        "        else: train_mask = (dates<day - datetime.timedelta((int(time_length*1.75)+time_length))) & (dates >= train_min_day) # only data which the model has not already seen\n",
        "        val_mask = (dates<day) & (dates >= (day - datetime.timedelta(time_length)))\n",
        "        test_mask = dates==day\n",
        "        train_mask = train_mask.squeeze()\n",
        "        test_mask = test_mask.squeeze()\n",
        "        val_mask = val_mask.squeeze()\n",
        "        # inference data\n",
        "        inf_d = data_d[test_mask]\n",
        "        inf_tick = data_tick[test_mask]\n",
        "        moves = resp[test_mask]\n",
        "        inf_tick = inf_tick.astype(np.int32)\n",
        "        # number of tickers\n",
        "        num_tickers = len(ticker_list)\n",
        "        if i % rf == 0:\n",
        "            train_min_day = day\n",
        "            print(f'max training day: {dates[train_mask].max()}, min training day: {dates[train_mask].min()}')\n",
        "            # training data\n",
        "            train_d = data_d[train_mask]\n",
        "            train_tick = data_tick[train_mask]\n",
        "            train_resp = resp[train_mask]\n",
        "            train_tick = train_tick.astype(np.int32)\n",
        "            # validation data\n",
        "            val_d = data_d[val_mask]\n",
        "            val_tick = data_tick[val_mask]\n",
        "            val_resp = resp[val_mask]\n",
        "            val_tick = val_tick.astype(np.int32)\n",
        "            # define the model\n",
        "            if i == 0:\n",
        "                model = define_model(train_d.shape[1], train_d.shape[-1],\n",
        "                                    num_tickers=num_tickers, regularization=reg)\n",
        "            model.fit(x=train_d,\n",
        "                      y=train_resp,\n",
        "                      validation_data=(val_d, val_resp),\n",
        "                      epochs=num_epochs, batch_size=batches,\n",
        "                      callbacks=early_stopping, verbose=1)\n",
        "            # get the ticker specific error rate\n",
        "            val_preds = model.predict(val_d)\n",
        "            full_mse = mse(val_resp.squeeze(), val_preds.squeeze())\n",
        "            full_rmse = np.sqrt(full_mse)\n",
        "            uni_tickers = np.unique(val_tick)\n",
        "            for ticker in uni_tickers:\n",
        "                ticker_mask = val_tick == ticker\n",
        "                ticker_mask = ticker_mask.squeeze()\n",
        "                ticker_train_preds = val_preds.squeeze()\n",
        "                ticker_train_moves  = val_resp.squeeze()\n",
        "                ticker_train_preds = ticker_train_preds[ticker_mask]\n",
        "                ticker_train_moves = ticker_train_moves[ticker_mask]\n",
        "                # get rmse\n",
        "                ticker_train_mse = mse(ticker_train_moves, ticker_train_preds)\n",
        "                ticker_train_rmse = np.sqrt(ticker_train_mse)\n",
        "                ticker_specific_rmse[ticker] = ticker_train_rmse\n",
        "            # print to check\n",
        "            print(ticker_specific_rmse)\n",
        "            # get the risk_free return\n",
        "            train_days = dates[train_mask]\n",
        "            rfr = get_risk_free(risk_free, resp_length, train_days.min(), train_days.max())\n",
        "            # print to ensure no leakage\n",
        "            print(train_days.min(), train_days.max())\n",
        "        # preds\n",
        "        print(day)\n",
        "        preds = model.predict(inf_d)\n",
        "        preds = preds.squeeze()\n",
        "        moves = moves.squeeze()\n",
        "        inf_tick = inf_tick.squeeze()\n",
        "        # divide them by the ticker specific risk\n",
        "        sharpe_scores = np.zeros(preds.shape[0])\n",
        "        specific_rmses =  np.zeros(preds.shape[0])\n",
        "        ticker_sds =  np.zeros(preds.shape[0])\n",
        "        for j, pos_score in enumerate(zip(inf_tick.squeeze(), preds)):\n",
        "            # get rmse for each position and divide the score by it\n",
        "            sd_risk = ticker_specific_rmse.get(pos_score[0], -1)\n",
        "            if sd_risk < 0:\n",
        "                ticker_sd = full_rmse\n",
        "                sharpe_score = (pos_score[1] - rfr) / ticker_sd\n",
        "                # if ticker was not in the training set based on the split use\n",
        "                # the overall training RMSE\n",
        "                specific_rmse = False\n",
        "            else:\n",
        "                ticker_sd = sd_risk\n",
        "                sharpe_score = (pos_score[1] - rfr) / ticker_sd\n",
        "                specific_rmse = True\n",
        "            sharpe_scores[j] = sharpe_score\n",
        "            ticker_sds[j] = ticker_sd\n",
        "            specific_rmses[j] = specific_rmse\n",
        "        # go long if the pred > 0 and sharpe_scores > 1\n",
        "        mask_pred = preds > 0\n",
        "        mask_sharpe = sharpe_scores > sr_rating\n",
        "        final_mask = mask_pred * mask_sharpe\n",
        "        # mask to get the long positions\n",
        "        long_tickers = inf_tick[final_mask]\n",
        "        long_moves = moves[final_mask]\n",
        "        long_ratings = sharpe_scores[final_mask]\n",
        "        long_ers = preds[final_mask]\n",
        "        # short side\n",
        "        mask_short_pred = preds < 0\n",
        "        if l_s: mask_short_sharpe = sharpe_scores < -sr_rating\n",
        "        else:  mask_short_sharpe = sharpe_scores < -999999999\n",
        "        final_short_mask = mask_short_pred * mask_short_sharpe\n",
        "        # mask to get the short positions\n",
        "        short_tickers = inf_tick[final_short_mask]\n",
        "        short_moves = moves[final_short_mask]\n",
        "        short_ratings = sharpe_scores[final_short_mask]\n",
        "        short_ers = preds[final_short_mask]\n",
        "        # if there are no trades\n",
        "        if long_ratings.shape[0] == short_ratings.shape[0] == 0: continue\n",
        "        # notify when the first trade is made\n",
        "        if not df_created: print('First trade made')\n",
        "        # if long and short trades\n",
        "        if (long_ratings.shape[0] > 0) and (short_ratings.shape[0] > 0):\n",
        "            execute_trades = np.concatenate((long_ratings, short_ratings), axis=0)\n",
        "            trade_results = np.concatenate((long_moves, short_moves), axis=0)\n",
        "            trade_names = np.concatenate((long_tickers, short_tickers), axis=0)\n",
        "            ls_mask = np.asarray([True]*long_ratings.shape[0] + [False]*short_ratings.shape[0])\n",
        "            trade_ers = np.concatenate((long_ers, short_ers), axis=0)\n",
        "        elif long_ratings.shape[0] > 0:\n",
        "            execute_trades = long_ratings\n",
        "            trade_results = long_moves\n",
        "            trade_names = long_tickers\n",
        "            ls_mask = np.asarray([True] * long_ratings.shape[0])\n",
        "            trade_ers = long_ers\n",
        "        else:\n",
        "            execute_trades = short_ratings\n",
        "            trade_results = short_moves\n",
        "            trade_names = short_tickers\n",
        "            ls_mask = np.asarray([False] * short_ratings.shape[0])\n",
        "            trade_ers = short_ers\n",
        "        trade_weights = abs(execute_trades)\n",
        "        total_mass = trade_weights.sum()\n",
        "        trade_weights = trade_weights / total_mass\n",
        "        trade_capital = trade_weights * curr_nav\n",
        "        if ~ls_mask[-1]:\n",
        "            if ls_mask[0]:\n",
        "                long_initial = trade_capital[ls_mask]\n",
        "                short_initial = trade_capital[~ls_mask]\n",
        "                trade_long_final = long_initial * (trade_results[ls_mask]+1)\n",
        "                trade_short_final = short_initial * ((-trade_results[~ls_mask])+1)\n",
        "                trade_final = np.concatenate((trade_long_final, trade_short_final), axis=0)\n",
        "            else:\n",
        "                # all short\n",
        "                trade_final = trade_capital * ((-trade_results)+1)\n",
        "        else:\n",
        "            # all long\n",
        "            trade_final = trade_capital * (trade_results+1)\n",
        "        trade_PL = trade_final - trade_capital\n",
        "        total_PL = trade_PL.sum()\n",
        "        total_capital = trade_final.sum()\n",
        "        curr_nav = total_capital\n",
        "        # getting the tickers\n",
        "        trade_ticker_names = [ai90[t] for t in trade_names]\n",
        "        # getting L/S\n",
        "        ls = []\n",
        "        for i in ls_mask:\n",
        "            if i: ls.append('L')\n",
        "            else: ls.append('S')\n",
        "        temp = pd.DataFrame()\n",
        "        temp['Date'] = [day]*trade_weights.shape[0]\n",
        "        temp['Ticker'] = trade_ticker_names\n",
        "        temp['L/S'] = ls\n",
        "        temp['Rating'] = np.round(execute_trades, 2)\n",
        "        temp['Weight'] = np.round(trade_weights, 5)\n",
        "        temp['Initial position'] = np.round(trade_capital, 2)\n",
        "        temp['Final position'] = np.round(trade_final, 2)\n",
        "        temp['PL'] = np.round(trade_PL, 5)\n",
        "        temp['PL%'] = np.round((temp['PL'] / temp['Initial position'])*100, 2)\n",
        "        temp['Total PL'] = [total_PL]*trade_weights.shape[0]\n",
        "        temp['Total Capital'] = [curr_nav]*trade_weights.shape[0]\n",
        "        if not df_created:\n",
        "            sim_report = temp\n",
        "            df_created = True\n",
        "        else: sim_report = pd.concat([sim_report, temp], axis=0)\n",
        "    final_pl = (curr_nav - start_nav) / start_nav\n",
        "    return model, final_pl, sim_report\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93KHhZu8pNup"
      },
      "source": [
        "### Hidden parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "YfC9DaERpTgv"
      },
      "outputs": [],
      "source": [
        "# keep track of the sims\n",
        "sim_number = 1\n",
        "curr_date = datetime.date.today()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "TKVeMO9apWWJ"
      },
      "outputs": [],
      "source": [
        "# number of tickers for the embedding layer\n",
        "num_tickers = len(ai90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "g-8ny0q_PZH0"
      },
      "outputs": [],
      "source": [
        "# array to store sim results\n",
        "PLs = [0]*num_sims"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N01TCZbTDpTQ"
      },
      "source": [
        "# Simulations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0edsfmW90IZR"
      },
      "source": [
        "### Run the simulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HqEBcnBk0Qn0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "36bad425-3488-446d-b376-9880f1c5c130"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max training day: 2023-08-31, min training day: 2019-10-17\n",
            "Epoch 1/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - loss: 0.0455 - mse: 0.0314 - val_loss: 0.0652 - val_mse: 0.0591\n",
            "Epoch 2/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0346 - mse: 0.0296 - val_loss: 0.0618 - val_mse: 0.0591\n",
            "Epoch 3/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0311 - mse: 0.0288 - val_loss: 0.0619 - val_mse: 0.0604\n",
            "Epoch 4/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0287 - mse: 0.0274 - val_loss: 0.0635 - val_mse: 0.0624\n",
            "Epoch 5/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0277 - mse: 0.0266 - val_loss: 0.0612 - val_mse: 0.0600\n",
            "Epoch 6/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0275 - mse: 0.0264 - val_loss: 0.0602 - val_mse: 0.0591\n",
            "Epoch 7/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0272 - mse: 0.0261 - val_loss: 0.0634 - val_mse: 0.0622\n",
            "Epoch 8/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0265 - mse: 0.0254 - val_loss: 0.0595 - val_mse: 0.0583\n",
            "Epoch 9/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0265 - mse: 0.0253 - val_loss: 0.0578 - val_mse: 0.0565\n",
            "Epoch 10/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0259 - mse: 0.0247 - val_loss: 0.0578 - val_mse: 0.0565\n",
            "Epoch 11/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0249 - mse: 0.0236 - val_loss: 0.0609 - val_mse: 0.0596\n",
            "Epoch 12/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0248 - mse: 0.0234 - val_loss: 0.0617 - val_mse: 0.0603\n",
            "Epoch 13/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0242 - mse: 0.0227 - val_loss: 0.0613 - val_mse: 0.0598\n",
            "Epoch 14/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0238 - mse: 0.0223 - val_loss: 0.0616 - val_mse: 0.0600\n",
            "Epoch 15/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0260 - mse: 0.0244 - val_loss: 0.0640 - val_mse: 0.0624\n",
            "Epoch 16/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0241 - mse: 0.0225 - val_loss: 0.0634 - val_mse: 0.0617\n",
            "Epoch 17/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0236 - mse: 0.0219 - val_loss: 0.0631 - val_mse: 0.0613\n",
            "Epoch 18/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0233 - mse: 0.0216 - val_loss: 0.0626 - val_mse: 0.0609\n",
            "Epoch 19/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0231 - mse: 0.0213 - val_loss: 0.0633 - val_mse: 0.0614\n",
            "Epoch 20/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0224 - mse: 0.0205 - val_loss: 0.0626 - val_mse: 0.0607\n",
            "Epoch 21/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0223 - mse: 0.0204 - val_loss: 0.0626 - val_mse: 0.0606\n",
            "Epoch 22/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0234 - mse: 0.0214 - val_loss: 0.0628 - val_mse: 0.0607\n",
            "Epoch 23/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0223 - mse: 0.0202 - val_loss: 0.0626 - val_mse: 0.0605\n",
            "Epoch 24/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0216 - mse: 0.0195 - val_loss: 0.0663 - val_mse: 0.0642\n",
            "Epoch 25/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0216 - mse: 0.0195 - val_loss: 0.0630 - val_mse: 0.0608\n",
            "Epoch 26/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0211 - mse: 0.0189 - val_loss: 0.0639 - val_mse: 0.0617\n",
            "Epoch 27/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0215 - mse: 0.0193 - val_loss: 0.0660 - val_mse: 0.0638\n",
            "Epoch 28/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0213 - mse: 0.0191 - val_loss: 0.0677 - val_mse: 0.0655\n",
            "Epoch 29/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0218 - mse: 0.0195 - val_loss: 0.0663 - val_mse: 0.0640\n",
            "Epoch 30/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0208 - mse: 0.0185 - val_loss: 0.0612 - val_mse: 0.0589\n",
            "Epoch 31/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0209 - mse: 0.0186 - val_loss: 0.0625 - val_mse: 0.0601\n",
            "Epoch 32/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0206 - mse: 0.0182 - val_loss: 0.0640 - val_mse: 0.0617\n",
            "Epoch 33/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0204 - mse: 0.0181 - val_loss: 0.0652 - val_mse: 0.0628\n",
            "Epoch 34/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0206 - mse: 0.0182 - val_loss: 0.0641 - val_mse: 0.0617\n",
            "Epoch 35/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0199 - mse: 0.0175 - val_loss: 0.0671 - val_mse: 0.0647\n",
            "Epoch 36/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0198 - mse: 0.0174 - val_loss: 0.0662 - val_mse: 0.0637\n",
            "Epoch 37/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0200 - mse: 0.0175 - val_loss: 0.0637 - val_mse: 0.0612\n",
            "Epoch 38/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0205 - mse: 0.0180 - val_loss: 0.0662 - val_mse: 0.0637\n",
            "Epoch 39/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0197 - mse: 0.0172 - val_loss: 0.0661 - val_mse: 0.0636\n",
            "Epoch 40/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0200 - mse: 0.0175 - val_loss: 0.0649 - val_mse: 0.0623\n",
            "Epoch 41/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0209 - mse: 0.0183 - val_loss: 0.0665 - val_mse: 0.0639\n",
            "Epoch 42/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0218 - mse: 0.0192 - val_loss: 0.0645 - val_mse: 0.0618\n",
            "Epoch 43/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0199 - mse: 0.0173 - val_loss: 0.0666 - val_mse: 0.0640\n",
            "Epoch 43: early stopping\n",
            "Restoring model weights from the end of the best epoch: 38.\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "{np.int32(0): np.float32(0.15677178), np.int32(1): np.float32(0.08805929), np.int32(2): np.float32(0.05119869), np.int32(3): np.float32(0.05178285), np.int32(4): np.float32(0.029818714), np.int32(5): np.float32(0.2054248), np.int32(6): np.float32(0.16811967), np.int32(7): np.float32(0.05224502), np.int32(8): np.float32(0.21549828), np.int32(9): np.float32(0.1893103), np.int32(10): np.float32(0.1763273), np.int32(11): np.float32(0.12322448), np.int32(12): np.float32(0.0641598), np.int32(13): np.float32(0.14164582), np.int32(14): np.float32(0.14031823), np.int32(15): np.float32(0.10915434), np.int32(16): np.float32(0.038978506), np.int32(17): np.float32(0.09277754), np.int32(18): np.float32(0.081527725), np.int32(19): np.float32(0.10338069), np.int32(20): np.float32(0.28959987), np.int32(21): np.float32(0.06697076), np.int32(22): np.float32(0.10474583), np.int32(23): np.float32(0.038741935), np.int32(24): np.float32(0.09348794), np.int32(25): np.float32(0.25207356), np.int32(26): np.float32(0.21804245), np.int32(27): np.float32(0.078267485), np.int32(28): np.float32(0.07341767), np.int32(29): np.float32(0.15567358), np.int32(30): np.float32(0.104753755), np.int32(31): np.float32(0.11347127), np.int32(32): np.float32(0.023097437), np.int32(33): np.float32(0.11787246), np.int32(34): np.float32(0.036058452), np.int32(35): np.float32(0.07053664), np.int32(36): np.float32(0.074285105), np.int32(38): np.float32(0.4181426), np.int32(39): np.float32(0.0699246), np.int32(40): np.float32(0.3563378), np.int32(41): np.float32(0.11146125), np.int32(42): np.float32(1.8966076), np.int32(43): np.float32(0.26273897), np.int32(44): np.float32(0.18391427), np.int32(45): np.float32(0.07563167), np.int32(46): np.float32(0.059900366), np.int32(47): np.float32(0.10197235), np.int32(48): np.float32(0.1899603), np.int32(49): np.float32(0.058594517), np.int32(50): np.float32(0.110705145), np.int32(51): np.float32(0.06778155), np.int32(52): np.float32(0.063193135), np.int32(53): np.float32(0.11053641), np.int32(54): np.float32(0.1320192), np.int32(55): np.float32(0.12418449), np.int32(56): np.float32(0.10521102), np.int32(57): np.float32(0.056490812), np.int32(58): np.float32(0.09831678), np.int32(59): np.float32(0.15379022), np.int32(60): np.float32(0.025539646), np.int32(61): np.float32(0.24466655), np.int32(62): np.float32(0.09406924), np.int32(63): np.float32(0.12435455), np.int32(64): np.float32(0.22561106), np.int32(65): np.float32(0.23049901), np.int32(66): np.float32(0.15059823), np.int32(67): np.float32(0.0947112), np.int32(68): np.float32(0.11414913), np.int32(69): np.float32(0.13106728), np.int32(70): np.float32(0.35529304), np.int32(71): np.float32(0.23893534), np.int32(72): np.float32(0.13919774), np.int32(73): np.float32(0.16455935), np.int32(74): np.float32(0.55136186), np.int32(75): np.float32(0.36481324), np.int32(76): np.float32(0.27644888), np.int32(77): np.float32(0.27773413), np.int32(78): np.float32(0.13618293), np.int32(79): np.float32(0.03333738), np.int32(80): np.float32(0.11467468), np.int32(81): np.float32(0.061751667), np.int32(82): np.float32(0.10769716), np.int32(83): np.float32(0.11085358), np.int32(84): np.float32(0.08122325), np.int32(85): np.float32(0.34660926), np.int32(86): np.float32(0.15899113), np.int32(87): np.float32(0.1425593), np.int32(88): np.float32(0.15443179), np.int32(89): np.float32(0.12056376), np.int32(90): np.float32(0.11699772), np.int32(91): np.float32(0.09715615), np.int32(92): np.float32(0.094312906), np.int32(93): np.float32(0.05464914), np.int32(94): np.float32(0.05605037), np.int32(95): np.float32(0.14748307), np.int32(96): np.float32(0.18941592), np.int32(97): np.float32(0.065597475), np.int32(98): np.float32(0.1349038), np.int32(99): np.float32(0.14399314)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-13-1585781058.py:17: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  rf = yf.download(rfa, start=di, end=df)\n",
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "risk free return: 0.024185361237271705\n",
            "2019-10-17 2023-08-31\n",
            "2024-01-02\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "First trade made\n",
            "2024-03-07\n",
            "\u001b[1m1/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2024-05-10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2024-07-17\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2024-09-19\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2024-11-21\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2025-01-30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2025-04-04\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_74badf2c-bc99-426e-9282-a09db54579f4\", \"2025-07-10_simulation_report_1.csv\", 3819)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max training day: 2023-08-31, min training day: 2019-10-17\n",
            "Epoch 1/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - loss: 0.0446 - mse: 0.0311 - val_loss: 0.0643 - val_mse: 0.0588\n",
            "Epoch 2/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0342 - mse: 0.0297 - val_loss: 0.0604 - val_mse: 0.0580\n",
            "Epoch 3/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0304 - mse: 0.0283 - val_loss: 0.0609 - val_mse: 0.0596\n",
            "Epoch 4/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0287 - mse: 0.0274 - val_loss: 0.0656 - val_mse: 0.0645\n",
            "Epoch 5/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0280 - mse: 0.0270 - val_loss: 0.0601 - val_mse: 0.0591\n",
            "Epoch 6/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0284 - mse: 0.0274 - val_loss: 0.0598 - val_mse: 0.0588\n",
            "Epoch 7/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0277 - mse: 0.0267 - val_loss: 0.0569 - val_mse: 0.0559\n",
            "Epoch 8/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0270 - mse: 0.0259 - val_loss: 0.0592 - val_mse: 0.0580\n",
            "Epoch 9/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0277 - mse: 0.0265 - val_loss: 0.0636 - val_mse: 0.0624\n",
            "Epoch 10/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0266 - mse: 0.0252 - val_loss: 0.0585 - val_mse: 0.0570\n",
            "Epoch 11/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0277 - mse: 0.0263 - val_loss: 0.0586 - val_mse: 0.0572\n",
            "Epoch 12/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0271 - mse: 0.0256 - val_loss: 0.0604 - val_mse: 0.0590\n",
            "Epoch 13/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0260 - mse: 0.0245 - val_loss: 0.0610 - val_mse: 0.0596\n",
            "Epoch 14/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0259 - mse: 0.0244 - val_loss: 0.0607 - val_mse: 0.0592\n",
            "Epoch 15/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0255 - mse: 0.0240 - val_loss: 0.0598 - val_mse: 0.0583\n",
            "Epoch 16/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0249 - mse: 0.0234 - val_loss: 0.0607 - val_mse: 0.0593\n",
            "Epoch 17/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0242 - mse: 0.0227 - val_loss: 0.0659 - val_mse: 0.0644\n",
            "Epoch 18/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0250 - mse: 0.0234 - val_loss: 0.0558 - val_mse: 0.0542\n",
            "Epoch 19/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0243 - mse: 0.0227 - val_loss: 0.0650 - val_mse: 0.0633\n",
            "Epoch 20/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0245 - mse: 0.0228 - val_loss: 0.0619 - val_mse: 0.0602\n",
            "Epoch 21/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0249 - mse: 0.0231 - val_loss: 0.0659 - val_mse: 0.0641\n",
            "Epoch 22/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0235 - mse: 0.0218 - val_loss: 0.0655 - val_mse: 0.0637\n",
            "Epoch 23/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0236 - mse: 0.0218 - val_loss: 0.0656 - val_mse: 0.0638\n",
            "Epoch 24/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0227 - mse: 0.0209 - val_loss: 0.0661 - val_mse: 0.0643\n",
            "Epoch 25/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0236 - mse: 0.0217 - val_loss: 0.0626 - val_mse: 0.0607\n",
            "Epoch 26/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0231 - mse: 0.0212 - val_loss: 0.0652 - val_mse: 0.0632\n",
            "Epoch 27/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0238 - mse: 0.0218 - val_loss: 0.0634 - val_mse: 0.0614\n",
            "Epoch 28/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0237 - mse: 0.0217 - val_loss: 0.0686 - val_mse: 0.0666\n",
            "Epoch 29/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0225 - mse: 0.0205 - val_loss: 0.0627 - val_mse: 0.0607\n",
            "Epoch 30/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0239 - mse: 0.0219 - val_loss: 0.0650 - val_mse: 0.0628\n",
            "Epoch 31/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0221 - mse: 0.0200 - val_loss: 0.0658 - val_mse: 0.0637\n",
            "Epoch 32/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0262 - mse: 0.0240 - val_loss: 0.0654 - val_mse: 0.0633\n",
            "Epoch 33/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0222 - mse: 0.0201 - val_loss: 0.0580 - val_mse: 0.0558\n",
            "Epoch 34/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0229 - mse: 0.0206 - val_loss: 0.0585 - val_mse: 0.0563\n",
            "Epoch 35/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0221 - mse: 0.0199 - val_loss: 0.0659 - val_mse: 0.0637\n",
            "Epoch 36/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0274 - mse: 0.0251 - val_loss: 0.0610 - val_mse: 0.0586\n",
            "Epoch 37/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0287 - mse: 0.0264 - val_loss: 0.0639 - val_mse: 0.0618\n",
            "Epoch 38/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0275 - mse: 0.0253 - val_loss: 0.0557 - val_mse: 0.0536\n",
            "Epoch 39/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0254 - mse: 0.0233 - val_loss: 0.0633 - val_mse: 0.0612\n",
            "Epoch 40/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0242 - mse: 0.0221 - val_loss: 0.0654 - val_mse: 0.0633\n",
            "Epoch 40: early stopping\n",
            "Restoring model weights from the end of the best epoch: 35.\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-13-1585781058.py:17: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  rf = yf.download(rfa, start=di, end=df)\n",
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{np.int32(0): np.float32(0.13989492), np.int32(1): np.float32(0.10828615), np.int32(2): np.float32(0.044800278), np.int32(3): np.float32(0.05919954), np.int32(4): np.float32(0.021151297), np.int32(5): np.float32(0.2138207), np.int32(6): np.float32(0.16027011), np.int32(7): np.float32(0.041132443), np.int32(8): np.float32(0.22674735), np.int32(9): np.float32(0.14973472), np.int32(10): np.float32(0.20009534), np.int32(11): np.float32(0.10851206), np.int32(12): np.float32(0.081806354), np.int32(13): np.float32(0.12812643), np.int32(14): np.float32(0.12567906), np.int32(15): np.float32(0.08560698), np.int32(16): np.float32(0.023808612), np.int32(17): np.float32(0.08195434), np.int32(18): np.float32(0.15601735), np.int32(19): np.float32(0.067564726), np.int32(20): np.float32(0.28801736), np.int32(21): np.float32(0.10518069), np.int32(22): np.float32(0.19825234), np.int32(23): np.float32(0.05540014), np.int32(24): np.float32(0.085623324), np.int32(25): np.float32(0.24824229), np.int32(26): np.float32(0.15429102), np.int32(27): np.float32(0.07013623), np.int32(28): np.float32(0.07028275), np.int32(29): np.float32(0.2944678), np.int32(30): np.float32(0.095684856), np.int32(31): np.float32(0.11648957), np.int32(32): np.float32(0.023783859), np.int32(33): np.float32(0.13191302), np.int32(34): np.float32(0.01860841), np.int32(35): np.float32(0.13983601), np.int32(36): np.float32(0.10902162), np.int32(38): np.float32(0.30766362), np.int32(39): np.float32(0.046958547), np.int32(40): np.float32(0.3622002), np.int32(41): np.float32(0.06481196), np.int32(42): np.float32(1.9165771), np.int32(43): np.float32(0.21552286), np.int32(44): np.float32(0.15277958), np.int32(45): np.float32(0.059310686), np.int32(46): np.float32(0.10194417), np.int32(47): np.float32(0.050143342), np.int32(48): np.float32(0.19215865), np.int32(49): np.float32(0.04805807), np.int32(50): np.float32(0.10056191), np.int32(51): np.float32(0.08074823), np.int32(52): np.float32(0.026889153), np.int32(53): np.float32(0.05520953), np.int32(54): np.float32(0.13019535), np.int32(55): np.float32(0.10482556), np.int32(56): np.float32(0.14039963), np.int32(57): np.float32(0.041233405), np.int32(58): np.float32(0.1449422), np.int32(59): np.float32(0.18859431), np.int32(60): np.float32(0.020896384), np.int32(61): np.float32(0.23564136), np.int32(62): np.float32(0.09869078), np.int32(63): np.float32(0.07311344), np.int32(64): np.float32(0.21487126), np.int32(65): np.float32(0.25968084), np.int32(66): np.float32(0.1679302), np.int32(67): np.float32(0.039486676), np.int32(68): np.float32(0.08793181), np.int32(69): np.float32(0.10662337), np.int32(70): np.float32(0.3608131), np.int32(71): np.float32(0.27155104), np.int32(72): np.float32(0.1277208), np.int32(73): np.float32(0.21449158), np.int32(74): np.float32(0.4789203), np.int32(75): np.float32(0.3914409), np.int32(76): np.float32(0.05946845), np.int32(77): np.float32(0.22441821), np.int32(78): np.float32(0.15761738), np.int32(79): np.float32(0.15606882), np.int32(80): np.float32(0.13599823), np.int32(81): np.float32(0.040111344), np.int32(82): np.float32(0.1328983), np.int32(83): np.float32(0.12941219), np.int32(84): np.float32(0.067032), np.int32(85): np.float32(0.3695627), np.int32(86): np.float32(0.32922673), np.int32(87): np.float32(0.11979345), np.int32(88): np.float32(0.033633795), np.int32(89): np.float32(0.117779694), np.int32(90): np.float32(0.10775956), np.int32(91): np.float32(0.12520353), np.int32(92): np.float32(0.10298543), np.int32(93): np.float32(0.070856474), np.int32(94): np.float32(0.04660864), np.int32(95): np.float32(0.14757463), np.int32(96): np.float32(0.053145308), np.int32(97): np.float32(0.05932194), np.int32(98): np.float32(0.16888079), np.int32(99): np.float32(0.110561766)}\n",
            "\n",
            "\n",
            "risk free return: 0.024185361237271705\n",
            "2019-10-17 2023-08-31\n",
            "2024-01-02\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "First trade made\n",
            "2024-03-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "2024-05-10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2024-07-17\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2024-09-19\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2024-11-21\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2025-01-30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2025-04-04\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5060d4ae-1829-49c9-93c0-914056d81851\", \"2025-07-10_simulation_report_2.csv\", 4148)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max training day: 2023-08-31, min training day: 2019-10-17\n",
            "Epoch 1/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - loss: 0.0432 - mse: 0.0307 - val_loss: 0.0607 - val_mse: 0.0565\n",
            "Epoch 2/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0323 - mse: 0.0290 - val_loss: 0.0596 - val_mse: 0.0579\n",
            "Epoch 3/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0313 - mse: 0.0298 - val_loss: 0.0594 - val_mse: 0.0584\n",
            "Epoch 4/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0290 - mse: 0.0280 - val_loss: 0.0564 - val_mse: 0.0554\n",
            "Epoch 5/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0281 - mse: 0.0272 - val_loss: 0.0606 - val_mse: 0.0597\n",
            "Epoch 6/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0282 - mse: 0.0272 - val_loss: 0.0591 - val_mse: 0.0580\n",
            "Epoch 7/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0276 - mse: 0.0265 - val_loss: 0.0628 - val_mse: 0.0614\n",
            "Epoch 8/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0285 - mse: 0.0271 - val_loss: 0.0575 - val_mse: 0.0561\n",
            "Epoch 9/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0271 - mse: 0.0257 - val_loss: 0.0631 - val_mse: 0.0618\n",
            "Epoch 10/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0268 - mse: 0.0254 - val_loss: 0.0616 - val_mse: 0.0602\n",
            "Epoch 11/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0256 - mse: 0.0242 - val_loss: 0.0605 - val_mse: 0.0590\n",
            "Epoch 12/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0249 - mse: 0.0235 - val_loss: 0.0606 - val_mse: 0.0591\n",
            "Epoch 13/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0253 - mse: 0.0238 - val_loss: 0.0631 - val_mse: 0.0616\n",
            "Epoch 14/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0259 - mse: 0.0243 - val_loss: 0.0611 - val_mse: 0.0596\n",
            "Epoch 15/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0249 - mse: 0.0233 - val_loss: 0.0607 - val_mse: 0.0591\n",
            "Epoch 16/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0261 - mse: 0.0244 - val_loss: 0.0621 - val_mse: 0.0605\n",
            "Epoch 17/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0244 - mse: 0.0227 - val_loss: 0.0652 - val_mse: 0.0635\n",
            "Epoch 18/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0239 - mse: 0.0222 - val_loss: 0.0632 - val_mse: 0.0614\n",
            "Epoch 19/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0236 - mse: 0.0218 - val_loss: 0.0632 - val_mse: 0.0614\n",
            "Epoch 20/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0230 - mse: 0.0212 - val_loss: 0.0615 - val_mse: 0.0596\n",
            "Epoch 21/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0236 - mse: 0.0217 - val_loss: 0.0633 - val_mse: 0.0613\n",
            "Epoch 22/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0230 - mse: 0.0210 - val_loss: 0.0601 - val_mse: 0.0581\n",
            "Epoch 23/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0237 - mse: 0.0217 - val_loss: 0.0641 - val_mse: 0.0622\n",
            "Epoch 24/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0245 - mse: 0.0225 - val_loss: 0.0605 - val_mse: 0.0585\n",
            "Epoch 25/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0248 - mse: 0.0228 - val_loss: 0.0609 - val_mse: 0.0589\n",
            "Epoch 25: early stopping\n",
            "Restoring model weights from the end of the best epoch: 20.\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-13-1585781058.py:17: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  rf = yf.download(rfa, start=di, end=df)\n",
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{np.int32(0): np.float32(0.17387114), np.int32(1): np.float32(0.048992198), np.int32(2): np.float32(0.057354365), np.int32(3): np.float32(0.055271223), np.int32(4): np.float32(0.039132003), np.int32(5): np.float32(0.19260427), np.int32(6): np.float32(0.16405046), np.int32(7): np.float32(0.028771343), np.int32(8): np.float32(0.19933885), np.int32(9): np.float32(0.17965798), np.int32(10): np.float32(0.17497747), np.int32(11): np.float32(0.1068738), np.int32(12): np.float32(0.07409902), np.int32(13): np.float32(0.113947876), np.int32(14): np.float32(0.119087845), np.int32(15): np.float32(0.12267396), np.int32(16): np.float32(0.03311357), np.int32(17): np.float32(0.09655803), np.int32(18): np.float32(0.14245087), np.int32(19): np.float32(0.056984168), np.int32(20): np.float32(0.1407948), np.int32(21): np.float32(0.1085832), np.int32(22): np.float32(0.14170901), np.int32(23): np.float32(0.091342315), np.int32(24): np.float32(0.07182308), np.int32(25): np.float32(0.23573287), np.int32(26): np.float32(0.10555328), np.int32(27): np.float32(0.12666951), np.int32(28): np.float32(0.057699453), np.int32(29): np.float32(0.17696035), np.int32(30): np.float32(0.120344326), np.int32(31): np.float32(0.10361732), np.int32(32): np.float32(0.025449878), np.int32(33): np.float32(0.1182867), np.int32(34): np.float32(0.016784903), np.int32(35): np.float32(0.02308854), np.int32(36): np.float32(0.12095958), np.int32(38): np.float32(0.24952321), np.int32(39): np.float32(0.04274338), np.int32(40): np.float32(0.34261164), np.int32(41): np.float32(0.09116257), np.int32(42): np.float32(1.8939463), np.int32(43): np.float32(0.14279242), np.int32(44): np.float32(0.1459057), np.int32(45): np.float32(0.07808309), np.int32(46): np.float32(0.12000109), np.int32(47): np.float32(0.0613118), np.int32(48): np.float32(0.18832862), np.int32(49): np.float32(0.04631126), np.int32(50): np.float32(0.21378921), np.int32(51): np.float32(0.071244135), np.int32(52): np.float32(0.05093338), np.int32(53): np.float32(0.06597423), np.int32(54): np.float32(0.108824685), np.int32(55): np.float32(0.09734429), np.int32(56): np.float32(0.094700605), np.int32(57): np.float32(0.040595107), np.int32(58): np.float32(0.08197051), np.int32(59): np.float32(0.1674143), np.int32(60): np.float32(0.08603086), np.int32(61): np.float32(0.21218659), np.int32(62): np.float32(0.08388566), np.int32(63): np.float32(0.08229373), np.int32(64): np.float32(0.23069672), np.int32(65): np.float32(0.24646841), np.int32(66): np.float32(0.14976676), np.int32(67): np.float32(0.08132741), np.int32(68): np.float32(0.09679014), np.int32(69): np.float32(0.109760545), np.int32(70): np.float32(0.34437835), np.int32(71): np.float32(0.274497), np.int32(72): np.float32(0.085542575), np.int32(73): np.float32(0.18885629), np.int32(74): np.float32(0.50183207), np.int32(75): np.float32(0.3520156), np.int32(76): np.float32(0.06348924), np.int32(77): np.float32(0.29251143), np.int32(78): np.float32(0.14608186), np.int32(79): np.float32(0.07254252), np.int32(80): np.float32(0.097050846), np.int32(81): np.float32(0.046876773), np.int32(82): np.float32(0.105596595), np.int32(83): np.float32(0.16671786), np.int32(84): np.float32(0.06785715), np.int32(85): np.float32(0.3425685), np.int32(86): np.float32(0.1933172), np.int32(87): np.float32(0.17921941), np.int32(88): np.float32(0.21476826), np.int32(89): np.float32(0.10335556), np.int32(90): np.float32(0.11165273), np.int32(91): np.float32(0.10239498), np.int32(92): np.float32(0.072857924), np.int32(93): np.float32(0.08522748), np.int32(94): np.float32(0.046552487), np.int32(95): np.float32(0.16429728), np.int32(96): np.float32(0.058429793), np.int32(97): np.float32(0.06294401), np.int32(98): np.float32(0.14014173), np.int32(99): np.float32(0.103197075)}\n",
            "\n",
            "\n",
            "risk free return: 0.024185361237271705\n",
            "2019-10-17 2023-08-31\n",
            "2024-01-02\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "First trade made\n",
            "2024-03-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2024-05-10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "2024-07-17\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "2024-09-19\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2024-11-21\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2025-01-30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2025-04-04\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7ed68b30-8917-4e5f-a85e-6378e9e2a7a8\", \"2025-07-10_simulation_report_3.csv\", 5073)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max training day: 2023-08-31, min training day: 2019-10-17\n",
            "Epoch 1/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - loss: 0.0452 - mse: 0.0311 - val_loss: 0.0640 - val_mse: 0.0583\n",
            "Epoch 2/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0340 - mse: 0.0293 - val_loss: 0.0603 - val_mse: 0.0579\n",
            "Epoch 3/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0305 - mse: 0.0284 - val_loss: 0.0559 - val_mse: 0.0546\n",
            "Epoch 4/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0294 - mse: 0.0281 - val_loss: 0.0603 - val_mse: 0.0592\n",
            "Epoch 5/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0283 - mse: 0.0273 - val_loss: 0.0599 - val_mse: 0.0590\n",
            "Epoch 6/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0282 - mse: 0.0272 - val_loss: 0.0586 - val_mse: 0.0576\n",
            "Epoch 7/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0276 - mse: 0.0265 - val_loss: 0.0612 - val_mse: 0.0601\n",
            "Epoch 8/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0266 - mse: 0.0255 - val_loss: 0.0628 - val_mse: 0.0613\n",
            "Epoch 9/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0282 - mse: 0.0269 - val_loss: 0.0599 - val_mse: 0.0585\n",
            "Epoch 10/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0280 - mse: 0.0266 - val_loss: 0.0596 - val_mse: 0.0583\n",
            "Epoch 11/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0261 - mse: 0.0247 - val_loss: 0.0595 - val_mse: 0.0580\n",
            "Epoch 12/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0263 - mse: 0.0248 - val_loss: 0.0595 - val_mse: 0.0579\n",
            "Epoch 13/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0261 - mse: 0.0246 - val_loss: 0.0605 - val_mse: 0.0589\n",
            "Epoch 14/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0251 - mse: 0.0236 - val_loss: 0.0632 - val_mse: 0.0615\n",
            "Epoch 15/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0251 - mse: 0.0234 - val_loss: 0.0619 - val_mse: 0.0602\n",
            "Epoch 16/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0253 - mse: 0.0236 - val_loss: 0.0604 - val_mse: 0.0587\n",
            "Epoch 17/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0245 - mse: 0.0227 - val_loss: 0.0619 - val_mse: 0.0602\n",
            "Epoch 18/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0242 - mse: 0.0225 - val_loss: 0.0589 - val_mse: 0.0570\n",
            "Epoch 19/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0273 - mse: 0.0254 - val_loss: 0.0631 - val_mse: 0.0613\n",
            "Epoch 20/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0242 - mse: 0.0224 - val_loss: 0.0634 - val_mse: 0.0616\n",
            "Epoch 21/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0236 - mse: 0.0217 - val_loss: 0.0643 - val_mse: 0.0624\n",
            "Epoch 22/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0233 - mse: 0.0214 - val_loss: 0.0634 - val_mse: 0.0615\n",
            "Epoch 23/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0231 - mse: 0.0211 - val_loss: 0.0618 - val_mse: 0.0598\n",
            "Epoch 24/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0258 - mse: 0.0238 - val_loss: 0.0627 - val_mse: 0.0607\n",
            "Epoch 25/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0231 - mse: 0.0211 - val_loss: 0.0658 - val_mse: 0.0638\n",
            "Epoch 26/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0230 - mse: 0.0209 - val_loss: 0.0668 - val_mse: 0.0648\n",
            "Epoch 27/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0223 - mse: 0.0203 - val_loss: 0.0634 - val_mse: 0.0613\n",
            "Epoch 28/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0219 - mse: 0.0197 - val_loss: 0.0666 - val_mse: 0.0645\n",
            "Epoch 29/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0212 - mse: 0.0190 - val_loss: 0.0714 - val_mse: 0.0692\n",
            "Epoch 30/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0213 - mse: 0.0191 - val_loss: 0.0666 - val_mse: 0.0644\n",
            "Epoch 31/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0212 - mse: 0.0189 - val_loss: 0.0688 - val_mse: 0.0665\n",
            "Epoch 32/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0210 - mse: 0.0186 - val_loss: 0.0657 - val_mse: 0.0633\n",
            "Epoch 33/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0209 - mse: 0.0185 - val_loss: 0.0685 - val_mse: 0.0660\n",
            "Epoch 34/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0199 - mse: 0.0175 - val_loss: 0.0742 - val_mse: 0.0716\n",
            "Epoch 35/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0203 - mse: 0.0178 - val_loss: 0.0745 - val_mse: 0.0719\n",
            "Epoch 36/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0196 - mse: 0.0170 - val_loss: 0.0733 - val_mse: 0.0707\n",
            "Epoch 37/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0198 - mse: 0.0171 - val_loss: 0.0765 - val_mse: 0.0738\n",
            "Epoch 38/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0191 - mse: 0.0164 - val_loss: 0.0663 - val_mse: 0.0635\n",
            "Epoch 39/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0192 - mse: 0.0164 - val_loss: 0.0617 - val_mse: 0.0588\n",
            "Epoch 40/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0252 - mse: 0.0223 - val_loss: 0.0712 - val_mse: 0.0684\n",
            "Epoch 41/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0189 - mse: 0.0161 - val_loss: 0.0761 - val_mse: 0.0732\n",
            "Epoch 42/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0192 - mse: 0.0164 - val_loss: 0.0783 - val_mse: 0.0754\n",
            "Epoch 43/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0187 - mse: 0.0158 - val_loss: 0.0746 - val_mse: 0.0716\n",
            "Epoch 44/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0191 - mse: 0.0161 - val_loss: 0.0781 - val_mse: 0.0751\n",
            "Epoch 45/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0182 - mse: 0.0152 - val_loss: 0.0783 - val_mse: 0.0752\n",
            "Epoch 46/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0188 - mse: 0.0157 - val_loss: 0.0687 - val_mse: 0.0655\n",
            "Epoch 47/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0182 - mse: 0.0151 - val_loss: 0.0749 - val_mse: 0.0717\n",
            "Epoch 48/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0180 - mse: 0.0148 - val_loss: 0.0717 - val_mse: 0.0685\n",
            "Epoch 49/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0175 - mse: 0.0143 - val_loss: 0.0689 - val_mse: 0.0656\n",
            "Epoch 50/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0210 - mse: 0.0177 - val_loss: 0.0729 - val_mse: 0.0696\n",
            "Epoch 51/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0185 - mse: 0.0152 - val_loss: 0.0784 - val_mse: 0.0751\n",
            "Epoch 52/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0170 - mse: 0.0137 - val_loss: 0.0703 - val_mse: 0.0670\n",
            "Epoch 53/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0169 - mse: 0.0136 - val_loss: 0.0726 - val_mse: 0.0693\n",
            "Epoch 54/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0175 - mse: 0.0141 - val_loss: 0.0706 - val_mse: 0.0673\n",
            "Epoch 55/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0178 - mse: 0.0143 - val_loss: 0.0776 - val_mse: 0.0741\n",
            "Epoch 56/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0167 - mse: 0.0132 - val_loss: 0.0766 - val_mse: 0.0732\n",
            "Epoch 57/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0168 - mse: 0.0134 - val_loss: 0.0750 - val_mse: 0.0715\n",
            "Epoch 58/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0166 - mse: 0.0131 - val_loss: 0.0805 - val_mse: 0.0770\n",
            "Epoch 59/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0169 - mse: 0.0134 - val_loss: 0.0748 - val_mse: 0.0713\n",
            "Epoch 60/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0162 - mse: 0.0127 - val_loss: 0.0802 - val_mse: 0.0766\n",
            "Epoch 61/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0164 - mse: 0.0128 - val_loss: 0.0768 - val_mse: 0.0733\n",
            "Epoch 62/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0161 - mse: 0.0126 - val_loss: 0.0706 - val_mse: 0.0670\n",
            "Epoch 63/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0165 - mse: 0.0129 - val_loss: 0.0705 - val_mse: 0.0669\n",
            "Epoch 64/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0171 - mse: 0.0135 - val_loss: 0.0747 - val_mse: 0.0711\n",
            "Epoch 65/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0159 - mse: 0.0123 - val_loss: 0.0772 - val_mse: 0.0736\n",
            "Epoch 66/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0171 - mse: 0.0135 - val_loss: 0.0717 - val_mse: 0.0680\n",
            "Epoch 67/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0161 - mse: 0.0124 - val_loss: 0.0682 - val_mse: 0.0646\n",
            "Epoch 68/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0171 - mse: 0.0135 - val_loss: 0.0752 - val_mse: 0.0715\n",
            "Epoch 69/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0156 - mse: 0.0119 - val_loss: 0.0841 - val_mse: 0.0804\n",
            "Epoch 70/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0159 - mse: 0.0122 - val_loss: 0.0754 - val_mse: 0.0717\n",
            "Epoch 71/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0161 - mse: 0.0123 - val_loss: 0.0777 - val_mse: 0.0740\n",
            "Epoch 72/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0153 - mse: 0.0116 - val_loss: 0.0837 - val_mse: 0.0800\n",
            "Epoch 73/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0159 - mse: 0.0122 - val_loss: 0.0770 - val_mse: 0.0733\n",
            "Epoch 74/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0154 - mse: 0.0116 - val_loss: 0.0792 - val_mse: 0.0754\n",
            "Epoch 75/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0152 - mse: 0.0115 - val_loss: 0.0681 - val_mse: 0.0643\n",
            "Epoch 76/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0156 - mse: 0.0119 - val_loss: 0.0807 - val_mse: 0.0770\n",
            "Epoch 77/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0152 - mse: 0.0114 - val_loss: 0.0828 - val_mse: 0.0790\n",
            "Epoch 78/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0150 - mse: 0.0112 - val_loss: 0.0774 - val_mse: 0.0736\n",
            "Epoch 79/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0157 - mse: 0.0120 - val_loss: 0.0793 - val_mse: 0.0756\n",
            "Epoch 80/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0151 - mse: 0.0114 - val_loss: 0.0784 - val_mse: 0.0746\n",
            "Epoch 81/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0154 - mse: 0.0116 - val_loss: 0.0755 - val_mse: 0.0717\n",
            "Epoch 82/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0147 - mse: 0.0109 - val_loss: 0.0783 - val_mse: 0.0745\n",
            "Epoch 83/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0148 - mse: 0.0110 - val_loss: 0.0761 - val_mse: 0.0723\n",
            "Epoch 84/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0146 - mse: 0.0109 - val_loss: 0.0781 - val_mse: 0.0743\n",
            "Epoch 85/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0145 - mse: 0.0107 - val_loss: 0.0700 - val_mse: 0.0661\n",
            "Epoch 86/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0147 - mse: 0.0109 - val_loss: 0.0792 - val_mse: 0.0753\n",
            "Epoch 87/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0151 - mse: 0.0113 - val_loss: 0.0764 - val_mse: 0.0726\n",
            "Epoch 88/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0145 - mse: 0.0106 - val_loss: 0.0801 - val_mse: 0.0763\n",
            "Epoch 89/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0144 - mse: 0.0105 - val_loss: 0.0711 - val_mse: 0.0672\n",
            "Epoch 90/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0146 - mse: 0.0108 - val_loss: 0.0751 - val_mse: 0.0713\n",
            "Epoch 91/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0143 - mse: 0.0104 - val_loss: 0.0779 - val_mse: 0.0741\n",
            "Epoch 92/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0150 - mse: 0.0112 - val_loss: 0.0819 - val_mse: 0.0780\n",
            "Epoch 93/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0145 - mse: 0.0107 - val_loss: 0.0741 - val_mse: 0.0703\n",
            "Epoch 94/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0152 - mse: 0.0113 - val_loss: 0.0839 - val_mse: 0.0801\n",
            "Epoch 95/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0143 - mse: 0.0104 - val_loss: 0.0750 - val_mse: 0.0711\n",
            "Epoch 96/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0138 - mse: 0.0100 - val_loss: 0.0824 - val_mse: 0.0785\n",
            "Epoch 97/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0144 - mse: 0.0105 - val_loss: 0.0767 - val_mse: 0.0729\n",
            "Epoch 98/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0144 - mse: 0.0105 - val_loss: 0.0758 - val_mse: 0.0719\n",
            "Epoch 99/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0145 - mse: 0.0106 - val_loss: 0.0831 - val_mse: 0.0792\n",
            "Epoch 100/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0140 - mse: 0.0101 - val_loss: 0.0795 - val_mse: 0.0756\n",
            "Epoch 101/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0145 - mse: 0.0106 - val_loss: 0.0754 - val_mse: 0.0715\n",
            "Epoch 101: early stopping\n",
            "Restoring model weights from the end of the best epoch: 96.\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-13-1585781058.py:17: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  rf = yf.download(rfa, start=di, end=df)\n",
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{np.int32(0): np.float32(0.1512632), np.int32(1): np.float32(0.1711451), np.int32(2): np.float32(0.0948973), np.int32(3): np.float32(0.10072819), np.int32(4): np.float32(0.07813552), np.int32(5): np.float32(0.25036502), np.int32(6): np.float32(0.26250622), np.int32(7): np.float32(0.33211157), np.int32(8): np.float32(0.28533337), np.int32(9): np.float32(0.21997581), np.int32(10): np.float32(0.25471005), np.int32(11): np.float32(0.14979477), np.int32(12): np.float32(0.08640613), np.int32(13): np.float32(0.12252486), np.int32(14): np.float32(0.17383558), np.int32(15): np.float32(0.07720914), np.int32(16): np.float32(0.0752753), np.int32(17): np.float32(0.17879713), np.int32(18): np.float32(0.19201577), np.int32(19): np.float32(0.068315946), np.int32(20): np.float32(0.29872409), np.int32(21): np.float32(0.2099932), np.int32(22): np.float32(0.09087213), np.int32(23): np.float32(0.08038288), np.int32(24): np.float32(0.20727195), np.int32(25): np.float32(0.25470528), np.int32(26): np.float32(0.19514519), np.int32(27): np.float32(0.057006575), np.int32(28): np.float32(0.124565214), np.int32(29): np.float32(0.065811194), np.int32(30): np.float32(0.11768432), np.int32(31): np.float32(0.21824233), np.int32(32): np.float32(0.08662892), np.int32(33): np.float32(0.22267906), np.int32(34): np.float32(0.09976098), np.int32(35): np.float32(0.10093216), np.int32(36): np.float32(0.08657836), np.int32(38): np.float32(0.33328378), np.int32(39): np.float32(0.098266385), np.int32(40): np.float32(0.34814593), np.int32(41): np.float32(0.053207286), np.int32(42): np.float32(2.0328429), np.int32(43): np.float32(0.19780874), np.int32(44): np.float32(0.183809), np.int32(45): np.float32(0.12173188), np.int32(46): np.float32(0.18762086), np.int32(47): np.float32(0.07587808), np.int32(48): np.float32(0.23214741), np.int32(49): np.float32(0.19702755), np.int32(50): np.float32(0.23119345), np.int32(51): np.float32(0.1055169), np.int32(52): np.float32(0.05801004), np.int32(53): np.float32(0.16072327), np.int32(54): np.float32(0.15685387), np.int32(55): np.float32(0.17351295), np.int32(56): np.float32(0.1331369), np.int32(57): np.float32(0.05430049), np.int32(58): np.float32(0.13073264), np.int32(59): np.float32(0.10112223), np.int32(60): np.float32(0.078077585), np.int32(61): np.float32(0.26104686), np.int32(62): np.float32(0.16586566), np.int32(63): np.float32(0.07545126), np.int32(64): np.float32(0.28383064), np.int32(65): np.float32(0.34726104), np.int32(66): np.float32(0.17973213), np.int32(67): np.float32(0.10657416), np.int32(68): np.float32(0.18798159), np.int32(69): np.float32(0.17722535), np.int32(70): np.float32(0.35107604), np.int32(71): np.float32(0.441668), np.int32(72): np.float32(0.08979008), np.int32(73): np.float32(0.057665434), np.int32(74): np.float32(0.5210122), np.int32(75): np.float32(0.33662802), np.int32(76): np.float32(0.109435745), np.int32(77): np.float32(0.22263516), np.int32(78): np.float32(0.069761164), np.int32(79): np.float32(0.1674513), np.int32(80): np.float32(0.22998738), np.int32(81): np.float32(0.04436667), np.int32(82): np.float32(0.14063016), np.int32(83): np.float32(0.17572655), np.int32(84): np.float32(0.06720971), np.int32(85): np.float32(0.31010664), np.int32(86): np.float32(0.31435224), np.int32(87): np.float32(0.1396961), np.int32(88): np.float32(0.23870689), np.int32(89): np.float32(0.19088477), np.int32(90): np.float32(0.17714618), np.int32(91): np.float32(0.0899155), np.int32(92): np.float32(0.12846155), np.int32(93): np.float32(0.091198936), np.int32(94): np.float32(0.049678273), np.int32(95): np.float32(0.18454023), np.int32(96): np.float32(0.055659596), np.int32(97): np.float32(0.124763064), np.int32(98): np.float32(0.22947292), np.int32(99): np.float32(0.15474166)}\n",
            "\n",
            "\n",
            "risk free return: 0.024185361237271705\n",
            "2019-10-17 2023-08-31\n",
            "2024-01-02\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "First trade made\n",
            "2024-03-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2024-05-10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "2024-07-17\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "2024-09-19\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2024-11-21\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2025-01-30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "2025-04-04\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_96bc6883-1926-40b3-bf35-c2f448b7c6f7\", \"2025-07-10_simulation_report_4.csv\", 7493)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max training day: 2023-08-31, min training day: 2019-10-17\n",
            "Epoch 1/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - loss: 0.0438 - mse: 0.0311 - val_loss: 0.0624 - val_mse: 0.0584\n",
            "Epoch 2/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0322 - mse: 0.0290 - val_loss: 0.0616 - val_mse: 0.0600\n",
            "Epoch 3/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0297 - mse: 0.0283 - val_loss: 0.0581 - val_mse: 0.0570\n",
            "Epoch 4/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0286 - mse: 0.0276 - val_loss: 0.0586 - val_mse: 0.0576\n",
            "Epoch 5/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0275 - mse: 0.0266 - val_loss: 0.0591 - val_mse: 0.0580\n",
            "Epoch 6/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0289 - mse: 0.0278 - val_loss: 0.0636 - val_mse: 0.0626\n",
            "Epoch 7/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0281 - mse: 0.0272 - val_loss: 0.0593 - val_mse: 0.0583\n",
            "Epoch 8/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0279 - mse: 0.0269 - val_loss: 0.0624 - val_mse: 0.0614\n",
            "Epoch 9/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0269 - mse: 0.0259 - val_loss: 0.0596 - val_mse: 0.0585\n",
            "Epoch 10/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0273 - mse: 0.0262 - val_loss: 0.0598 - val_mse: 0.0586\n",
            "Epoch 11/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0268 - mse: 0.0256 - val_loss: 0.0599 - val_mse: 0.0587\n",
            "Epoch 12/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0260 - mse: 0.0248 - val_loss: 0.0622 - val_mse: 0.0608\n",
            "Epoch 13/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0259 - mse: 0.0246 - val_loss: 0.0623 - val_mse: 0.0610\n",
            "Epoch 14/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0258 - mse: 0.0244 - val_loss: 0.0600 - val_mse: 0.0585\n",
            "Epoch 15/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0287 - mse: 0.0272 - val_loss: 0.0594 - val_mse: 0.0579\n",
            "Epoch 16/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0257 - mse: 0.0243 - val_loss: 0.0647 - val_mse: 0.0633\n",
            "Epoch 17/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0253 - mse: 0.0239 - val_loss: 0.0629 - val_mse: 0.0615\n",
            "Epoch 18/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0246 - mse: 0.0232 - val_loss: 0.0622 - val_mse: 0.0607\n",
            "Epoch 19/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0248 - mse: 0.0233 - val_loss: 0.0627 - val_mse: 0.0612\n",
            "Epoch 20/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0259 - mse: 0.0244 - val_loss: 0.0641 - val_mse: 0.0626\n",
            "Epoch 21/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0243 - mse: 0.0228 - val_loss: 0.0632 - val_mse: 0.0616\n",
            "Epoch 22/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0246 - mse: 0.0230 - val_loss: 0.0636 - val_mse: 0.0620\n",
            "Epoch 23/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0238 - mse: 0.0223 - val_loss: 0.0600 - val_mse: 0.0584\n",
            "Epoch 24/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0255 - mse: 0.0238 - val_loss: 0.0624 - val_mse: 0.0607\n",
            "Epoch 25/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0240 - mse: 0.0223 - val_loss: 0.0645 - val_mse: 0.0629\n",
            "Epoch 26/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0237 - mse: 0.0221 - val_loss: 0.0692 - val_mse: 0.0675\n",
            "Epoch 27/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0234 - mse: 0.0217 - val_loss: 0.0693 - val_mse: 0.0676\n",
            "Epoch 28/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0232 - mse: 0.0215 - val_loss: 0.0674 - val_mse: 0.0657\n",
            "Epoch 29/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0233 - mse: 0.0215 - val_loss: 0.0608 - val_mse: 0.0590\n",
            "Epoch 30/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0231 - mse: 0.0213 - val_loss: 0.0640 - val_mse: 0.0622\n",
            "Epoch 31/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0233 - mse: 0.0215 - val_loss: 0.0560 - val_mse: 0.0540\n",
            "Epoch 32/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - loss: 0.0263 - mse: 0.0243 - val_loss: 0.0655 - val_mse: 0.0635\n",
            "Epoch 33/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0252 - mse: 0.0232 - val_loss: 0.0598 - val_mse: 0.0578\n",
            "Epoch 34/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - loss: 0.0232 - mse: 0.0212 - val_loss: 0.0521 - val_mse: 0.0502\n",
            "Epoch 35/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 17ms/step - loss: 0.0227 - mse: 0.0207 - val_loss: 0.0598 - val_mse: 0.0578\n",
            "Epoch 36/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - loss: 0.0226 - mse: 0.0206 - val_loss: 0.0684 - val_mse: 0.0664\n",
            "Epoch 37/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 17ms/step - loss: 0.0225 - mse: 0.0205 - val_loss: 0.0638 - val_mse: 0.0618\n",
            "Epoch 38/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 17ms/step - loss: 0.0222 - mse: 0.0201 - val_loss: 0.0639 - val_mse: 0.0618\n",
            "Epoch 39/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0218 - mse: 0.0198 - val_loss: 0.0667 - val_mse: 0.0647\n",
            "Epoch 40/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0226 - mse: 0.0205 - val_loss: 0.0662 - val_mse: 0.0641\n",
            "Epoch 41/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0218 - mse: 0.0197 - val_loss: 0.0633 - val_mse: 0.0611\n",
            "Epoch 42/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0210 - mse: 0.0188 - val_loss: 0.0628 - val_mse: 0.0607\n",
            "Epoch 43/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0213 - mse: 0.0191 - val_loss: 0.0670 - val_mse: 0.0648\n",
            "Epoch 44/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0211 - mse: 0.0189 - val_loss: 0.0646 - val_mse: 0.0624\n",
            "Epoch 45/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0216 - mse: 0.0194 - val_loss: 0.0667 - val_mse: 0.0644\n",
            "Epoch 46/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0210 - mse: 0.0188 - val_loss: 0.0633 - val_mse: 0.0611\n",
            "Epoch 47/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0210 - mse: 0.0188 - val_loss: 0.0661 - val_mse: 0.0638\n",
            "Epoch 48/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0204 - mse: 0.0181 - val_loss: 0.0631 - val_mse: 0.0608\n",
            "Epoch 49/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0204 - mse: 0.0181 - val_loss: 0.0718 - val_mse: 0.0695\n",
            "Epoch 50/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0221 - mse: 0.0198 - val_loss: 0.0709 - val_mse: 0.0685\n",
            "Epoch 51/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0212 - mse: 0.0188 - val_loss: 0.0705 - val_mse: 0.0682\n",
            "Epoch 52/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0226 - mse: 0.0202 - val_loss: 0.0609 - val_mse: 0.0585\n",
            "Epoch 53/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0205 - mse: 0.0181 - val_loss: 0.0651 - val_mse: 0.0627\n",
            "Epoch 54/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0205 - mse: 0.0181 - val_loss: 0.0642 - val_mse: 0.0618\n",
            "Epoch 55/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0207 - mse: 0.0183 - val_loss: 0.0616 - val_mse: 0.0591\n",
            "Epoch 56/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0203 - mse: 0.0179 - val_loss: 0.0737 - val_mse: 0.0713\n",
            "Epoch 57/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0199 - mse: 0.0175 - val_loss: 0.0709 - val_mse: 0.0684\n",
            "Epoch 58/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0202 - mse: 0.0178 - val_loss: 0.0672 - val_mse: 0.0647\n",
            "Epoch 59/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0194 - mse: 0.0169 - val_loss: 0.0705 - val_mse: 0.0680\n",
            "Epoch 60/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0202 - mse: 0.0177 - val_loss: 0.0708 - val_mse: 0.0682\n",
            "Epoch 61/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0213 - mse: 0.0187 - val_loss: 0.0655 - val_mse: 0.0629\n",
            "Epoch 62/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0200 - mse: 0.0174 - val_loss: 0.0659 - val_mse: 0.0633\n",
            "Epoch 63/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0196 - mse: 0.0170 - val_loss: 0.0681 - val_mse: 0.0655\n",
            "Epoch 64/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0219 - mse: 0.0193 - val_loss: 0.0642 - val_mse: 0.0616\n",
            "Epoch 64: early stopping\n",
            "Restoring model weights from the end of the best epoch: 59.\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-13-1585781058.py:17: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  rf = yf.download(rfa, start=di, end=df)\n",
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{np.int32(0): np.float32(0.165394), np.int32(1): np.float32(0.09374992), np.int32(2): np.float32(0.06503086), np.int32(3): np.float32(0.056554392), np.int32(4): np.float32(0.05743986), np.int32(5): np.float32(0.25707486), np.int32(6): np.float32(0.22102587), np.int32(7): np.float32(0.11884689), np.int32(8): np.float32(0.30256817), np.int32(9): np.float32(0.15719679), np.int32(10): np.float32(0.21440321), np.int32(11): np.float32(0.09806352), np.int32(12): np.float32(0.077259704), np.int32(13): np.float32(0.07910905), np.int32(14): np.float32(0.1430611), np.int32(15): np.float32(0.13381778), np.int32(16): np.float32(0.032277647), np.int32(17): np.float32(0.14319468), np.int32(18): np.float32(0.1260808), np.int32(19): np.float32(0.09911246), np.int32(20): np.float32(0.28394672), np.int32(21): np.float32(0.10785769), np.int32(22): np.float32(0.2293467), np.int32(23): np.float32(0.0552788), np.int32(24): np.float32(0.11838135), np.int32(25): np.float32(0.30197698), np.int32(26): np.float32(0.12793587), np.int32(27): np.float32(0.09522706), np.int32(28): np.float32(0.097197644), np.int32(29): np.float32(0.1984638), np.int32(30): np.float32(0.062508956), np.int32(31): np.float32(0.14641905), np.int32(32): np.float32(0.12163953), np.int32(33): np.float32(0.1383293), np.int32(34): np.float32(0.050490387), np.int32(35): np.float32(0.06830279), np.int32(36): np.float32(0.0672229), np.int32(38): np.float32(0.30060133), np.int32(39): np.float32(0.12222967), np.int32(40): np.float32(0.31302083), np.int32(41): np.float32(0.07907372), np.int32(42): np.float32(2.0057685), np.int32(43): np.float32(0.09631236), np.int32(44): np.float32(0.1524397), np.int32(45): np.float32(0.08649289), np.int32(46): np.float32(0.047659222), np.int32(47): np.float32(0.060436964), np.int32(48): np.float32(0.2059205), np.int32(49): np.float32(0.064760655), np.int32(50): np.float32(0.22217253), np.int32(51): np.float32(0.06889095), np.int32(52): np.float32(0.07847265), np.int32(53): np.float32(0.10467692), np.int32(54): np.float32(0.08923235), np.int32(55): np.float32(0.098729864), np.int32(56): np.float32(0.15104067), np.int32(57): np.float32(0.049209125), np.int32(58): np.float32(0.1105624), np.int32(59): np.float32(0.09549005), np.int32(60): np.float32(0.051092226), np.int32(61): np.float32(0.21712716), np.int32(62): np.float32(0.08930436), np.int32(63): np.float32(0.07201543), np.int32(64): np.float32(0.25645044), np.int32(65): np.float32(0.2661878), np.int32(66): np.float32(0.15916307), np.int32(67): np.float32(0.044302817), np.int32(68): np.float32(0.1434685), np.int32(69): np.float32(0.026450913), np.int32(70): np.float32(0.3032419), np.int32(71): np.float32(0.33120793), np.int32(72): np.float32(0.09557194), np.int32(73): np.float32(0.13947377), np.int32(74): np.float32(0.4748592), np.int32(75): np.float32(0.3903438), np.int32(76): np.float32(0.07286927), np.int32(77): np.float32(0.27979514), np.int32(78): np.float32(0.1295545), np.int32(79): np.float32(0.15321846), np.int32(80): np.float32(0.13429065), np.int32(81): np.float32(0.039772406), np.int32(82): np.float32(0.12349752), np.int32(83): np.float32(0.17336413), np.int32(84): np.float32(0.06442817), np.int32(85): np.float32(0.3922595), np.int32(86): np.float32(0.32036272), np.int32(87): np.float32(0.16083033), np.int32(88): np.float32(0.10936178), np.int32(89): np.float32(0.063259), np.int32(90): np.float32(0.09096303), np.int32(91): np.float32(0.0886901), np.int32(92): np.float32(0.06137938), np.int32(93): np.float32(0.07165124), np.int32(94): np.float32(0.043836657), np.int32(95): np.float32(0.09736153), np.int32(96): np.float32(0.059065897), np.int32(97): np.float32(0.070330635), np.int32(98): np.float32(0.15903667), np.int32(99): np.float32(0.11278601)}\n",
            "\n",
            "\n",
            "risk free return: 0.024185361237271705\n",
            "2019-10-17 2023-08-31\n",
            "2024-01-02\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "First trade made\n",
            "2024-03-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "2024-05-10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2024-07-17\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2024-09-19\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2024-11-21\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2025-01-30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2025-04-04\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5f66caf6-4288-4036-8991-c0e3da3d0abc\", \"2025-07-10_simulation_report_5.csv\", 6082)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max training day: 2023-08-31, min training day: 2019-10-17\n",
            "Epoch 1/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - loss: 0.0440 - mse: 0.0307 - val_loss: 0.0608 - val_mse: 0.0559\n",
            "Epoch 2/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0332 - mse: 0.0293 - val_loss: 0.0604 - val_mse: 0.0584\n",
            "Epoch 3/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0302 - mse: 0.0286 - val_loss: 0.0593 - val_mse: 0.0582\n",
            "Epoch 4/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0288 - mse: 0.0278 - val_loss: 0.0585 - val_mse: 0.0575\n",
            "Epoch 5/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0285 - mse: 0.0275 - val_loss: 0.0597 - val_mse: 0.0588\n",
            "Epoch 6/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0280 - mse: 0.0270 - val_loss: 0.0625 - val_mse: 0.0613\n",
            "Epoch 7/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0277 - mse: 0.0266 - val_loss: 0.0601 - val_mse: 0.0590\n",
            "Epoch 8/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0284 - mse: 0.0272 - val_loss: 0.0604 - val_mse: 0.0592\n",
            "Epoch 9/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0267 - mse: 0.0255 - val_loss: 0.0616 - val_mse: 0.0603\n",
            "Epoch 10/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0258 - mse: 0.0245 - val_loss: 0.0621 - val_mse: 0.0607\n",
            "Epoch 11/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0258 - mse: 0.0244 - val_loss: 0.0609 - val_mse: 0.0594\n",
            "Epoch 12/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0258 - mse: 0.0243 - val_loss: 0.0609 - val_mse: 0.0594\n",
            "Epoch 13/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0245 - mse: 0.0230 - val_loss: 0.0617 - val_mse: 0.0601\n",
            "Epoch 14/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0261 - mse: 0.0244 - val_loss: 0.0650 - val_mse: 0.0632\n",
            "Epoch 15/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0244 - mse: 0.0227 - val_loss: 0.0630 - val_mse: 0.0613\n",
            "Epoch 16/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0243 - mse: 0.0226 - val_loss: 0.0639 - val_mse: 0.0622\n",
            "Epoch 17/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0235 - mse: 0.0218 - val_loss: 0.0621 - val_mse: 0.0603\n",
            "Epoch 18/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0237 - mse: 0.0220 - val_loss: 0.0661 - val_mse: 0.0642\n",
            "Epoch 19/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0238 - mse: 0.0219 - val_loss: 0.0634 - val_mse: 0.0616\n",
            "Epoch 20/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0231 - mse: 0.0212 - val_loss: 0.0618 - val_mse: 0.0599\n",
            "Epoch 21/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0227 - mse: 0.0208 - val_loss: 0.0652 - val_mse: 0.0632\n",
            "Epoch 22/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0242 - mse: 0.0222 - val_loss: 0.0657 - val_mse: 0.0637\n",
            "Epoch 23/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0225 - mse: 0.0205 - val_loss: 0.0611 - val_mse: 0.0590\n",
            "Epoch 24/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0220 - mse: 0.0199 - val_loss: 0.0671 - val_mse: 0.0650\n",
            "Epoch 25/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0225 - mse: 0.0203 - val_loss: 0.0667 - val_mse: 0.0645\n",
            "Epoch 26/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0240 - mse: 0.0217 - val_loss: 0.0665 - val_mse: 0.0643\n",
            "Epoch 27/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0221 - mse: 0.0198 - val_loss: 0.0655 - val_mse: 0.0633\n",
            "Epoch 28/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0211 - mse: 0.0188 - val_loss: 0.0692 - val_mse: 0.0669\n",
            "Epoch 29/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0215 - mse: 0.0192 - val_loss: 0.0694 - val_mse: 0.0670\n",
            "Epoch 30/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0209 - mse: 0.0185 - val_loss: 0.0714 - val_mse: 0.0689\n",
            "Epoch 31/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0214 - mse: 0.0189 - val_loss: 0.0666 - val_mse: 0.0641\n",
            "Epoch 32/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0213 - mse: 0.0188 - val_loss: 0.0728 - val_mse: 0.0702\n",
            "Epoch 33/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0207 - mse: 0.0181 - val_loss: 0.0714 - val_mse: 0.0688\n",
            "Epoch 34/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0200 - mse: 0.0173 - val_loss: 0.0719 - val_mse: 0.0692\n",
            "Epoch 35/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0210 - mse: 0.0183 - val_loss: 0.0678 - val_mse: 0.0650\n",
            "Epoch 36/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0203 - mse: 0.0175 - val_loss: 0.0729 - val_mse: 0.0701\n",
            "Epoch 37/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0193 - mse: 0.0165 - val_loss: 0.0738 - val_mse: 0.0710\n",
            "Epoch 38/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0190 - mse: 0.0162 - val_loss: 0.0713 - val_mse: 0.0684\n",
            "Epoch 39/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0188 - mse: 0.0159 - val_loss: 0.0722 - val_mse: 0.0693\n",
            "Epoch 40/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0186 - mse: 0.0157 - val_loss: 0.0758 - val_mse: 0.0728\n",
            "Epoch 41/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0186 - mse: 0.0156 - val_loss: 0.0762 - val_mse: 0.0732\n",
            "Epoch 42/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0181 - mse: 0.0151 - val_loss: 0.0791 - val_mse: 0.0761\n",
            "Epoch 43/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0178 - mse: 0.0147 - val_loss: 0.0730 - val_mse: 0.0699\n",
            "Epoch 44/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0180 - mse: 0.0148 - val_loss: 0.0790 - val_mse: 0.0759\n",
            "Epoch 45/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0189 - mse: 0.0158 - val_loss: 0.0736 - val_mse: 0.0704\n",
            "Epoch 46/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0179 - mse: 0.0147 - val_loss: 0.0788 - val_mse: 0.0757\n",
            "Epoch 47/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0178 - mse: 0.0146 - val_loss: 0.0712 - val_mse: 0.0680\n",
            "Epoch 48/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0172 - mse: 0.0140 - val_loss: 0.0791 - val_mse: 0.0760\n",
            "Epoch 49/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0182 - mse: 0.0150 - val_loss: 0.0771 - val_mse: 0.0739\n",
            "Epoch 50/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0172 - mse: 0.0139 - val_loss: 0.0711 - val_mse: 0.0679\n",
            "Epoch 51/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0186 - mse: 0.0154 - val_loss: 0.0718 - val_mse: 0.0685\n",
            "Epoch 52/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0202 - mse: 0.0169 - val_loss: 0.0787 - val_mse: 0.0754\n",
            "Epoch 53/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0174 - mse: 0.0141 - val_loss: 0.0747 - val_mse: 0.0714\n",
            "Epoch 54/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0167 - mse: 0.0134 - val_loss: 0.0735 - val_mse: 0.0702\n",
            "Epoch 55/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0165 - mse: 0.0131 - val_loss: 0.0791 - val_mse: 0.0758\n",
            "Epoch 56/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0205 - mse: 0.0171 - val_loss: 0.0802 - val_mse: 0.0769\n",
            "Epoch 57/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0166 - mse: 0.0132 - val_loss: 0.0739 - val_mse: 0.0706\n",
            "Epoch 58/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0164 - mse: 0.0130 - val_loss: 0.0711 - val_mse: 0.0676\n",
            "Epoch 59/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0163 - mse: 0.0128 - val_loss: 0.0718 - val_mse: 0.0684\n",
            "Epoch 60/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0166 - mse: 0.0132 - val_loss: 0.0755 - val_mse: 0.0720\n",
            "Epoch 61/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0159 - mse: 0.0125 - val_loss: 0.0774 - val_mse: 0.0740\n",
            "Epoch 62/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0155 - mse: 0.0121 - val_loss: 0.0764 - val_mse: 0.0730\n",
            "Epoch 63/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0152 - mse: 0.0118 - val_loss: 0.0790 - val_mse: 0.0756\n",
            "Epoch 64/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0156 - mse: 0.0122 - val_loss: 0.0744 - val_mse: 0.0710\n",
            "Epoch 65/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0156 - mse: 0.0121 - val_loss: 0.0796 - val_mse: 0.0762\n",
            "Epoch 66/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0159 - mse: 0.0124 - val_loss: 0.0800 - val_mse: 0.0765\n",
            "Epoch 67/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0156 - mse: 0.0121 - val_loss: 0.0817 - val_mse: 0.0782\n",
            "Epoch 68/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0153 - mse: 0.0118 - val_loss: 0.0743 - val_mse: 0.0708\n",
            "Epoch 69/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0159 - mse: 0.0124 - val_loss: 0.0811 - val_mse: 0.0776\n",
            "Epoch 70/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0154 - mse: 0.0119 - val_loss: 0.0819 - val_mse: 0.0783\n",
            "Epoch 71/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0154 - mse: 0.0118 - val_loss: 0.0782 - val_mse: 0.0747\n",
            "Epoch 72/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0151 - mse: 0.0116 - val_loss: 0.0766 - val_mse: 0.0731\n",
            "Epoch 73/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0153 - mse: 0.0117 - val_loss: 0.0755 - val_mse: 0.0719\n",
            "Epoch 74/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0157 - mse: 0.0121 - val_loss: 0.0795 - val_mse: 0.0759\n",
            "Epoch 75/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0150 - mse: 0.0114 - val_loss: 0.0738 - val_mse: 0.0702\n",
            "Epoch 76/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0143 - mse: 0.0107 - val_loss: 0.0760 - val_mse: 0.0724\n",
            "Epoch 77/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0147 - mse: 0.0111 - val_loss: 0.0809 - val_mse: 0.0773\n",
            "Epoch 78/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0161 - mse: 0.0125 - val_loss: 0.0767 - val_mse: 0.0731\n",
            "Epoch 79/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0143 - mse: 0.0107 - val_loss: 0.0730 - val_mse: 0.0694\n",
            "Epoch 80/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0143 - mse: 0.0106 - val_loss: 0.0750 - val_mse: 0.0713\n",
            "Epoch 81/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0143 - mse: 0.0107 - val_loss: 0.0741 - val_mse: 0.0705\n",
            "Epoch 81: early stopping\n",
            "Restoring model weights from the end of the best epoch: 76.\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-13-1585781058.py:17: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  rf = yf.download(rfa, start=di, end=df)\n",
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{np.int32(0): np.float32(0.2323987), np.int32(1): np.float32(0.048753984), np.int32(2): np.float32(0.06160405), np.int32(3): np.float32(0.056426454), np.int32(4): np.float32(0.053873442), np.int32(5): np.float32(0.20408446), np.int32(6): np.float32(0.21886334), np.int32(7): np.float32(0.06302984), np.int32(8): np.float32(0.23989715), np.int32(9): np.float32(0.19468987), np.int32(10): np.float32(0.20490834), np.int32(11): np.float32(0.08530365), np.int32(12): np.float32(0.12143223), np.int32(13): np.float32(0.11789931), np.int32(14): np.float32(0.2306831), np.int32(15): np.float32(0.12704314), np.int32(16): np.float32(0.11380592), np.int32(17): np.float32(0.1273778), np.int32(18): np.float32(0.07127861), np.int32(19): np.float32(0.08615474), np.int32(20): np.float32(0.27079475), np.int32(21): np.float32(0.08545203), np.int32(22): np.float32(0.12073406), np.int32(23): np.float32(0.05770719), np.int32(24): np.float32(0.13806051), np.int32(25): np.float32(0.31379303), np.int32(26): np.float32(0.19929728), np.int32(27): np.float32(0.07609268), np.int32(28): np.float32(0.08232155), np.int32(29): np.float32(0.23736306), np.int32(30): np.float32(0.2452123), np.int32(31): np.float32(0.14428996), np.int32(32): np.float32(0.017696274), np.int32(33): np.float32(0.084765345), np.int32(34): np.float32(0.04453499), np.int32(35): np.float32(0.032412276), np.int32(36): np.float32(0.110508725), np.int32(38): np.float32(0.5289253), np.int32(39): np.float32(0.049312517), np.int32(40): np.float32(0.33177075), np.int32(41): np.float32(0.26279286), np.int32(42): np.float32(1.9675136), np.int32(43): np.float32(0.26474887), np.int32(44): np.float32(0.13401291), np.int32(45): np.float32(0.0715331), np.int32(46): np.float32(0.05801932), np.int32(47): np.float32(0.10751603), np.int32(48): np.float32(0.23817496), np.int32(49): np.float32(0.18205525), np.int32(50): np.float32(0.33947447), np.int32(51): np.float32(0.085104674), np.int32(52): np.float32(0.041826542), np.int32(53): np.float32(0.08187324), np.int32(54): np.float32(0.17499651), np.int32(55): np.float32(0.1471097), np.int32(56): np.float32(0.095771335), np.int32(57): np.float32(0.040994246), np.int32(58): np.float32(0.17576575), np.int32(59): np.float32(0.20374388), np.int32(60): np.float32(0.027181981), np.int32(61): np.float32(0.17797196), np.int32(62): np.float32(0.076126724), np.int32(63): np.float32(0.113708764), np.int32(64): np.float32(0.22232097), np.int32(65): np.float32(0.27878395), np.int32(66): np.float32(0.19303976), np.int32(67): np.float32(0.0680272), np.int32(68): np.float32(0.111171946), np.int32(69): np.float32(0.067848995), np.int32(70): np.float32(0.30981478), np.int32(71): np.float32(0.2131435), np.int32(72): np.float32(0.17635146), np.int32(73): np.float32(0.0460558), np.int32(74): np.float32(0.57871205), np.int32(75): np.float32(0.2774137), np.int32(76): np.float32(0.10923572), np.int32(77): np.float32(0.20362699), np.int32(78): np.float32(0.078119434), np.int32(79): np.float32(0.3057876), np.int32(80): np.float32(0.089406915), np.int32(81): np.float32(0.08150168), np.int32(82): np.float32(0.14432131), np.int32(83): np.float32(0.15142304), np.int32(84): np.float32(0.055416908), np.int32(85): np.float32(0.3780583), np.int32(86): np.float32(0.24827121), np.int32(87): np.float32(0.26734492), np.int32(88): np.float32(0.092371956), np.int32(89): np.float32(0.16063683), np.int32(90): np.float32(0.105743766), np.int32(91): np.float32(0.094915494), np.int32(92): np.float32(0.035212178), np.int32(93): np.float32(0.09000253), np.int32(94): np.float32(0.11915709), np.int32(95): np.float32(0.2174453), np.int32(96): np.float32(0.07393562), np.int32(97): np.float32(0.0564391), np.int32(98): np.float32(0.1923423), np.int32(99): np.float32(0.114856295)}\n",
            "\n",
            "\n",
            "risk free return: 0.024185361237271705\n",
            "2019-10-17 2023-08-31\n",
            "2024-01-02\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "First trade made\n",
            "2024-03-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2024-05-10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "2024-07-17\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2024-09-19\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2024-11-21\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2025-01-30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2025-04-04\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7f8bc88f-7a70-4a22-ace5-382e9c841e70\", \"2025-07-10_simulation_report_6.csv\", 8915)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max training day: 2023-08-31, min training day: 2019-10-17\n",
            "Epoch 1/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - loss: 0.0428 - mse: 0.0307 - val_loss: 0.0600 - val_mse: 0.0564\n",
            "Epoch 2/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0319 - mse: 0.0291 - val_loss: 0.0574 - val_mse: 0.0561\n",
            "Epoch 3/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0300 - mse: 0.0288 - val_loss: 0.0580 - val_mse: 0.0570\n",
            "Epoch 4/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0288 - mse: 0.0279 - val_loss: 0.0580 - val_mse: 0.0571\n",
            "Epoch 5/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0277 - mse: 0.0268 - val_loss: 0.0607 - val_mse: 0.0598\n",
            "Epoch 6/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0272 - mse: 0.0262 - val_loss: 0.0597 - val_mse: 0.0588\n",
            "Epoch 7/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0277 - mse: 0.0268 - val_loss: 0.0592 - val_mse: 0.0582\n",
            "Epoch 8/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0274 - mse: 0.0263 - val_loss: 0.0567 - val_mse: 0.0556\n",
            "Epoch 9/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0268 - mse: 0.0257 - val_loss: 0.0562 - val_mse: 0.0550\n",
            "Epoch 10/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0265 - mse: 0.0254 - val_loss: 0.0608 - val_mse: 0.0596\n",
            "Epoch 11/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0263 - mse: 0.0251 - val_loss: 0.0614 - val_mse: 0.0601\n",
            "Epoch 12/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0266 - mse: 0.0252 - val_loss: 0.0624 - val_mse: 0.0611\n",
            "Epoch 13/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0265 - mse: 0.0251 - val_loss: 0.0659 - val_mse: 0.0645\n",
            "Epoch 14/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0255 - mse: 0.0241 - val_loss: 0.0590 - val_mse: 0.0576\n",
            "Epoch 15/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0252 - mse: 0.0238 - val_loss: 0.0623 - val_mse: 0.0608\n",
            "Epoch 16/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0250 - mse: 0.0234 - val_loss: 0.0593 - val_mse: 0.0578\n",
            "Epoch 17/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0259 - mse: 0.0243 - val_loss: 0.0598 - val_mse: 0.0580\n",
            "Epoch 18/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0263 - mse: 0.0245 - val_loss: 0.0622 - val_mse: 0.0604\n",
            "Epoch 19/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0256 - mse: 0.0239 - val_loss: 0.0623 - val_mse: 0.0606\n",
            "Epoch 20/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0254 - mse: 0.0237 - val_loss: 0.0633 - val_mse: 0.0616\n",
            "Epoch 21/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0251 - mse: 0.0234 - val_loss: 0.0636 - val_mse: 0.0618\n",
            "Epoch 22/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0243 - mse: 0.0226 - val_loss: 0.0633 - val_mse: 0.0616\n",
            "Epoch 23/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0245 - mse: 0.0227 - val_loss: 0.0655 - val_mse: 0.0636\n",
            "Epoch 24/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0249 - mse: 0.0230 - val_loss: 0.0632 - val_mse: 0.0613\n",
            "Epoch 25/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0235 - mse: 0.0216 - val_loss: 0.0633 - val_mse: 0.0614\n",
            "Epoch 26/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0236 - mse: 0.0216 - val_loss: 0.0642 - val_mse: 0.0622\n",
            "Epoch 27/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0231 - mse: 0.0211 - val_loss: 0.0658 - val_mse: 0.0638\n",
            "Epoch 28/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0248 - mse: 0.0228 - val_loss: 0.0625 - val_mse: 0.0603\n",
            "Epoch 29/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0237 - mse: 0.0216 - val_loss: 0.0655 - val_mse: 0.0633\n",
            "Epoch 30/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0247 - mse: 0.0225 - val_loss: 0.0638 - val_mse: 0.0615\n",
            "Epoch 31/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0240 - mse: 0.0217 - val_loss: 0.0635 - val_mse: 0.0612\n",
            "Epoch 32/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - loss: 0.0244 - mse: 0.0222 - val_loss: 0.0638 - val_mse: 0.0615\n",
            "Epoch 33/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - loss: 0.0228 - mse: 0.0205 - val_loss: 0.0658 - val_mse: 0.0635\n",
            "Epoch 34/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - loss: 0.0238 - mse: 0.0215 - val_loss: 0.0660 - val_mse: 0.0636\n",
            "Epoch 35/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - loss: 0.0229 - mse: 0.0205 - val_loss: 0.0617 - val_mse: 0.0593\n",
            "Epoch 36/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - loss: 0.0229 - mse: 0.0206 - val_loss: 0.0713 - val_mse: 0.0689\n",
            "Epoch 37/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0225 - mse: 0.0201 - val_loss: 0.0627 - val_mse: 0.0603\n",
            "Epoch 38/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0218 - mse: 0.0194 - val_loss: 0.0686 - val_mse: 0.0662\n",
            "Epoch 39/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0222 - mse: 0.0197 - val_loss: 0.0652 - val_mse: 0.0626\n",
            "Epoch 40/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0226 - mse: 0.0201 - val_loss: 0.0611 - val_mse: 0.0587\n",
            "Epoch 41/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0228 - mse: 0.0203 - val_loss: 0.0578 - val_mse: 0.0552\n",
            "Epoch 42/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0277 - mse: 0.0251 - val_loss: 0.0629 - val_mse: 0.0604\n",
            "Epoch 43/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0253 - mse: 0.0228 - val_loss: 0.0641 - val_mse: 0.0616\n",
            "Epoch 43: early stopping\n",
            "Restoring model weights from the end of the best epoch: 38.\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-13-1585781058.py:17: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  rf = yf.download(rfa, start=di, end=df)\n",
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{np.int32(0): np.float32(0.16382115), np.int32(1): np.float32(0.083545275), np.int32(2): np.float32(0.044866472), np.int32(3): np.float32(0.060196295), np.int32(4): np.float32(0.05611939), np.int32(5): np.float32(0.23105162), np.int32(6): np.float32(0.1934012), np.int32(7): np.float32(0.027796628), np.int32(8): np.float32(0.24199893), np.int32(9): np.float32(0.17815815), np.int32(10): np.float32(0.17827971), np.int32(11): np.float32(0.09133957), np.int32(12): np.float32(0.07768189), np.int32(13): np.float32(0.08950665), np.int32(14): np.float32(0.15357833), np.int32(15): np.float32(0.15241715), np.int32(16): np.float32(0.041295704), np.int32(17): np.float32(0.10554812), np.int32(18): np.float32(0.1450188), np.int32(19): np.float32(0.05351945), np.int32(20): np.float32(0.32554156), np.int32(21): np.float32(0.13427056), np.int32(22): np.float32(0.1465797), np.int32(23): np.float32(0.038506083), np.int32(24): np.float32(0.098548636), np.int32(25): np.float32(0.2646372), np.int32(26): np.float32(0.1711552), np.int32(27): np.float32(0.14810798), np.int32(28): np.float32(0.08275072), np.int32(29): np.float32(0.23416777), np.int32(30): np.float32(0.04883406), np.int32(31): np.float32(0.12836465), np.int32(32): np.float32(0.025302945), np.int32(33): np.float32(0.075755686), np.int32(34): np.float32(0.055202633), np.int32(35): np.float32(0.09732324), np.int32(36): np.float32(0.09537941), np.int32(38): np.float32(0.3190279), np.int32(39): np.float32(0.040257107), np.int32(40): np.float32(0.34069955), np.int32(41): np.float32(0.07551338), np.int32(42): np.float32(1.9550751), np.int32(43): np.float32(0.16711622), np.int32(44): np.float32(0.1786899), np.int32(45): np.float32(0.07607432), np.int32(46): np.float32(0.062027354), np.int32(47): np.float32(0.08373623), np.int32(48): np.float32(0.19893888), np.int32(49): np.float32(0.108891875), np.int32(50): np.float32(0.15187092), np.int32(51): np.float32(0.13334091), np.int32(52): np.float32(0.032504544), np.int32(53): np.float32(0.117901385), np.int32(54): np.float32(0.12608172), np.int32(55): np.float32(0.1251226), np.int32(56): np.float32(0.10294921), np.int32(57): np.float32(0.057674263), np.int32(58): np.float32(0.11493676), np.int32(59): np.float32(0.13922238), np.int32(60): np.float32(0.053583413), np.int32(61): np.float32(0.22023427), np.int32(62): np.float32(0.08976488), np.int32(63): np.float32(0.11440215), np.int32(64): np.float32(0.25490478), np.int32(65): np.float32(0.28651556), np.int32(66): np.float32(0.16667412), np.int32(67): np.float32(0.111869305), np.int32(68): np.float32(0.11097038), np.int32(69): np.float32(0.07225554), np.int32(70): np.float32(0.38074434), np.int32(71): np.float32(0.27319303), np.int32(72): np.float32(0.10053636), np.int32(73): np.float32(0.10638589), np.int32(74): np.float32(0.53277034), np.int32(75): np.float32(0.3844654), np.int32(76): np.float32(0.071235344), np.int32(77): np.float32(0.25625175), np.int32(78): np.float32(0.11636884), np.int32(79): np.float32(0.12385159), np.int32(80): np.float32(0.1305614), np.int32(81): np.float32(0.061009932), np.int32(82): np.float32(0.13149673), np.int32(83): np.float32(0.10902788), np.int32(84): np.float32(0.070203856), np.int32(85): np.float32(0.3559441), np.int32(86): np.float32(0.24070339), np.int32(87): np.float32(0.1838687), np.int32(88): np.float32(0.10481606), np.int32(89): np.float32(0.14168155), np.int32(90): np.float32(0.094979085), np.int32(91): np.float32(0.0876556), np.int32(92): np.float32(0.090488456), np.int32(93): np.float32(0.110071205), np.int32(94): np.float32(0.08053215), np.int32(95): np.float32(0.2016205), np.int32(96): np.float32(0.048499044), np.int32(97): np.float32(0.061706133), np.int32(98): np.float32(0.17423843), np.int32(99): np.float32(0.13189821)}\n",
            "\n",
            "\n",
            "risk free return: 0.024185361237271705\n",
            "2019-10-17 2023-08-31\n",
            "2024-01-02\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "First trade made\n",
            "2024-03-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2024-05-10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2024-07-17\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "2024-09-19\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "2024-11-21\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2025-01-30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2025-04-04\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8ff6d689-e9df-4efc-b70c-649cfc20b6d9\", \"2025-07-10_simulation_report_7.csv\", 2014)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max training day: 2023-08-31, min training day: 2019-10-17\n",
            "Epoch 1/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - loss: 0.0437 - mse: 0.0306 - val_loss: 0.0646 - val_mse: 0.0600\n",
            "Epoch 2/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0333 - mse: 0.0296 - val_loss: 0.0614 - val_mse: 0.0597\n",
            "Epoch 3/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0301 - mse: 0.0286 - val_loss: 0.0595 - val_mse: 0.0585\n",
            "Epoch 4/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0292 - mse: 0.0282 - val_loss: 0.0584 - val_mse: 0.0575\n",
            "Epoch 5/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0283 - mse: 0.0274 - val_loss: 0.0640 - val_mse: 0.0632\n",
            "Epoch 6/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0282 - mse: 0.0273 - val_loss: 0.0591 - val_mse: 0.0582\n",
            "Epoch 7/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0280 - mse: 0.0270 - val_loss: 0.0597 - val_mse: 0.0587\n",
            "Epoch 8/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0272 - mse: 0.0262 - val_loss: 0.0601 - val_mse: 0.0591\n",
            "Epoch 9/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0277 - mse: 0.0266 - val_loss: 0.0584 - val_mse: 0.0573\n",
            "Epoch 10/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0268 - mse: 0.0257 - val_loss: 0.0630 - val_mse: 0.0619\n",
            "Epoch 11/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0267 - mse: 0.0255 - val_loss: 0.0607 - val_mse: 0.0595\n",
            "Epoch 12/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0288 - mse: 0.0275 - val_loss: 0.0643 - val_mse: 0.0630\n",
            "Epoch 13/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0274 - mse: 0.0261 - val_loss: 0.0638 - val_mse: 0.0625\n",
            "Epoch 14/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0256 - mse: 0.0244 - val_loss: 0.0635 - val_mse: 0.0622\n",
            "Epoch 15/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0268 - mse: 0.0254 - val_loss: 0.0599 - val_mse: 0.0585\n",
            "Epoch 16/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0257 - mse: 0.0243 - val_loss: 0.0647 - val_mse: 0.0634\n",
            "Epoch 17/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0249 - mse: 0.0236 - val_loss: 0.0633 - val_mse: 0.0619\n",
            "Epoch 18/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0249 - mse: 0.0235 - val_loss: 0.0595 - val_mse: 0.0580\n",
            "Epoch 19/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0259 - mse: 0.0244 - val_loss: 0.0609 - val_mse: 0.0594\n",
            "Epoch 20/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0251 - mse: 0.0236 - val_loss: 0.0606 - val_mse: 0.0591\n",
            "Epoch 21/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0248 - mse: 0.0233 - val_loss: 0.0600 - val_mse: 0.0584\n",
            "Epoch 22/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0258 - mse: 0.0242 - val_loss: 0.0622 - val_mse: 0.0606\n",
            "Epoch 23/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0245 - mse: 0.0230 - val_loss: 0.0616 - val_mse: 0.0601\n",
            "Epoch 24/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0242 - mse: 0.0226 - val_loss: 0.0616 - val_mse: 0.0599\n",
            "Epoch 25/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0240 - mse: 0.0224 - val_loss: 0.0616 - val_mse: 0.0599\n",
            "Epoch 26/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0247 - mse: 0.0230 - val_loss: 0.0621 - val_mse: 0.0604\n",
            "Epoch 27/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0240 - mse: 0.0223 - val_loss: 0.0633 - val_mse: 0.0615\n",
            "Epoch 28/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0232 - mse: 0.0215 - val_loss: 0.0664 - val_mse: 0.0644\n",
            "Epoch 29/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0236 - mse: 0.0216 - val_loss: 0.0662 - val_mse: 0.0643\n",
            "Epoch 30/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0228 - mse: 0.0209 - val_loss: 0.0650 - val_mse: 0.0631\n",
            "Epoch 31/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0227 - mse: 0.0208 - val_loss: 0.0654 - val_mse: 0.0634\n",
            "Epoch 32/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0223 - mse: 0.0203 - val_loss: 0.0660 - val_mse: 0.0640\n",
            "Epoch 33/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0232 - mse: 0.0211 - val_loss: 0.0473 - val_mse: 0.0452\n",
            "Epoch 34/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0226 - mse: 0.0205 - val_loss: 0.0668 - val_mse: 0.0647\n",
            "Epoch 35/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0216 - mse: 0.0195 - val_loss: 0.0665 - val_mse: 0.0643\n",
            "Epoch 36/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0217 - mse: 0.0195 - val_loss: 0.0696 - val_mse: 0.0674\n",
            "Epoch 37/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0214 - mse: 0.0192 - val_loss: 0.0633 - val_mse: 0.0610\n",
            "Epoch 38/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0226 - mse: 0.0204 - val_loss: 0.0654 - val_mse: 0.0631\n",
            "Epoch 39/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0219 - mse: 0.0196 - val_loss: 0.0663 - val_mse: 0.0639\n",
            "Epoch 40/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0208 - mse: 0.0184 - val_loss: 0.0644 - val_mse: 0.0621\n",
            "Epoch 41/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0225 - mse: 0.0201 - val_loss: 0.0695 - val_mse: 0.0671\n",
            "Epoch 42/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0204 - mse: 0.0180 - val_loss: 0.0696 - val_mse: 0.0672\n",
            "Epoch 43/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0236 - mse: 0.0211 - val_loss: 0.0684 - val_mse: 0.0658\n",
            "Epoch 44/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0224 - mse: 0.0198 - val_loss: 0.0638 - val_mse: 0.0612\n",
            "Epoch 45/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0206 - mse: 0.0180 - val_loss: 0.0685 - val_mse: 0.0659\n",
            "Epoch 46/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0208 - mse: 0.0182 - val_loss: 0.0687 - val_mse: 0.0662\n",
            "Epoch 47/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0223 - mse: 0.0197 - val_loss: 0.0648 - val_mse: 0.0622\n",
            "Epoch 48/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0198 - mse: 0.0172 - val_loss: 0.0766 - val_mse: 0.0740\n",
            "Epoch 49/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0207 - mse: 0.0181 - val_loss: 0.0699 - val_mse: 0.0673\n",
            "Epoch 50/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0193 - mse: 0.0166 - val_loss: 0.0702 - val_mse: 0.0676\n",
            "Epoch 51/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0200 - mse: 0.0174 - val_loss: 0.0701 - val_mse: 0.0674\n",
            "Epoch 52/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0190 - mse: 0.0164 - val_loss: 0.0757 - val_mse: 0.0731\n",
            "Epoch 53/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0196 - mse: 0.0169 - val_loss: 0.0750 - val_mse: 0.0723\n",
            "Epoch 54/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0196 - mse: 0.0168 - val_loss: 0.0721 - val_mse: 0.0694\n",
            "Epoch 55/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0194 - mse: 0.0167 - val_loss: 0.0775 - val_mse: 0.0747\n",
            "Epoch 56/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0192 - mse: 0.0164 - val_loss: 0.0737 - val_mse: 0.0709\n",
            "Epoch 57/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0194 - mse: 0.0167 - val_loss: 0.0743 - val_mse: 0.0715\n",
            "Epoch 58/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - loss: 0.0184 - mse: 0.0156 - val_loss: 0.0674 - val_mse: 0.0646\n",
            "Epoch 59/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - loss: 0.0187 - mse: 0.0159 - val_loss: 0.0715 - val_mse: 0.0687\n",
            "Epoch 60/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - loss: 0.0183 - mse: 0.0155 - val_loss: 0.0766 - val_mse: 0.0735\n",
            "Epoch 61/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - loss: 0.0184 - mse: 0.0154 - val_loss: 0.0775 - val_mse: 0.0745\n",
            "Epoch 62/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0181 - mse: 0.0152 - val_loss: 0.0625 - val_mse: 0.0596\n",
            "Epoch 63/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0179 - mse: 0.0150 - val_loss: 0.0620 - val_mse: 0.0590\n",
            "Epoch 64/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0175 - mse: 0.0146 - val_loss: 0.0634 - val_mse: 0.0604\n",
            "Epoch 65/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0178 - mse: 0.0149 - val_loss: 0.0719 - val_mse: 0.0689\n",
            "Epoch 66/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0175 - mse: 0.0146 - val_loss: 0.0755 - val_mse: 0.0725\n",
            "Epoch 67/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0173 - mse: 0.0143 - val_loss: 0.0758 - val_mse: 0.0728\n",
            "Epoch 68/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0174 - mse: 0.0144 - val_loss: 0.0737 - val_mse: 0.0707\n",
            "Epoch 69/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0202 - mse: 0.0172 - val_loss: 0.0582 - val_mse: 0.0552\n",
            "Epoch 70/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0174 - mse: 0.0144 - val_loss: 0.0603 - val_mse: 0.0573\n",
            "Epoch 71/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0171 - mse: 0.0141 - val_loss: 0.0636 - val_mse: 0.0605\n",
            "Epoch 72/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0168 - mse: 0.0138 - val_loss: 0.0666 - val_mse: 0.0636\n",
            "Epoch 73/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0166 - mse: 0.0135 - val_loss: 0.0647 - val_mse: 0.0616\n",
            "Epoch 74/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0177 - mse: 0.0146 - val_loss: 0.0634 - val_mse: 0.0604\n",
            "Epoch 75/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0174 - mse: 0.0143 - val_loss: 0.0703 - val_mse: 0.0672\n",
            "Epoch 76/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0163 - mse: 0.0132 - val_loss: 0.0624 - val_mse: 0.0593\n",
            "Epoch 77/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0169 - mse: 0.0138 - val_loss: 0.0660 - val_mse: 0.0628\n",
            "Epoch 78/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0169 - mse: 0.0138 - val_loss: 0.0626 - val_mse: 0.0595\n",
            "Epoch 79/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0198 - mse: 0.0166 - val_loss: 0.0565 - val_mse: 0.0533\n",
            "Epoch 80/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0161 - mse: 0.0129 - val_loss: 0.0617 - val_mse: 0.0586\n",
            "Epoch 81/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0159 - mse: 0.0128 - val_loss: 0.0736 - val_mse: 0.0704\n",
            "Epoch 82/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0169 - mse: 0.0138 - val_loss: 0.0732 - val_mse: 0.0700\n",
            "Epoch 83/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0160 - mse: 0.0128 - val_loss: 0.0664 - val_mse: 0.0632\n",
            "Epoch 84/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0158 - mse: 0.0127 - val_loss: 0.0691 - val_mse: 0.0659\n",
            "Epoch 85/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0161 - mse: 0.0129 - val_loss: 0.0656 - val_mse: 0.0624\n",
            "Epoch 86/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0157 - mse: 0.0125 - val_loss: 0.0674 - val_mse: 0.0641\n",
            "Epoch 87/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0161 - mse: 0.0128 - val_loss: 0.0596 - val_mse: 0.0564\n",
            "Epoch 88/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0154 - mse: 0.0122 - val_loss: 0.0604 - val_mse: 0.0571\n",
            "Epoch 89/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0156 - mse: 0.0123 - val_loss: 0.0683 - val_mse: 0.0650\n",
            "Epoch 90/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0161 - mse: 0.0128 - val_loss: 0.0652 - val_mse: 0.0620\n",
            "Epoch 91/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0157 - mse: 0.0125 - val_loss: 0.0756 - val_mse: 0.0723\n",
            "Epoch 92/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0157 - mse: 0.0124 - val_loss: 0.0660 - val_mse: 0.0627\n",
            "Epoch 93/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0161 - mse: 0.0128 - val_loss: 0.0577 - val_mse: 0.0544\n",
            "Epoch 94/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0154 - mse: 0.0121 - val_loss: 0.0727 - val_mse: 0.0695\n",
            "Epoch 95/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0157 - mse: 0.0124 - val_loss: 0.0746 - val_mse: 0.0713\n",
            "Epoch 96/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0157 - mse: 0.0124 - val_loss: 0.0642 - val_mse: 0.0609\n",
            "Epoch 97/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0156 - mse: 0.0123 - val_loss: 0.0535 - val_mse: 0.0502\n",
            "Epoch 98/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0153 - mse: 0.0120 - val_loss: 0.0626 - val_mse: 0.0593\n",
            "Epoch 99/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0157 - mse: 0.0123 - val_loss: 0.0621 - val_mse: 0.0588\n",
            "Epoch 100/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0152 - mse: 0.0119 - val_loss: 0.0608 - val_mse: 0.0575\n",
            "Epoch 101/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0152 - mse: 0.0119 - val_loss: 0.0591 - val_mse: 0.0558\n",
            "Epoch 102/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0152 - mse: 0.0118 - val_loss: 0.0770 - val_mse: 0.0737\n",
            "Epoch 103/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0152 - mse: 0.0119 - val_loss: 0.0609 - val_mse: 0.0575\n",
            "Epoch 104/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0152 - mse: 0.0119 - val_loss: 0.0756 - val_mse: 0.0723\n",
            "Epoch 105/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0151 - mse: 0.0118 - val_loss: 0.0563 - val_mse: 0.0530\n",
            "Epoch 106/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0157 - mse: 0.0124 - val_loss: 0.0605 - val_mse: 0.0572\n",
            "Epoch 107/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0147 - mse: 0.0113 - val_loss: 0.0576 - val_mse: 0.0542\n",
            "Epoch 108/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0162 - mse: 0.0129 - val_loss: 0.0747 - val_mse: 0.0713\n",
            "Epoch 109/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0150 - mse: 0.0117 - val_loss: 0.0633 - val_mse: 0.0599\n",
            "Epoch 110/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0153 - mse: 0.0119 - val_loss: 0.0703 - val_mse: 0.0669\n",
            "Epoch 111/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0152 - mse: 0.0118 - val_loss: 0.0475 - val_mse: 0.0440\n",
            "Epoch 112/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0168 - mse: 0.0134 - val_loss: 0.0731 - val_mse: 0.0697\n",
            "Epoch 112: early stopping\n",
            "Restoring model weights from the end of the best epoch: 107.\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-13-1585781058.py:17: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  rf = yf.download(rfa, start=di, end=df)\n",
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{np.int32(0): np.float32(0.14577681), np.int32(1): np.float32(0.13057084), np.int32(2): np.float32(0.13838351), np.int32(3): np.float32(0.05281755), np.int32(4): np.float32(0.042928584), np.int32(5): np.float32(0.23566693), np.int32(6): np.float32(0.25586995), np.int32(7): np.float32(0.025186611), np.int32(8): np.float32(0.19224907), np.int32(9): np.float32(0.17736931), np.int32(10): np.float32(0.20426875), np.int32(11): np.float32(0.0707293), np.int32(12): np.float32(0.14105573), np.int32(13): np.float32(0.097953066), np.int32(14): np.float32(0.17159387), np.int32(15): np.float32(0.06171441), np.int32(16): np.float32(0.040934302), np.int32(17): np.float32(0.11929461), np.int32(18): np.float32(0.075471334), np.int32(19): np.float32(0.046033643), np.int32(20): np.float32(0.25501776), np.int32(21): np.float32(0.15483958), np.int32(22): np.float32(0.29057544), np.int32(23): np.float32(0.11051201), np.int32(24): np.float32(0.15645972), np.int32(25): np.float32(0.2567248), np.int32(26): np.float32(0.26646978), np.int32(27): np.float32(0.14146625), np.int32(28): np.float32(0.14438054), np.int32(29): np.float32(0.08359285), np.int32(30): np.float32(0.39267525), np.int32(31): np.float32(0.17764266), np.int32(32): np.float32(0.05252055), np.int32(33): np.float32(0.10260314), np.int32(34): np.float32(0.031679794), np.int32(35): np.float32(0.111881346), np.int32(36): np.float32(0.10888147), np.int32(38): np.float32(0.28827032), np.int32(39): np.float32(0.14649582), np.int32(40): np.float32(0.40931898), np.int32(41): np.float32(0.077655055), np.int32(42): np.float32(1.2719203), np.int32(43): np.float32(0.34694245), np.int32(44): np.float32(0.2549915), np.int32(45): np.float32(0.13749589), np.int32(46): np.float32(0.10248724), np.int32(47): np.float32(0.064789996), np.int32(48): np.float32(0.24763817), np.int32(49): np.float32(0.060792107), np.int32(50): np.float32(0.18038362), np.int32(51): np.float32(0.045449715), np.int32(52): np.float32(0.065467164), np.int32(53): np.float32(0.12742452), np.int32(54): np.float32(0.12772092), np.int32(55): np.float32(0.14712591), np.int32(56): np.float32(0.075848706), np.int32(57): np.float32(0.04039519), np.int32(58): np.float32(0.18626827), np.int32(59): np.float32(0.21608947), np.int32(60): np.float32(0.019880535), np.int32(61): np.float32(0.2409955), np.int32(62): np.float32(0.09442514), np.int32(63): np.float32(0.146263), np.int32(64): np.float32(0.25769562), np.int32(65): np.float32(0.27362764), np.int32(66): np.float32(0.17959896), np.int32(67): np.float32(0.052660465), np.int32(68): np.float32(0.1307478), np.int32(69): np.float32(0.15708336), np.int32(70): np.float32(0.37558874), np.int32(71): np.float32(0.31769365), np.int32(72): np.float32(0.13267413), np.int32(73): np.float32(0.2804939), np.int32(74): np.float32(0.49520394), np.int32(75): np.float32(0.5324903), np.int32(76): np.float32(0.036547184), np.int32(77): np.float32(0.27242473), np.int32(78): np.float32(0.122422196), np.int32(79): np.float32(0.19139682), np.int32(80): np.float32(0.08015159), np.int32(81): np.float32(0.044143587), np.int32(82): np.float32(0.31347466), np.int32(83): np.float32(0.0946369), np.int32(84): np.float32(0.084681265), np.int32(85): np.float32(0.35148206), np.int32(86): np.float32(0.347378), np.int32(87): np.float32(0.2005835), np.int32(88): np.float32(0.21931203), np.int32(89): np.float32(0.19030483), np.int32(90): np.float32(0.2495439), np.int32(91): np.float32(0.08219045), np.int32(92): np.float32(0.07280923), np.int32(93): np.float32(0.08466173), np.int32(94): np.float32(0.054106575), np.int32(95): np.float32(0.17566445), np.int32(96): np.float32(0.09543548), np.int32(97): np.float32(0.052506253), np.int32(98): np.float32(0.27691492), np.int32(99): np.float32(0.08578825)}\n",
            "\n",
            "\n",
            "risk free return: 0.024185361237271705\n",
            "2019-10-17 2023-08-31\n",
            "2024-01-02\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "First trade made\n",
            "2024-03-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "2024-05-10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2024-07-17\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "2024-09-19\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2024-11-21\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2025-01-30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2025-04-04\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8dcf057f-897a-4d22-9a6a-df070eceec81\", \"2025-07-10_simulation_report_8.csv\", 8529)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max training day: 2023-08-31, min training day: 2019-10-17\n",
            "Epoch 1/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - loss: 0.0451 - mse: 0.0313 - val_loss: 0.0637 - val_mse: 0.0586\n",
            "Epoch 2/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0332 - mse: 0.0291 - val_loss: 0.0597 - val_mse: 0.0576\n",
            "Epoch 3/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0301 - mse: 0.0283 - val_loss: 0.0591 - val_mse: 0.0578\n",
            "Epoch 4/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0295 - mse: 0.0283 - val_loss: 0.0607 - val_mse: 0.0596\n",
            "Epoch 5/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0286 - mse: 0.0276 - val_loss: 0.0605 - val_mse: 0.0594\n",
            "Epoch 6/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0272 - mse: 0.0262 - val_loss: 0.0585 - val_mse: 0.0574\n",
            "Epoch 7/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0276 - mse: 0.0265 - val_loss: 0.0641 - val_mse: 0.0629\n",
            "Epoch 8/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0284 - mse: 0.0272 - val_loss: 0.0576 - val_mse: 0.0564\n",
            "Epoch 9/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0269 - mse: 0.0256 - val_loss: 0.0610 - val_mse: 0.0596\n",
            "Epoch 10/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0278 - mse: 0.0264 - val_loss: 0.0602 - val_mse: 0.0588\n",
            "Epoch 11/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0265 - mse: 0.0250 - val_loss: 0.0625 - val_mse: 0.0608\n",
            "Epoch 12/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0260 - mse: 0.0243 - val_loss: 0.0599 - val_mse: 0.0582\n",
            "Epoch 13/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0264 - mse: 0.0246 - val_loss: 0.0588 - val_mse: 0.0572\n",
            "Epoch 14/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0256 - mse: 0.0239 - val_loss: 0.0625 - val_mse: 0.0607\n",
            "Epoch 15/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0274 - mse: 0.0256 - val_loss: 0.0632 - val_mse: 0.0614\n",
            "Epoch 16/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0262 - mse: 0.0244 - val_loss: 0.0551 - val_mse: 0.0533\n",
            "Epoch 17/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0248 - mse: 0.0230 - val_loss: 0.0542 - val_mse: 0.0523\n",
            "Epoch 18/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0246 - mse: 0.0228 - val_loss: 0.0632 - val_mse: 0.0613\n",
            "Epoch 19/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0235 - mse: 0.0215 - val_loss: 0.0575 - val_mse: 0.0555\n",
            "Epoch 20/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - loss: 0.0228 - mse: 0.0209 - val_loss: 0.0603 - val_mse: 0.0583\n",
            "Epoch 21/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0256 - mse: 0.0235 - val_loss: 0.0536 - val_mse: 0.0514\n",
            "Epoch 22/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0237 - mse: 0.0215 - val_loss: 0.0617 - val_mse: 0.0596\n",
            "Epoch 23/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0231 - mse: 0.0209 - val_loss: 0.0599 - val_mse: 0.0578\n",
            "Epoch 24/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0228 - mse: 0.0207 - val_loss: 0.0593 - val_mse: 0.0571\n",
            "Epoch 25/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0230 - mse: 0.0208 - val_loss: 0.0621 - val_mse: 0.0599\n",
            "Epoch 26/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0226 - mse: 0.0203 - val_loss: 0.0628 - val_mse: 0.0605\n",
            "Epoch 27/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0235 - mse: 0.0211 - val_loss: 0.0627 - val_mse: 0.0603\n",
            "Epoch 28/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0225 - mse: 0.0202 - val_loss: 0.0574 - val_mse: 0.0550\n",
            "Epoch 29/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0221 - mse: 0.0197 - val_loss: 0.0645 - val_mse: 0.0620\n",
            "Epoch 30/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0220 - mse: 0.0196 - val_loss: 0.0553 - val_mse: 0.0528\n",
            "Epoch 31/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0215 - mse: 0.0190 - val_loss: 0.0592 - val_mse: 0.0566\n",
            "Epoch 32/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0240 - mse: 0.0214 - val_loss: 0.0611 - val_mse: 0.0585\n",
            "Epoch 33/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0216 - mse: 0.0191 - val_loss: 0.0623 - val_mse: 0.0598\n",
            "Epoch 34/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0211 - mse: 0.0186 - val_loss: 0.0597 - val_mse: 0.0571\n",
            "Epoch 35/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0221 - mse: 0.0194 - val_loss: 0.0628 - val_mse: 0.0601\n",
            "Epoch 36/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0203 - mse: 0.0177 - val_loss: 0.0631 - val_mse: 0.0604\n",
            "Epoch 37/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0200 - mse: 0.0173 - val_loss: 0.0655 - val_mse: 0.0628\n",
            "Epoch 38/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0216 - mse: 0.0188 - val_loss: 0.0635 - val_mse: 0.0606\n",
            "Epoch 39/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0265 - mse: 0.0237 - val_loss: 0.0682 - val_mse: 0.0655\n",
            "Epoch 40/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0207 - mse: 0.0180 - val_loss: 0.0683 - val_mse: 0.0656\n",
            "Epoch 41/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0199 - mse: 0.0172 - val_loss: 0.0668 - val_mse: 0.0640\n",
            "Epoch 42/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0197 - mse: 0.0169 - val_loss: 0.0657 - val_mse: 0.0628\n",
            "Epoch 42: early stopping\n",
            "Restoring model weights from the end of the best epoch: 37.\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "{np.int32(0): np.float32(0.15582693), np.int32(1): np.float32(0.05180538), np.int32(2): np.float32(0.048806716), np.int32(3): np.float32(0.04661373), np.int32(4): np.float32(0.088536106), np.int32(5): np.float32(0.20428154), np.int32(6): np.float32(0.16378453), np.int32(7): np.float32(0.02486474), np.int32(8): np.float32(0.21460618), np.int32(9): np.float32(0.17757268), np.int32(10): np.float32(0.18793653), np.int32(11): np.float32(0.09806429), np.int32(12): np.float32(0.067237884), np.int32(13): np.float32(0.16971682), np.int32(14): np.float32(0.12989677), np.int32(15): np.float32(0.13485318), np.int32(16): np.float32(0.04381637), np.int32(17): np.float32(0.13372274), np.int32(18): np.float32(0.10721337), np.int32(19): np.float32(0.08835793), np.int32(20): np.float32(0.2750788), np.int32(21): np.float32(0.096321926), np.int32(22): np.float32(0.11629849), np.int32(23): np.float32(0.029641744), np.int32(24): np.float32(0.10379475), np.int32(25): np.float32(0.25459605), np.int32(26): np.float32(0.09756253), np.int32(27): np.float32(0.05586839), np.int32(28): np.float32(0.07457407), np.int32(29): np.float32(0.13864948), np.int32(30): np.float32(0.05331027), np.int32(31): np.float32(0.10083116), np.int32(32): np.float32(0.030929511), np.int32(33): np.float32(0.121133), np.int32(34): np.float32(0.025917698), np.int32(35): np.float32(0.07355503), np.int32(36): np.float32(0.12519684), np.int32(38): np.float32(0.33005533), np.int32(39): np.float32(0.08158898), np.int32(40): np.float32(0.35537934), np.int32(41): np.float32(0.17851655), np.int32(42): np.float32(1.9230645), np.int32(43): np.float32(0.21255353), np.int32(44): np.float32(0.16645455), np.int32(45): np.float32(0.07164441), np.int32(46): np.float32(0.048337836), np.int32(47): np.float32(0.16608183), np.int32(48): np.float32(0.20046921), np.int32(49): np.float32(0.07368585), np.int32(50): np.float32(0.13305722), np.int32(51): np.float32(0.055504963), np.int32(52): np.float32(0.06117216), np.int32(53): np.float32(0.09757194), np.int32(54): np.float32(0.090575), np.int32(55): np.float32(0.14218126), np.int32(56): np.float32(0.09708665), np.int32(57): np.float32(0.058476064), np.int32(58): np.float32(0.095885344), np.int32(59): np.float32(0.12237112), np.int32(60): np.float32(0.09008755), np.int32(61): np.float32(0.23446381), np.int32(62): np.float32(0.064707145), np.int32(63): np.float32(0.11263346), np.int32(64): np.float32(0.24050833), np.int32(65): np.float32(0.27956933), np.int32(66): np.float32(0.1749408), np.int32(67): np.float32(0.10131861), np.int32(68): np.float32(0.11720451), np.int32(69): np.float32(0.03466717), np.int32(70): np.float32(0.31916103), np.int32(71): np.float32(0.2796944), np.int32(72): np.float32(0.11369953), np.int32(73): np.float32(0.14185074), np.int32(74): np.float32(0.51262933), np.int32(75): np.float32(0.3476253), np.int32(76): np.float32(0.06326317), np.int32(77): np.float32(0.27050126), np.int32(78): np.float32(0.12194886), np.int32(79): np.float32(0.07216544), np.int32(80): np.float32(0.109205164), np.int32(81): np.float32(0.035776064), np.int32(82): np.float32(0.097800754), np.int32(83): np.float32(0.07342304), np.int32(84): np.float32(0.073910594), np.int32(85): np.float32(0.34880537), np.int32(86): np.float32(0.25040466), np.int32(87): np.float32(0.15545313), np.int32(88): np.float32(0.17997368), np.int32(89): np.float32(0.097513184), np.int32(90): np.float32(0.12541685), np.int32(91): np.float32(0.10609171), np.int32(92): np.float32(0.083940245), np.int32(93): np.float32(0.05767822), np.int32(94): np.float32(0.055683363), np.int32(95): np.float32(0.25575945), np.int32(96): np.float32(0.04403194), np.int32(97): np.float32(0.057366822), np.int32(98): np.float32(0.143116), np.int32(99): np.float32(0.117830776)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-13-1585781058.py:17: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  rf = yf.download(rfa, start=di, end=df)\n",
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "risk free return: 0.024185361237271705\n",
            "2019-10-17 2023-08-31\n",
            "2024-01-02\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "First trade made\n",
            "2024-03-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2024-05-10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2024-07-17\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2024-09-19\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2024-11-21\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2025-01-30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2025-04-04\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_774071ad-c6ff-4188-aebe-e4b2b0bb69b2\", \"2025-07-10_simulation_report_9.csv\", 4675)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max training day: 2023-08-31, min training day: 2019-10-17\n",
            "Epoch 1/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - loss: 0.0438 - mse: 0.0306 - val_loss: 0.0611 - val_mse: 0.0561\n",
            "Epoch 2/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0334 - mse: 0.0294 - val_loss: 0.0603 - val_mse: 0.0583\n",
            "Epoch 3/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0299 - mse: 0.0281 - val_loss: 0.0586 - val_mse: 0.0574\n",
            "Epoch 4/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0281 - mse: 0.0270 - val_loss: 0.0607 - val_mse: 0.0597\n",
            "Epoch 5/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0280 - mse: 0.0269 - val_loss: 0.0595 - val_mse: 0.0584\n",
            "Epoch 6/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0276 - mse: 0.0264 - val_loss: 0.0596 - val_mse: 0.0584\n",
            "Epoch 7/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0269 - mse: 0.0257 - val_loss: 0.0607 - val_mse: 0.0594\n",
            "Epoch 8/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0272 - mse: 0.0259 - val_loss: 0.0595 - val_mse: 0.0581\n",
            "Epoch 9/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0263 - mse: 0.0250 - val_loss: 0.0622 - val_mse: 0.0607\n",
            "Epoch 10/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0259 - mse: 0.0245 - val_loss: 0.0615 - val_mse: 0.0601\n",
            "Epoch 11/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0251 - mse: 0.0237 - val_loss: 0.0611 - val_mse: 0.0597\n",
            "Epoch 12/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0262 - mse: 0.0247 - val_loss: 0.0560 - val_mse: 0.0546\n",
            "Epoch 13/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0252 - mse: 0.0238 - val_loss: 0.0582 - val_mse: 0.0567\n",
            "Epoch 14/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0245 - mse: 0.0230 - val_loss: 0.0598 - val_mse: 0.0583\n",
            "Epoch 15/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0241 - mse: 0.0226 - val_loss: 0.0612 - val_mse: 0.0596\n",
            "Epoch 16/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0241 - mse: 0.0225 - val_loss: 0.0617 - val_mse: 0.0601\n",
            "Epoch 17/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0240 - mse: 0.0224 - val_loss: 0.0619 - val_mse: 0.0602\n",
            "Epoch 18/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0239 - mse: 0.0222 - val_loss: 0.0637 - val_mse: 0.0620\n",
            "Epoch 19/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0235 - mse: 0.0218 - val_loss: 0.0642 - val_mse: 0.0624\n",
            "Epoch 20/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0234 - mse: 0.0216 - val_loss: 0.0621 - val_mse: 0.0603\n",
            "Epoch 21/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0228 - mse: 0.0210 - val_loss: 0.0656 - val_mse: 0.0637\n",
            "Epoch 22/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0230 - mse: 0.0211 - val_loss: 0.0641 - val_mse: 0.0622\n",
            "Epoch 23/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0224 - mse: 0.0205 - val_loss: 0.0605 - val_mse: 0.0585\n",
            "Epoch 24/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0225 - mse: 0.0205 - val_loss: 0.0606 - val_mse: 0.0586\n",
            "Epoch 25/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0225 - mse: 0.0205 - val_loss: 0.0639 - val_mse: 0.0618\n",
            "Epoch 26/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0239 - mse: 0.0218 - val_loss: 0.0674 - val_mse: 0.0653\n",
            "Epoch 27/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0215 - mse: 0.0194 - val_loss: 0.0559 - val_mse: 0.0538\n",
            "Epoch 28/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0209 - mse: 0.0188 - val_loss: 0.0600 - val_mse: 0.0578\n",
            "Epoch 29/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0206 - mse: 0.0183 - val_loss: 0.0615 - val_mse: 0.0592\n",
            "Epoch 30/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0211 - mse: 0.0188 - val_loss: 0.0640 - val_mse: 0.0616\n",
            "Epoch 31/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0217 - mse: 0.0193 - val_loss: 0.0584 - val_mse: 0.0560\n",
            "Epoch 32/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0205 - mse: 0.0181 - val_loss: 0.0602 - val_mse: 0.0577\n",
            "Epoch 33/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0201 - mse: 0.0176 - val_loss: 0.0639 - val_mse: 0.0614\n",
            "Epoch 34/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0205 - mse: 0.0180 - val_loss: 0.0669 - val_mse: 0.0643\n",
            "Epoch 35/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0204 - mse: 0.0178 - val_loss: 0.0670 - val_mse: 0.0644\n",
            "Epoch 36/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0196 - mse: 0.0170 - val_loss: 0.0709 - val_mse: 0.0683\n",
            "Epoch 37/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0208 - mse: 0.0181 - val_loss: 0.0681 - val_mse: 0.0655\n",
            "Epoch 38/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0203 - mse: 0.0176 - val_loss: 0.0648 - val_mse: 0.0622\n",
            "Epoch 39/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0192 - mse: 0.0165 - val_loss: 0.0723 - val_mse: 0.0695\n",
            "Epoch 40/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0199 - mse: 0.0171 - val_loss: 0.0762 - val_mse: 0.0734\n",
            "Epoch 41/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0203 - mse: 0.0176 - val_loss: 0.0664 - val_mse: 0.0636\n",
            "Epoch 42/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0207 - mse: 0.0179 - val_loss: 0.0743 - val_mse: 0.0714\n",
            "Epoch 43/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0193 - mse: 0.0165 - val_loss: 0.0653 - val_mse: 0.0624\n",
            "Epoch 44/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0193 - mse: 0.0164 - val_loss: 0.0684 - val_mse: 0.0656\n",
            "Epoch 45/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0191 - mse: 0.0162 - val_loss: 0.0677 - val_mse: 0.0648\n",
            "Epoch 46/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0186 - mse: 0.0157 - val_loss: 0.0711 - val_mse: 0.0682\n",
            "Epoch 47/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0188 - mse: 0.0159 - val_loss: 0.0719 - val_mse: 0.0690\n",
            "Epoch 48/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0211 - mse: 0.0182 - val_loss: 0.0392 - val_mse: 0.0362\n",
            "Epoch 49/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0250 - mse: 0.0221 - val_loss: 0.0605 - val_mse: 0.0576\n",
            "Epoch 50/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0196 - mse: 0.0167 - val_loss: 0.0633 - val_mse: 0.0604\n",
            "Epoch 51/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0188 - mse: 0.0159 - val_loss: 0.0684 - val_mse: 0.0655\n",
            "Epoch 52/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0180 - mse: 0.0150 - val_loss: 0.0737 - val_mse: 0.0706\n",
            "Epoch 53/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0184 - mse: 0.0153 - val_loss: 0.0754 - val_mse: 0.0723\n",
            "Epoch 54/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0186 - mse: 0.0155 - val_loss: 0.0632 - val_mse: 0.0601\n",
            "Epoch 55/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0190 - mse: 0.0159 - val_loss: 0.0762 - val_mse: 0.0730\n",
            "Epoch 56/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0184 - mse: 0.0152 - val_loss: 0.0703 - val_mse: 0.0672\n",
            "Epoch 57/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0177 - mse: 0.0145 - val_loss: 0.0708 - val_mse: 0.0676\n",
            "Epoch 58/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0185 - mse: 0.0153 - val_loss: 0.0710 - val_mse: 0.0678\n",
            "Epoch 59/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0193 - mse: 0.0161 - val_loss: 0.0703 - val_mse: 0.0671\n",
            "Epoch 60/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0176 - mse: 0.0144 - val_loss: 0.0758 - val_mse: 0.0725\n",
            "Epoch 61/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0173 - mse: 0.0140 - val_loss: 0.0755 - val_mse: 0.0722\n",
            "Epoch 62/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0172 - mse: 0.0140 - val_loss: 0.0702 - val_mse: 0.0669\n",
            "Epoch 63/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0181 - mse: 0.0148 - val_loss: 0.0685 - val_mse: 0.0650\n",
            "Epoch 64/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0204 - mse: 0.0170 - val_loss: 0.0835 - val_mse: 0.0801\n",
            "Epoch 65/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0169 - mse: 0.0135 - val_loss: 0.0672 - val_mse: 0.0639\n",
            "Epoch 66/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0173 - mse: 0.0139 - val_loss: 0.0673 - val_mse: 0.0639\n",
            "Epoch 67/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0172 - mse: 0.0138 - val_loss: 0.0673 - val_mse: 0.0639\n",
            "Epoch 68/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0166 - mse: 0.0132 - val_loss: 0.0665 - val_mse: 0.0631\n",
            "Epoch 69/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - loss: 0.0177 - mse: 0.0143 - val_loss: 0.0726 - val_mse: 0.0691\n",
            "Epoch 70/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - loss: 0.0166 - mse: 0.0132 - val_loss: 0.0773 - val_mse: 0.0739\n",
            "Epoch 71/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - loss: 0.0165 - mse: 0.0130 - val_loss: 0.0684 - val_mse: 0.0649\n",
            "Epoch 72/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - loss: 0.0173 - mse: 0.0139 - val_loss: 0.0692 - val_mse: 0.0657\n",
            "Epoch 73/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0166 - mse: 0.0131 - val_loss: 0.0731 - val_mse: 0.0697\n",
            "Epoch 74/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0164 - mse: 0.0129 - val_loss: 0.0737 - val_mse: 0.0703\n",
            "Epoch 75/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0164 - mse: 0.0129 - val_loss: 0.0705 - val_mse: 0.0670\n",
            "Epoch 76/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0161 - mse: 0.0126 - val_loss: 0.0690 - val_mse: 0.0655\n",
            "Epoch 77/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0170 - mse: 0.0135 - val_loss: 0.0692 - val_mse: 0.0657\n",
            "Epoch 78/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0163 - mse: 0.0128 - val_loss: 0.0717 - val_mse: 0.0682\n",
            "Epoch 79/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0160 - mse: 0.0125 - val_loss: 0.0706 - val_mse: 0.0671\n",
            "Epoch 80/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0170 - mse: 0.0135 - val_loss: 0.0737 - val_mse: 0.0702\n",
            "Epoch 81/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0165 - mse: 0.0130 - val_loss: 0.0687 - val_mse: 0.0652\n",
            "Epoch 82/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0161 - mse: 0.0126 - val_loss: 0.0678 - val_mse: 0.0642\n",
            "Epoch 83/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0159 - mse: 0.0123 - val_loss: 0.0763 - val_mse: 0.0727\n",
            "Epoch 84/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0159 - mse: 0.0123 - val_loss: 0.0725 - val_mse: 0.0690\n",
            "Epoch 85/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0165 - mse: 0.0129 - val_loss: 0.0669 - val_mse: 0.0633\n",
            "Epoch 86/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0169 - mse: 0.0133 - val_loss: 0.0671 - val_mse: 0.0635\n",
            "Epoch 87/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0154 - mse: 0.0119 - val_loss: 0.0680 - val_mse: 0.0644\n",
            "Epoch 88/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0158 - mse: 0.0122 - val_loss: 0.0665 - val_mse: 0.0629\n",
            "Epoch 89/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0187 - mse: 0.0151 - val_loss: 0.0709 - val_mse: 0.0673\n",
            "Epoch 90/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0154 - mse: 0.0118 - val_loss: 0.0708 - val_mse: 0.0672\n",
            "Epoch 91/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0164 - mse: 0.0128 - val_loss: 0.0722 - val_mse: 0.0685\n",
            "Epoch 92/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0155 - mse: 0.0118 - val_loss: 0.0661 - val_mse: 0.0625\n",
            "Epoch 93/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0157 - mse: 0.0121 - val_loss: 0.0698 - val_mse: 0.0662\n",
            "Epoch 94/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0152 - mse: 0.0117 - val_loss: 0.0691 - val_mse: 0.0655\n",
            "Epoch 95/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0154 - mse: 0.0118 - val_loss: 0.0723 - val_mse: 0.0686\n",
            "Epoch 96/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0157 - mse: 0.0121 - val_loss: 0.0751 - val_mse: 0.0715\n",
            "Epoch 97/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0156 - mse: 0.0120 - val_loss: 0.0719 - val_mse: 0.0683\n",
            "Epoch 98/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0153 - mse: 0.0117 - val_loss: 0.0620 - val_mse: 0.0583\n",
            "Epoch 99/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0149 - mse: 0.0113 - val_loss: 0.0714 - val_mse: 0.0677\n",
            "Epoch 100/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0154 - mse: 0.0118 - val_loss: 0.0680 - val_mse: 0.0644\n",
            "Epoch 101/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0149 - mse: 0.0113 - val_loss: 0.0666 - val_mse: 0.0629\n",
            "Epoch 102/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0156 - mse: 0.0120 - val_loss: 0.0683 - val_mse: 0.0647\n",
            "Epoch 103/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0148 - mse: 0.0112 - val_loss: 0.0615 - val_mse: 0.0579\n",
            "Epoch 104/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0155 - mse: 0.0118 - val_loss: 0.0744 - val_mse: 0.0707\n",
            "Epoch 105/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0168 - mse: 0.0132 - val_loss: 0.0697 - val_mse: 0.0660\n",
            "Epoch 106/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0154 - mse: 0.0117 - val_loss: 0.0747 - val_mse: 0.0710\n",
            "Epoch 107/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0147 - mse: 0.0111 - val_loss: 0.0663 - val_mse: 0.0627\n",
            "Epoch 108/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0153 - mse: 0.0116 - val_loss: 0.0726 - val_mse: 0.0690\n",
            "Epoch 109/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0151 - mse: 0.0114 - val_loss: 0.0697 - val_mse: 0.0660\n",
            "Epoch 110/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0149 - mse: 0.0112 - val_loss: 0.0674 - val_mse: 0.0637\n",
            "Epoch 111/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0150 - mse: 0.0113 - val_loss: 0.0746 - val_mse: 0.0710\n",
            "Epoch 112/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0152 - mse: 0.0116 - val_loss: 0.0725 - val_mse: 0.0689\n",
            "Epoch 113/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0146 - mse: 0.0109 - val_loss: 0.0669 - val_mse: 0.0632\n",
            "Epoch 114/200\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0147 - mse: 0.0111 - val_loss: 0.0740 - val_mse: 0.0703\n",
            "Epoch 114: early stopping\n",
            "Restoring model weights from the end of the best epoch: 109.\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-13-1585781058.py:17: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  rf = yf.download(rfa, start=di, end=df)\n",
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{np.int32(0): np.float32(0.15407768), np.int32(1): np.float32(0.11179019), np.int32(2): np.float32(0.053829584), np.int32(3): np.float32(0.11361559), np.int32(4): np.float32(0.06406867), np.int32(5): np.float32(0.18897754), np.int32(6): np.float32(0.15961277), np.int32(7): np.float32(0.06463447), np.int32(8): np.float32(0.28335685), np.int32(9): np.float32(0.20455468), np.int32(10): np.float32(0.22218157), np.int32(11): np.float32(0.066906966), np.int32(12): np.float32(0.092432074), np.int32(13): np.float32(0.14245376), np.int32(14): np.float32(0.12033417), np.int32(15): np.float32(0.08736233), np.int32(16): np.float32(0.07190228), np.int32(17): np.float32(0.12823622), np.int32(18): np.float32(0.08076232), np.int32(19): np.float32(0.21500905), np.int32(20): np.float32(0.22749317), np.int32(21): np.float32(0.060573336), np.int32(22): np.float32(0.26852328), np.int32(23): np.float32(0.097863905), np.int32(24): np.float32(0.16353016), np.int32(25): np.float32(0.20048423), np.int32(26): np.float32(0.22090371), np.int32(27): np.float32(0.0743992), np.int32(28): np.float32(0.15533577), np.int32(29): np.float32(0.23407593), np.int32(30): np.float32(0.082157224), np.int32(31): np.float32(0.1562568), np.int32(32): np.float32(0.1315439), np.int32(33): np.float32(0.0790505), np.int32(34): np.float32(0.06085367), np.int32(35): np.float32(0.055988673), np.int32(36): np.float32(0.07834848), np.int32(38): np.float32(0.2761066), np.int32(39): np.float32(0.11454577), np.int32(40): np.float32(0.39812148), np.int32(41): np.float32(0.10705679), np.int32(42): np.float32(1.8214725), np.int32(43): np.float32(0.39457068), np.int32(44): np.float32(0.19881676), np.int32(45): np.float32(0.10406088), np.int32(46): np.float32(0.12184385), np.int32(47): np.float32(0.12659013), np.int32(48): np.float32(0.23642838), np.int32(49): np.float32(0.10896654), np.int32(50): np.float32(0.19894534), np.int32(51): np.float32(0.09504031), np.int32(52): np.float32(0.22491753), np.int32(53): np.float32(0.13238999), np.int32(54): np.float32(0.09199969), np.int32(55): np.float32(0.18554054), np.int32(56): np.float32(0.123198695), np.int32(57): np.float32(0.058076054), np.int32(58): np.float32(0.11537181), np.int32(59): np.float32(0.17588192), np.int32(60): np.float32(0.036447458), np.int32(61): np.float32(0.46339002), np.int32(62): np.float32(0.08574957), np.int32(63): np.float32(0.11539452), np.int32(64): np.float32(0.24391386), np.int32(65): np.float32(0.27537072), np.int32(66): np.float32(0.13237883), np.int32(67): np.float32(0.058230523), np.int32(68): np.float32(0.14678065), np.int32(69): np.float32(0.035916176), np.int32(70): np.float32(0.34982938), np.int32(71): np.float32(0.27645716), np.int32(72): np.float32(0.1341677), np.int32(73): np.float32(0.19921668), np.int32(74): np.float32(0.47094956), np.int32(75): np.float32(0.33622992), np.int32(76): np.float32(0.05754477), np.int32(77): np.float32(0.17437094), np.int32(78): np.float32(0.20426553), np.int32(79): np.float32(0.2201726), np.int32(80): np.float32(0.120055474), np.int32(81): np.float32(0.04435377), np.int32(82): np.float32(0.11947189), np.int32(83): np.float32(0.21158494), np.int32(84): np.float32(0.075894974), np.int32(85): np.float32(0.42331526), np.int32(86): np.float32(0.1616853), np.int32(87): np.float32(0.23979962), np.int32(88): np.float32(0.06879341), np.int32(89): np.float32(0.1667485), np.int32(90): np.float32(0.123734534), np.int32(91): np.float32(0.075767346), np.int32(92): np.float32(0.16060504), np.int32(93): np.float32(0.057996888), np.int32(94): np.float32(0.031420484), np.int32(95): np.float32(0.18681386), np.int32(96): np.float32(0.027579684), np.int32(97): np.float32(0.057261985), np.int32(98): np.float32(0.07237793), np.int32(99): np.float32(0.060422875)}\n",
            "\n",
            "\n",
            "risk free return: 0.024185361237271705\n",
            "2019-10-17 2023-08-31\n",
            "2024-01-02\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "First trade made\n",
            "2024-03-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2024-05-10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2024-07-17\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2024-09-19\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2024-11-21\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "2025-01-30\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "2025-04-04\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f58a15d2-8c5b-413b-9e07-41bc0d1ae2be\", \"2025-07-10_simulation_report_10.csv\", 7511)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "all_sims = pd.DataFrame()\n",
        "for i in range(num_sims):\n",
        "    model, PL, simulation_report = simulate_trades(dates, sim_start, resp_length,\n",
        "                                                X, tickers, y, ai90,\n",
        "                                                risk_free_asset,\n",
        "                                                retrain_frequency, epochs,\n",
        "                                                batches, reg, patience, SR,\n",
        "                                                long_short, nav)\n",
        "    # download the simulation report\n",
        "    sim_file = f'{curr_date}_simulation_report_{sim_number}.csv'\n",
        "    simulation_report.to_csv(sim_file, index=False)\n",
        "    files.download(sim_file)\n",
        "    PLs[i] = PL\n",
        "    sim_number += 1\n",
        "    if not all_sims.empty: all_sims = pd.concat([all_sims, simulation_report], axis=0)\n",
        "    else: all_sims = simulation_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZXo8VohfR9J"
      },
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8S8xMPxtPlE4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b420f757-02a0-413f-c54e-4dca4cc2267f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sim #1 PL: 47.32%\n",
            "Sim #2 PL: 47.19%\n",
            "Sim #3 PL: 62.73%\n",
            "Sim #4 PL: 61.24000000000001%\n",
            "Sim #5 PL: 7.93%\n",
            "Sim #6 PL: 18.93%\n",
            "Sim #7 PL: 42.970000000000006%\n",
            "Sim #8 PL: 15.03%\n",
            "Sim #9 PL: 74.49%\n",
            "Sim #10 PL: 3.53%\n"
          ]
        }
      ],
      "source": [
        "# output the PL of each sim\n",
        "for i, PL in enumerate(PLs):\n",
        "    print(f'Sim #{i+1} PL: {100*round(float(PL), 4)}%')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PLs_sorted = sorted(PLs)\n",
        "print(PLs_sorted[len(PLs_sorted)//2])"
      ],
      "metadata": {
        "id": "aZxLijH-8JVn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1592d58b-d39e-46bb-f60d-173d172676ad"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.47193316881683467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "QCzVFTD5LyW2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "d1eb72fa-4e17-4cc8-9aa0-bf6a1d58db39"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c779c8a8-0871-446c-b059-f971ce2dcfe5\", \"model_2025-07-10_11.keras\", 460671)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# save the final model\n",
        "model_name = f'model_{curr_date}_{sim_number}.keras'\n",
        "model.save(model_name)\n",
        "files.download(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# scatter plot to compare PL% vs Rating for each trade\n",
        "plt.scatter(all_sims['Rating'], all_sims['PL%'])\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('PL%')\n",
        "plt.title('PL% vs. Rating')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wys27-DyS5BJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "a002a9c9-d5e8-4d6f-96cf-deb2599919a0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj4AAAHHCAYAAAC/R1LgAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAboVJREFUeJzt3Xl8E3X+P/BX0qbpQU8KTYECFUEo5SxXxQOhUARRlJ8rIi64LCqCCrhyqNwiggiIXOIq7i5W0fWriEilCAsq5bZoaeWygEJbBEoDLW3TZH5/1ISmzTE5JpM0r+fjwUMzmcx8Mp80887neH8UgiAIICIiIvIDSrkLQEREROQpDHyIiIjIbzDwISIiIr/BwIeIiIj8BgMfIiIi8hsMfIiIiMhvMPAhIiIiv8HAh4iIiPwGAx8iIiLyGwx8iIhkdObMGSgUCnzwwQdyF4XILzDwIfJjH3zwARQKhelfcHAw2rVrh0mTJqG4uNi03//+9z8oFAr897//tXosQRAwb948NG/eHE2bNsXkyZNRVVVlts/169fRvHlzZGRkSPae3KH2NVEoFIiIiMDdd9+NrVu3On3MjIwMrFixwn2FJCKnBMpdACKS3/z585GYmIiKigp8//33WLt2Lb7++mvk5uYiNDRU1DE+/PBDvPbaa5g+fTrCwsKwcOFCxMXFYebMmaZ9Fi5ciNatW2PUqFFSvRW3GThwIP76179CEAScPXsWa9euxbBhw7Bt2zakp6c7fLyMjAzk5uZi8uTJZttbtWqFGzduQKVSuankRGQLAx8iwr333osePXoAAP7+97+jcePGWLZsGTZv3oxHH31U1DG++uorPPbYY5g/fz4A4MaNG/jyyy9Ngc/p06fx1ltvYc+ePdK8CTdr164dRo8ebXo8YsQIJCUl4a233nIq8LHG2NJGRJ7Bri4iqqd///4AgIKCAtGvuXHjBqKjo02PY2JiUF5ebnr8wgsvYOTIkaYAy57i4mIEBgZi3rx59Z47fvw4FAoFVq1aBQDQ6XSYN28e2rZti+DgYDRu3Bh33HEHsrKyRJffng4dOiA2NhanT582275582YMHToUzZo1g1qtRps2bbBgwQLo9XrTPv369cPWrVtx9uxZU/dZ69atAVge4zN27Fg0atQI58+fx/Dhw9GoUSM0adIE//jHP8yOCwCXL1/G448/joiICERFRWHMmDE4evQoxw0RWcEWHyKqx3hzb9y4sejX9OzZE2vWrMHDDz+MsLAwvPPOO7j99tsBAFlZWdi5cydOnDgh+nhxcXG4++678cknn2DOnDlmz23atAkBAQF4+OGHAQBz587FokWL8Pe//x29evWCVqvFoUOHcOTIEQwcOFD0OW0pLS1FSUkJ2rRpY7b9gw8+QKNGjTB16lQ0atQIO3fuxOzZs6HVavHGG28AAF5++WWUlpbi999/x/LlywEAjRo1snk+vV6P9PR09O7dG0uXLsWOHTvw5ptvok2bNpgwYQIAwGAwYNiwYThw4AAmTJiA9u3bY/PmzRgzZoxb3jNRgyQQkd/asGGDAEDYsWOH8Mcffwi//fab8PHHHwuNGzcWQkJChN9//10QBEHYtWuXAED49NNPrR5Lq9UKd9xxhwBAACB07NhR+P333wWdTickJSUJr7/+usPle+eddwQAws8//2y2PSkpSejfv7/pcZcuXYShQ4c6fHxrAAjjxo0T/vjjD+HixYvCoUOHhMGDBwsAhDfeeMNs3/Ly8nqvf+qpp4TQ0FChoqLCtG3o0KFCq1at6u1bUFAgABA2bNhg2jZmzBgBgDB//nyzfbt16yakpKSYHn/22WcCAGHFihWmbXq9Xujfv3+9YxJRDXZ1ERHS0tLQpEkTJCQkYOTIkWjUqBE+//xzNG/eXPQxwsPDsXv3bhw7dgw5OTnIyclB8+bNsWbNGlRWVmLKlCnIy8vDPffcg+bNm2P06NHQarU2j/nQQw8hMDAQmzZtMm3Lzc1FXl4eHnnkEdO2qKgoHDt2DCdPnnT8zVvx3nvvoUmTJmjatCl69OiBb7/9FtOmTcPUqVPN9gsJCTH9/7Vr13Dp0iXceeedKC8vxy+//OJSGZ5++mmzx3feeSd+/fVX0+PMzEyoVCqMHz/etE2pVGLixIkunZeoIWPgQ0RYvXo1srKysGvXLuTl5eHXX391agCvUqlEUlISunTpgsDAQFy6dAlz587F0qVLoVAocN9996FTp07YvHkzzp07h2effdbm8WJjYzFgwAB88sknpm2bNm1CYGAgHnroIdO2+fPn4+rVq2jXrh06deqEF198ET/99JPD5a/tgQceQFZWFrZu3Yq5c+dCoVCgvLwcSqX51+axY8fw4IMPIjIyEhEREWjSpIlpUHRpaanT5w8ODkaTJk3MtkVHR6OkpMT0+OzZs4iPj6838+7WW291+rxEDR3H+BARevXqJXrQsSNmzZqF7t27Y/jw4fjuu+9QWFiIJUuWIDg4GPPmzcPgwYOxYcOGesFEbSNHjsQTTzyBnJwcdO3aFZ988gkGDBiA2NhY0z533XUXTp8+jc2bN2P79u345z//ieXLl2PdunX4+9//7lTZW7RogbS0NADAkCFDEBsbi0mTJuGee+4xBV1Xr17F3XffjYiICMyfPx9t2rRBcHAwjhw5gunTp8NgMDh1bgAICAhw+rVEZB1bfIhIEkePHsX7779vStp34cIFREdHm6ZuN2vWDFVVVfjjjz9sHmf48OEICgrCpk2bkJOTgxMnTmDkyJH19ouJicETTzyBjz76CL/99hs6d+6MuXPnuu39PPXUU2jTpg1eeeUVCIIAoCax4+XLl/HBBx/g+eefx3333Ye0tDSz2W1GCoXCbWUxatWqFQoLC81mzwHAqVOn3H4uooaCgQ8RSeL555/H3//+dyQnJwOomaX1xx9/4MqVKwCA/Px8BAYGmrXcWBIVFYX09HR88skn+PjjjxEUFIThw4eb7XP58mWzx40aNcKtt96KyspK07bS0lL88ssvTnc/BQYG4oUXXkB+fj42b94M4GarjDEQAoCqqiqsWbOm3uvDwsJc6vqyJD09HTqdDu+++65pm8FgwOrVq916HqKGhF1dRCTaZ599ZnHA7pgxY5CQkGB6/Omnn+Knn37CZ599ZtqWmpqKuLg4PPzww3jooYewdOlSPPTQQ6K6dB555BGMHj0aa9asQXp6OqKiosyeT0pKQr9+/ZCSkoKYmBgcOnQI//3vfzFp0iTTPp9//jmeeOIJbNiwAWPHjnX8zaMmv87s2bOxePFiDB8+HLfffjuio6MxZswYPPfcc1AoFPjPf/5jFggZpaSkYNOmTZg6dSp69uyJRo0aYdiwYU6Vw2j48OHo1asXXnjhBZw6dQrt27fHl19+aQoupWhlIvJ5Ms8qIyIZGaezHzx40OZ+xuns1v599913pn3Ly8uFVq1aCStXrqx3nIMHDwrdu3cXwsPDhWHDhgkXL14UVU6tViuEhIQIAISNGzfWe/7VV18VevXqJURFRQkhISFC+/bthYULFwpVVVX13quYKd4AhIkTJ1p8bu7cuQIAYdeuXYIgCMIPP/wg9OnTRwgJCRGaNWsmTJs2Tfjmm2/M9hEEQbh+/bowatQoISoqSgBgmtpubTp7WFhYvXPPmTNHqPu1/ccffwijRo0SwsPDhcjISGHs2LHCDz/8IAAQPv74Y7vvlcjfKATBwk8TIiLyWV988QUefPBBfP/99+jbt6/cxSHyKgx8iIh82I0bN8xyCen1egwaNAiHDh1CUVGR2XNExDE+REQ+7dlnn8WNGzeQmpqKyspK/N///R/27t2L1157jUEPkQVs8SEi8mEZGRl48803cerUKVRUVODWW2/FhAkTzAZ2E9FNDHyIiIjIbzCPDxEREfkNBj5ERETkNzi4uQ6DwYALFy4gPDycyb+IiIh8hCAIuHbtGpo1a2Zz/T8GPnVcuHDBLAMtERER+Y7ffvsNLVq0sPo8A586wsPDAdRcuIiICJlL4110Oh22b9+OQYMGQaVSyV0cv8Q6kB/rQH6sA/l5Yx1otVokJCSY7uPWMPCpw9i9FRERwcCnDp1Oh9DQUERERHjNB93fsA7kxzqQH+tAft5cB/aGqXBwMxEREfkNBj5ERETkNxj4EBERkd9g4ENERER+g4EPERER+Q0GPkREROQ3GPgQERGR3/CawGfPnj0YNmwYmjVrBoVCgS+++MLseUEQMHv2bMTHxyMkJARpaWk4efKk2T5XrlzBY489hoiICERFRWHcuHG4fv26B98FEREReTOvCXzKysrQpUsXrF692uLzS5YswcqVK7Fu3Trs378fYWFhSE9PR0VFhWmfxx57DMeOHUNWVha++uor7NmzB08++aSn3gIRERF5Oa/J3Hzvvffi3nvvtficIAhYsWIFXnnlFTzwwAMAgH//+9+Ii4vDF198gZEjRyI/Px+ZmZk4ePAgevToAQB4++23MWTIECxduhTNmjXz2HuRgt4g4EDBFVy8VoGm4cHolRiDACUXUSUiInKE1wQ+thQUFKCoqAhpaWmmbZGRkejduzeys7MxcuRIZGdnIyoqyhT0AEBaWhqUSiX279+PBx98UI6iu0VmbiHmbclDYenN1q34yGDMGZaEwcnxMpaMiIjIt/hE4FNUVAQAiIuLM9seFxdneq6oqAhNmzY1ez4wMBAxMTGmfSyprKxEZWWl6bFWqwVQsw6JTqdzS/ldsSO/GFM25UAAoA64ub3k+g1M/ugwlj/SFWkd4qy+3p2M18Mbrou/Yh3Ij3UgP9aB/LyxDsSWxScCHyktWrQI8+bNq7d9+/btCA0NlaFE9S3uZf25qoLD+LrAc2UBgKysLM+ekOphHciPdSA/1oH8vKkOysvLRe3nE4GPRqMBABQXFyM+/mbXTnFxMbp27Wra5+LFi2avq66uxpUrV0yvt2TmzJmYOnWq6bFxWftBgwbJvjr7gYIr+Nu/Dtrd7/0xPdErMUby8uh0OmRlZWHgwIFetxqvv2AdyI91ID/Wgfy8sQ6MPTb2+ETgk5iYCI1Gg2+//dYU6Gi1Wuzfvx8TJkwAAKSmpuLq1as4fPgwUlJSAAA7d+6EwWBA7969rR5brVZDrVbX265SqWSvzEvl1ajU2x/AfKm82qNl9YZr4+9YB/JjHciPdSA/b6oDseXwmsDn+vXrOHXqlOlxQUEBcnJyEBMTg5YtW2Ly5Ml49dVX0bZtWyQmJmLWrFlo1qwZhg8fDgDo0KEDBg8ejPHjx2PdunXQ6XSYNGkSRo4c6bMzupqGB7t1PyIiIn/nNYHPoUOHcM8995geG7ufxowZgw8++ADTpk1DWVkZnnzySVy9ehV33HEHMjMzERx886b/4YcfYtKkSRgwYACUSiVGjBiBlStXevy9uEuvxBjERwajqLQCgoXnFQA0kcEe6eYiIiJqCLwm8OnXrx8EwdLtvYZCocD8+fMxf/58q/vExMQgIyNDiuLJIkCpwJxhSZiw8QgUgFnwY+wAmzMsifl8iIiIRPKazM1k2eDkeKwd3R2aSPPuLE1kMNaO7s48PkRERA7wmhYfsm5wcjwGJmmYuZmIiMhFDHx8RIBSgdQ2jeUuBhERkU9jVxcRERH5DQY+RERE5DcY+BAREZHfYOBDREREfoOBDxEREfkNBj5ERETkNxj4EBERkd9g4ENERER+g4EPERER+Q0GPkREROQ3GPgQERGR32DgQ0RERH6DgQ8RERH5DQY+RERE5DcY+BAREZHfYOBDREREfoOBDxEREfkNBj5ERETkNxj4EBERkd9g4ENERER+g4EPERER+Q0GPkREROQ3GPgQERGR32DgQ0RERH6DgQ8RERH5jUC5C+CP9AYBBwqu4OK1CjQND0avxBgEKBVyF4uIiKjBY+DjYZm5hZi3JQ+FpRWmbfGRwZgzLAmDk+NlLBkREVHDx64uD8rMLcSEjUfMgh4AKCqtwISNR5CZWyhTyYiIiPyDzwQ+er0es2bNQmJiIkJCQtCmTRssWLAAgiCY9hEEAbNnz0Z8fDxCQkKQlpaGkydPyljqm/QGAfO25EGw8Jxx27wtedAbLO1BRERE7uAzgc/ixYuxdu1arFq1Cvn5+Vi8eDGWLFmCt99+27TPkiVLsHLlSqxbtw779+9HWFgY0tPTUVFRYePInnGg4Eq9lp7aBACFpRU4UHDFc4UiIiLyMz4zxmfv3r144IEHMHToUABA69at8dFHH+HAgQMAalp7VqxYgVdeeQUPPPAAAODf//434uLi8MUXX2DkyJGylR0ALl4TF3yJ3Y+IiIgc5zOBz+23347169fjxIkTaNeuHY4ePYrvv/8ey5YtAwAUFBSgqKgIaWlpptdERkaid+/eyM7Othr4VFZWorKy0vRYq9UCAHQ6HXQ6ndvKHxsaCHWA/W6s2NBAt57XnYzl8tby+QPWgfxYB/JjHcjPG+tAbFl8JvCZMWMGtFot2rdvj4CAAOj1eixcuBCPPfYYAKCoqAgAEBcXZ/a6uLg403OWLFq0CPPmzau3ffv27QgNDXXjOwCW9LK/z6X8ffg6362ndbusrCy5i+D3WAfyYx3Ij3UgP2+qg/LyclH7+Uzg88knn+DDDz9ERkYGOnbsiJycHEyePBnNmjXDmDFjnD7uzJkzMXXqVNNjrVaLhIQEDBo0CBEREe4ousmO/GJM2ZQDAGaDnI0ZfJY/0hVpHeLqvsxr6HQ6ZGVlYeDAgVCpVHIXxy+xDuTHOpAf60B+3lgHxh4be3wm8HnxxRcxY8YMU5dVp06dcPbsWSxatAhjxoyBRqMBABQXFyM+/mY+nOLiYnTt2tXqcdVqNdRqdb3tKpXK7ZV5b+cWUCgDfD6PjxTXhhzDOpAf60B+rAP5eVMdiC2HzwQ+5eXlUCrNJ6EFBATAYDAAABITE6HRaPDtt9+aAh2tVov9+/djwoQJni6uVYOT4zEwScPMzURERDLwmcBn2LBhWLhwIVq2bImOHTvixx9/xLJly/C3v/0NAKBQKDB58mS8+uqraNu2LRITEzFr1iw0a9YMw4cPl7fwdQQoFUht01juYhAREfkdnwl83n77bcyaNQvPPPMMLl68iGbNmuGpp57C7NmzTftMmzYNZWVlePLJJ3H16lXccccdyMzMRHBwsIwlJyIiIm/hM4FPeHg4VqxYgRUrVljdR6FQYP78+Zg/f77nCkZEREQ+w2cyNxMRERG5ioEPERER+Q0GPkREROQ3GPgQERGR32DgQ0RERH6DgQ8RERH5DQY+RERE5DcY+BAREZHfYOBDREREfoOBDxEREfkNBj5ERETkNxj4EBERkd9g4ENERER+g4EPERER+Q0GPkREROQ3GPgQERGR32DgQ0RERH6DgQ8RERH5DQY+RERE5DcY+BAREZHfYOBDREREfoOBDxEREfmNQLkL4E/0BgEHCq7g4rUKNA0PRq/EGAQoFXIXi4iIyG8w8PGQzNxCzNuSh8LSCtO2+MhgzBmWhMHJ8TKWjIiIyH+wq8sDMnMLMWHjEbOgBwCKSiswYeMRZOYWylQyIiIi/8LAR2J6g4B5W/IgWHhO+PPfvC150Bss7UFERETuxMBHYgcKrtRr6amrsLQCBwqueKhERERE/ouBj8SKtLaDHkf3IyIiIucx8JHYleuVbt2PiIiInMfAR2IxYUFu3Y+IiIic51OBz/nz5zF69Gg0btwYISEh6NSpEw4dOmR6XhAEzJ49G/Hx8QgJCUFaWhpOnjwpY4kBTWSIW/cjIiIi5/lM4FNSUoK+fftCpVJh27ZtyMvLw5tvvono6GjTPkuWLMHKlSuxbt067N+/H2FhYUhPT0dFhXzjZ3olxiA+MtjmPvGRNckMiYiISFo+k8Bw8eLFSEhIwIYNG0zbEhMTTf8vCAJWrFiBV155BQ888AAA4N///jfi4uLwxRdfYOTIkR4vMwAEKBWYMywJEzYesTilXQFgzrAkZnAmIiLyAJ9p8fnyyy/Ro0cPPPzww2jatCm6deuGd9991/R8QUEBioqKkJaWZtoWGRmJ3r17Izs7W44imwxOjsfa0d3rtfzERwZj7ejuzNxMRETkIT7T4vPrr79i7dq1mDp1Kl566SUcPHgQzz33HIKCgjBmzBgUFRUBAOLi4sxeFxcXZ3rOksrKSlRW3pxRpdVqAQA6nQ46nc5t5R9wWyz6tb0Th8+W4NL1SsQ2UiOlVTQClAq3nscVeoNgsXxGxnJaK6+915Pr7NUBSY91ID/Wgfy8sQ7ElkUhCIJPpAwOCgpCjx49sHfvXtO25557DgcPHkR2djb27t2Lvn374sKFC4iPv9mC8pe//AUKhQKbNm2yeNy5c+di3rx59bZnZGQgNDTU/W+EiIiI3K68vByjRo1CaWkpIiIirO7nMy0+8fHxSEpKMtvWoUMHfPbZZwAAjUYDACguLjYLfIqLi9G1a1erx505cyamTp1qeqzVapGQkIBBgwbZvHANyY78YkzZlFNvDJKxrWb5I12R1iEOOp0OWVlZGDhwIFQqlcOvJ9dZqwPyHNaB/FgH8vPGOjD22NjjM4FP3759cfz4cbNtJ06cQKtWrQDUDHTWaDT49ttvTYGOVqvF/v37MWHCBKvHVavVUKvV9barVCpJKlNvEHCg4AouXqtA0/Ca2VxydgfpDQLmbz2OCr3lMigAzN96HIOSm8N4NWpfG0dez24v95Hq80nisQ7kxzqQnzfVgdhy+EzgM2XKFNx+++147bXX8Je//AUHDhzA+vXrsX79egCAQqHA5MmT8eqrr6Jt27ZITEzErFmz0KxZMwwfPlzewv8pM7cQ87bkma3dFR8ZjDnDkmQb4GxvLTEBN9cS69GyfguYI69PbdPYDSUmIiJyns/M6urZsyc+//xzfPTRR0hOTsaCBQuwYsUKPPbYY6Z9pk2bhmeffRZPPvkkevbsievXryMzMxPBwbbz6HhCZm4hJmw8Ui9IKCqtwISNR5CZWyhLuS5eE5fjyNp+rr6eiIjIk3ymxQcA7rvvPtx3331Wn1coFJg/fz7mz5/vwVLZpzcImLclz2IeHwE13UHztuRhYJLG491BTcPFBYXW9nP19URERJ7kMy0+vsyR7iBPM2aWthZuKWA7s7SrryciIvIkBj4e4M3dQcbM0gDqBS/Gx7YyS7v6eiIiIk9i4OMB3t4dZMwsramTWVojMrO0q68nIiLyFJ8a4+OrjN1BRaUVVtfr0sjcHTQ4OR4DkzROT7V39fVERESewMDHA2ovVKoAzIIfb+oOClAqXJpy7urriYiIpMauLg9hdxAREZH82OLjQewOIiIikhcDHw9jdxAREZF82NVFREREfoOBDxEREfkNBj5ERETkNxj4EBERkd9g4ENERER+g4EPERER+Q0GPkREROQ3GPgQERGR32DgQ0RERH6DmZu9RFW1Af/JPoOCy2VQAOiWEI34qBCzJS30BsHuchdi9vEFlt4HgAbx3vxdQ/mMEpFvYuDjBRZ9nYd3vyuAoday7f/Zdw4AoIkIxtz7kwAA87bkobC0wrRPfGQw5gxLMi1wmplbaHcfX2DpfUSFqgAAV8t1pm2++N78XUP5jBKR72JXl8wWfZ2Hd/aYBz21FWkr8PTGI3h64xGzmwUAFJVWYMLGI8jMLURmbiEm2NnHF1h7H1fLdWZBD+B7783fNZTPKBH5NgY+MqqqNuDd7wqcfr0xVpq3JQ9zvzwGS7FT7X301qIrL6E3CJi3Jc/i+7DEl96bv7NVt6xHIvIkBj4y+k/2GastPWIJAApLK1CkrbS7z4GCK66dTGIHCq7Uaw2wx1fem7+zV7esRyLyFI7xkdHZK+UePd/Fa44FFZ7mSvl+OPUHB8t6MbF16+2fUSLyfQx8ZNQqJtSj52saHuzR8znKlfKt2nXa9P8cLOt9xNatt39Gicj3satLRo+ntoYnGiYUqAkGjFPCvVWvxBjERwbD1UvCwbLex17d+spnlIh8HwMfGQUFKjH+zkRJz2G80cwZluT13T8BSgXmDKuZuu9KSTlY1vvYqltf+owSke9j4COzmUOS8NRdiVDY+b4f1lkj6ngxYSqzx5rIYKwd3d1nun0GJ8dj7eju0ESad3lEh6pMuXzE4GBZ72Otbn3tM0pEvo1jfGSmNwjod1sc2sVFYHPOeRwouIyK6putFNGhgVg4vBN0BgFbfiqye7xZ93WEJiLYpwf6Dk6Ox8AkDQ4UXEFR6Q1cKatCTCM1moarAQG4VFaJk8XXsWrXKbvH+uHUJZ++Fg1N7bplvRCRHBj4yMhihuIQFQIDBFyvrAYAlJRXY8HWfKS0ihZ1TE1EMFLbNJakvJ4UoFSg9EYVlnxz3GKW3763xooKfGrvw0HP3iFAqWgQn1Ei8k3s6vIwvUFA9unLmL/lmMVszFdv6ExBj1FhaQW++sn2QF0xg0ON596ccx7Zpy+7PP7F3cerzV6W35KyKocHQnPQMxERscXHgyy18LiTrcGh7l4jSco1l+xl+VUAWLA1D7OGdsDEjB+hAERleza+dt6WPAxM0rB7hYjID/lsi8/rr78OhUKByZMnm7ZVVFRg4sSJaNy4MRo1aoQRI0aguLhYvkLWYq0Fw10mp7WzGnC4e42kHfnFkq65JDbLb3SY2uJgWVs46JmIyL/5ZOBz8OBBvPPOO+jcubPZ9ilTpmDLli349NNPsXv3bly4cAEPPfSQTKW8ydE1qJzROtZyMkQp1kh6fdsvkq655EiW38HJ8fh+en98NL4P3hrZFZPuaePWcxARUcPic4HP9evX8dhjj+Hdd99FdPTNAb+lpaV47733sGzZMvTv3x8pKSnYsGED9u7di3379slYYufWoHKUtYy3UqyRVKSVds0lR7P8GgfLPtC1Ofre2sSt5yAioobF58b4TJw4EUOHDkVaWhpeffVV0/bDhw9Dp9MhLS3NtK19+/Zo2bIlsrOz0adPH4vHq6ysRGXlzQU+tVotAECn00Gn07mlzBdLy6AOkKa9RwEgLiIY3VqEWyyv2HNfLC2DThdhcx/j8dVK9xzPmm4twtEqWo1ibYXFliVb79mV1/oCY5l9sewNBetAfqwD+XljHYgti0IQBJ9Jbfvxxx9j4cKFOHjwIIKDg9GvXz907doVK1asQEZGBp544gmzIAYAevXqhXvuuQeLFy+2eMy5c+di3rx59bZnZGQgNNSza2kRERGRc8rLyzFq1CiUlpYiIsL6D2+fafH57bff8PzzzyMrKwvBwe7rppg5cyamTp1qeqzVapGQkIBBgwbZvHCO0BsEpK/YY7UVoraoEBVKK3QQE45qIoIx4972SOsQZ3WfqmoDeizMgq0hN0oFcOjlgQgKtN3zqdPpkJWVhVUnQvHb1UqbLSrfTL7L5VlTO/KL8fq2X8y61sS8Z1df682MdTBw4ECoVOIzWZP7sA7kxzqQnzfWgbHHxh6fCXwOHz6Mixcvonv37qZter0ee/bswapVq/DNN9+gqqoKV69eRVRUlGmf4uJiaDTWl3tQq9VQq9X1tqtUKrdVpgrAzKEdMWHjEQCWp16P69saaUka9EqMwTe5hXgm48d6+xinbf+tb2sM/HNfe8HFoXOXcaPafgDy04XropPKTU3vgGcyjgIwfy/Gs8wc2hHB6iBRx7Ll3s4tMCi5uVNZfl15rS9w5+eTnMM6kB/rQH7eVAdiy+Ezgc+AAQPw888/m2174okn0L59e0yfPh0JCQlQqVT49ttvMWLECADA8ePHce7cOaSmpspRZDPGdYosZWp+om9rTOrf1nRTHtK5GdYpFfX21djIk6M3CBZv8o7MkBIrrUOcxfdiq3zOciXLLzMEExFRXT4T+ISHhyM5OdlsW1hYGBo3bmzaPm7cOEydOhUxMTGIiIjAs88+i9TUVKsDmz3NuE7Rqp2nsOGHAly9ocPVGzos33ESHx/8zSxocGRNI1vJBB2dIeXoe3GlRcVasEaWGa8XUDNbr8+tTXm9iIgc5DOBjxjLly+HUqnEiBEjUFlZifT0dKxZs0buYgG4edPKyivC+z+cqfe8Mflf7VWqxbRYGJMT1u0+Mx5v9ahuiI8MRlGp9VlOGjtLXVjjSouKlJmfGyLj9bpy/QaW9AL+9q+DiGkUwutFROQgnw58/ve//5k9Dg4OxurVq7F69Wp5CmSFmKUqnFlOQdzSDvmYNTQJEzOO1FvawXgGW0tdSMFesFY7+CPz66UOuLmd14uIyHE+l8DQ1ziyVIWjyf/EL+0QZHFpB01ksMdvmlJkkm7IeL2IiNzLp1t8vJ2zS1Vs+3OtK2tjXozdZttErol18VoFHuja3OExOXXH4HRrEe7gO6nPkUzSHJjM60VE5G4MfCTk7FIV/84+i39nn7U45sWZFd7rLu0ghqXztIpWY2p70ae1SIpZZg0ZrxcRkXuxq0tCrt6M6q527ugK7wrUDBh2dOCytfMU/5kMcEe+8yveSzXLrKHi9SIici8GPhJy9WYk/PlvzuZcfHfiD8z47GfR3WbODlwWM6bk9W2/OD2mpFdiDOIjg2GtRM4Gaw0VrxcRkXsx8JGQvZuWWMXXqvD4+wdw9Yb4xeCcHbgspnuuSOv86usBSgXmDEsCgHrXRa5ZZt6M14uIyL0Y+EjI1k1LKn9NbYWPxvfB99P7OzVbyxNjSoxZrL1hlpkv4PUiInIfDm6WmLWlKqRyb3K8S7N7PDWmxB2Zn/2J8XrtO3URl/L34f0xPZm5mYjICWzx8YDByfH4fnp//OeJXpKdw9pYD71BQPbpy9iccx7Zpy/bHZsjpntOE2F5TIm9c9V93ni+puHBuHitpvuM+WisC1AqTNfd34JERz/HRETWsMXHQwKUCqzZfVKSY1sb6+HMshDG7rkJG61nep5xb/t6N11757L0fFRozUq6V8t1Fl9DBHB5EyJyL7b4eMiir/OQ/WuJJMfWRAZj9ahuiAwJMv0i/vqnCxanpNedIm+JtTElcRE1j9M6xJlttzb93XiuRV/nWXz+arnOLOgRWz7yH/Y+W/ycEJGj2OLjAVXVBrz7XYEkx37unlvRPj4CC7aa/yJWKmBzDS97a4JZGoPTrUU4vsncZrafmOnv735XIHoavjNrllHDJGYtOn5OiMhRDHw84D/ZZyDVkISVu05Z3G7rfGKXOaib6Vmnqz+dXsz0d0ffO5dhIIDLdRCRNBj4eMDZK+VyF8EidyxzIOVSCXIuw1B3nTJvGUxsHNT79c+FaBoZ5jXlkgKX6yAiKTDw8YBWMaFyF8GiS9cqsTnnvN0buykIKC0zPVb9+ZyUSyU4emxHgxVr+1saTBsTpsKrDyRjSOdmTr8fV8tXUlaFxduOYWp7YNpnP6FSr/DoIF9PB4NcroOIpMDAxwMeT22NhV/nO9zlExWicihbsyOUCmDB1nzTY2s30NpBgDpAwJJeQPqKPZg5tCMGJ8ebpr8XlVZYHcejVACCYHnMkSUK1AzYdmQZBkdn/ljb//4u8Vi/p/6YpCtlOjyT8SOe+v0qZg5JEl0ud5YPANQB5iUzDvKVOpGhHDOrjJ8tW91dXK6DiBzFWV0eEBSoxPg7Ex1+3RN9HX+NWHWDsLqzZPQGAW/tOImnrSxWatzX3pIKCsD03sW0DYhdhqF2Xpe3dpx0aOaPtZlChaUVeMdC0FPbO3sK8PVP5sezl2PG0ZlJjixGazzTvC15kuW2kWtmVYBSgfu72A6q7u8S32C7+ohIGmzx8RBjK8E7e8TN7tJEqDGp/61o2zQMkz760W2Do5UKy4ONa8+SMRgEzP8qD0XaSovHqH2zHZiksZqdWlOnReDd7wog1Dq3QgGEqAJQXqW3+hpLrLWG2HpPxpk/tmYKiTVrcy7SkzVWu8Vqt4Q4OjPJmfJJOchXzplVeoOAL4/aDqq+PFqIaYM7MPghItEY+HhQt5bRiAk9jyvlVXb3fbRXSwQoFRjSuRlWQYFnMo64fP7H+7TEf/ads/q88Qb6TMaPdo9V92ZrawmKzNxCi91HggDcqNJjSlo7tI4NFTVuxNj64Mj0+NrlFDMLzZ7LZVU4UHAFpTeqLJaldvdTZEiQQzOTXCmfFIN85ZxZJeZacFYXETmKgY+HOHrDbh0bZhpMWlmtR3CgEhXVBpfKoFC4/1dx7Ztt3envgO0WA6OPD57D99P72/3VXlVtwEuf5zrVWmMsp7uCg6LSG1jyzXG7LSHT0m/zWPmkGOQr58wqzuoiIikw8PEAZ7ovzlwqxx2Ld7p1YVMpZpfZu9m6q8UgM7cQL33+M66UOTfY21hOdwUHV8qqRL2vK2X2W/dql8uZ8jkzGFwsOWdWcVYXEUmBg5s9wJHuCwVq1rBaseOEW4MeTYQaj6e2trsAqVjWFkWtyx2/2o2tZc4EPXXLKWYRVnviI4MR00gtat+YRmqb53O1fGIHgzvLXnnEfg587dxE1HAx8PEAR5riBQCCILg0+NaSufd3RFCg0uYMLEeJudm6+qvdlcHIloICMbPQBiY1tXnMOcOSoIkQ9740EcF2r7nY8lk8fmSwpFPZ7V0vQLqgS85zE1HDxcDHAxxtii+9Ue22c4cGBWBKWlsMTNIAsL4AqSYyGGtGdUd8pP2yaiLE32xd/dXuymBfa0GBrWuwdnR3vPvXnlgzqjtiwoLMno+vdTxH3pe984ktX3xkMJY93AUAsGREZ3w0vg++n95f8uSFjpa/oZybiBomjvHxgBKR4zxccXe7WNxxayzaxYXj44O/Yc+JP1BWpUd5lR7Ld5zExwd/M02xtjQDK6VVNA6fLUFSfLjdQOObyXchWB1kcx8j46/2CRuPQAHzJIZifrU7OnB1SlpbtI4NsztDzNY1MGaz3jdzAA6fLak3S8046HxIsgbv/XCm3rEtvS9bs97Elq9XYgwM+mp8fRYY0ikeKpXK4mul4Gj5G8q5iajhYeAjMb1BwIKteZId35iXZ/eJS9h94hKiQlW4Wl5/LIylDL8Gg4CTxdeQmVuEiRlHRA/EdZTYPD+WiG0taxwWhIUPJjvUAlB7FlpmbiHufmOXxXw8D3RtbtpmKW9P3dxI1t6XpVlvYstnZNBb2dkDHC1/Qzm3L/PWNeeI5MTAR2LuyBtTV0yYCg90bY4NP9Rf9d1S0APUT1D40ue5Ti+HcfhsCfq2i7P4nLUvWmd/tYtZEiMmTIXsmQMQFOhcz621VAN1g0Vr+xmTMv6tb2sMTNLw5kJeQY5lRoh8AQMfiUmRY+TxPq3xyaHfHH6dIwkKbbl03XJGZ3tftM78ahfTVfbag52cDnrEZibu3z7O7n7bcovw8lAOtiX5iQ3mifyRy4Obc3NzsXr1aqxcuRKHDx92R5kalNgwcdOeHaE3GNzeiuSIWAtTuaVcz0nKAa5i8wz9J/uM6HxERHKyF8wD0q7tRuTtXGrxWb16NebPn4+7774bOp0Os2bNwrRp0/Dyyy+7q3y+T5If//K0KBjPmtIq2my7J9ZzkmqAq9gWubNXyt16PCKpyLnMCJEvcKjF57ffzLtXVq1ahWPHjuGTTz7B559/jszMTKxYscKd5TNZtGgRevbsifDwcDRt2hTDhw/H8ePHzfapqKjAxIkT0bhxYzRq1AgjRoxAcXGxJOURy1q3kDOMU6Tl+LKqHV7UDTYc+aJ1hbGr7IGuzZHaprFbupTEDp4Wm/WaWYRJblzqg8g2hwKftLQ0vPXWWxD+HM3ZuHFjZGZmorKyEteuXcOOHTvQpEkTSQq6e/duTJw4Efv27UNWVhZ0Oh0GDRqEsrIy0z5TpkzBli1b8Omnn2L37t24cOECHnroIUnKI5a7b4RzhiWhzy2N3ZaBWSxNZDCWP9LV4nO+/EUrNh+PvazXzCJM3oJLfRDZ5lDgc/DgQRw/fhy9e/dGTk4O1q9fj+XLlyMkJARRUVHYtGkT/vWvf0lS0MzMTIwdOxYdO3ZEly5d8MEHH+DcuXOmcUWlpaV47733sGzZMvTv3x8pKSnYsGED9u7di3379klSJjHcsUQCULPkhHE8i6PZfY3uaut4S9G9yRpTory0DpZncvnyF63Y7MBisl4zizB5Ay71QWSbQ2N8IiIisGbNGuzduxdjx45F//798d1330Gv10Ov1yMqKkqiYtZXWloKAIiJqfnjPXz4MHQ6HdLS0kz7tG/fHi1btkR2djb69Olj8TiVlZWorLzZHaXVagEAOp0OOp1z073rmj30NkzZlOP0MhQT+92KJ++6BQFKhalMA26LxZpRXbDo619QLLIl5YFOGhwvLBU9jT06RIXlD3dCgFIBg77adO6616Vbi3C0ilajWGt5yrkCQFxEMLq1CHfbNXUn47V8fdsvKNLWyjMUEYwZ97bHgNtiodPpRO8nJWt1QJ7jC3Vg/M4BLM+EnD30Nhj01bLmhXKFL9RBQ+eNdSC2LArB2G/loOrqaixatAgbN27EsmXLMHToUGcO4xSDwYD7778fV69exffffw8AyMjIwBNPPGEWxABAr169cM8992Dx4sUWjzV37lzMmzev3vaMjAyEhrp/NXMiIiJyv/LycowaNQqlpaWIiIiwup9DLT7V1dVYv3498vPz0aVLF7z00kt45JFH8PTTT+ODDz7AqlWrEBdnuTvEnSZOnIjc3FxT0OOKmTNnYurUqabHWq0WCQkJGDRokM0L5wi9QUD6ij1mrQS2RAYH4p7bmqLPLY3xW0k5/nv4dxRfuxnQaSKCMSQ5Dhv2nnW6FaluTpzajC0Ydbu2dDodsrKyMHDgQIvLJezIL7baGmKtm0yKYzRk9uqApOdLdaA3CDh8tgSXrlcitpEaKa2iG0R3rC/VQUPljXVg7LGxx6HAZ9y4cTh48CDuv/9+bNiwAT/99BNWrlyJnTt34r333kNqaipefPFFTJgwwalCizFp0iR89dVX2LNnD1q0aGHartFoUFVVhatXr5p1uRUXF0Oj0Vg9nlqthlpdPy+NSqVyW2UeOn0ZZ0sqIXZEzsUyPTYdKcSmI7Vz39x87dmSSqz97pzo49kyrm9r9G8fByhqZqCJmSZu7drc27kFBiU3d3rKeWZuIZ7JOPpnQHbzNedKKvFMxlEmXavFnZ9Pco4v1IEKsJplvSHwhTpo6LypDsSWw6HBzZs3b8Znn32G119/HVlZWdi6davpuXHjxmHfvn347rvvHCupSIIgYNKkSfj888+xc+dOJCYmmj2fkpIClUqFb7/91rTt+PHjOHfuHFJTUyUpk1jeOJvJ6OvcIvRMjIFSYTs4MS5FAQD7fr2MH05ewuac88g+fdksEZqzU86lTrqmNwjIPn3ZrMyWtrlyPFvbfVFDei9EREYOtfjExcVh+/btaNOmDXbu3InGjc1nCTVt2hQZGRluLaDRxIkTkZGRgc2bNyM8PBxFRUUAgMjISISEhCAyMhLjxo3D1KlTERMTg4iICDz77LNITU21OrDZU7xxNpNRYWkFUl7NwrWKatO2uuv5GJeiuHL9Bpb0Av7+70Oo1N8MaGLCgvDqA8kY0ln6DMrOJF2ztJRGVGjNL4Paa5uJXcfI2tIc93eJx5dHCxvE2khc54mIGiqHWnxWrVqFhQsXIiQkBE8//bRkyQotWbt2LUpLS9GvXz/Ex8eb/m3atMm0z/Lly3HfffdhxIgRuOuuu6DRaPB///d/HiujNSVllTLlWhandtADmC8zYW0pitqulFXhmYwjWPS186vQS5ULyFr5r5br6i3oKmZ5DWvHKyytwDt7CiRZssPTpFx+hIhIbg61+AwcOBDFxcW4dOmSZIkKrREz+Sw4OBirV6/G6tWrPVAicTJzCzEx40enByHLwbjMxJzNuajSC6LL/s6eAnRpEYUhnZs5fE4pcgHZ6j6zxN7yGo4ez3hMAHj581z0bx/n9GKqjjJ2TTo61soTy48QEcnJ4W9hhUJhNej56aefEBQU5HKhGgpnbpTeQgBQfK0KJeWO5Wh4ZXOuU2NBpEi6Zq/7zBJby2s4czyjy2VV6LNoh0daSzJzC3HH4p149N19eP7jHDz67j7csXinqHN7avkRIiK5uPXnpyAI0Ot9NCOWBFy5UfqqK2U6p26KYjMo22tlqD0g94dTfzhcDiNLXWquDlK/UqaTvKvI1W4qd3U5cmA0EXkrl1ZnJ9u8eTaXlJx934OT47F2dPd6g2o1kcGYNTQJkSFB2Jxz3mrXjaUBuc6y1KXmrkHqUnUVuaObyh1djtYGRs8amoTosCCnUh0QEbkLAx8JefNsLik5+771BgGRIUGYln4brpRVIaaRGpqIYJSUVWLBVtszjIwtHa62KyhQE2hZ6lIzdscVlVpemkMMV2an2eOOmXH23qOt6wNYr4fC0go8k3HEbBtniRGRHBwKfOxlRbx27ZpLhWloeiXGIChAiSq9Qe6ieIyzix/amiK+fk9BvRupsetm7ejuGJikwdwvXR9LZa9LzdgdN2HjEZuZr8WQojXQHd1Utt6jvevj6Ji2wtIKPL3xCNaM6ubUgHgiImc4FPhERUVBYSPRnSAINp/3S352OZxZodxWK8E7ewosvqZ2180vhddELwdSW5g6AGWVN8ekaUS0QFjrjjMGaZ8ePo8rZVV2zy1Fa6C7ZsbZ6nK0dX2cHdM26aMfsQoKl/JAETnD2dmP5NscCnx27dolVTkapAMFV1BV7R+tPUoFsOpRx5eUcGXmm7HrZsW3J514NfDq8E7QRAQ7/KU3ODkeA5M0Fr8wXxjUHn0W7cCVMsuz4ex1FbnC1W6q2my9R2ucbcUyCMAzGUewTsklSfyBtwQbTNLpvxwKfO6880688cYb+PLLL1FVVYUBAwZgzpw5CAkJkap8Ps3V7gx1gAKVet+YDbPyka52f7Fb+sKTc+abJiLY6XE2xqU56goKVOK1Bzthwsaa8SyOdBW5ypVuKiNXbkqutmIxP5DvcfTz4i3BhrVW5tpd6Ax+Gi6HAp+FCxdi7ty5SEtLQ0hICN566y1cvHgR77//vlTl82mu3gi8LeiJDlEBsJyuYOG2XxAYqLT6ZWHtC6+9JlyKotokZasL4HxXkdzndvWm5Orgb6kGfZM0HP28eEuwwSSd5FDg8+9//xtr1qzBU089BQDYsWMHhg4din/+859QKj2TkdaXdE2IkrsIbvPykA54vHcLfJO5zeLztr68bI3h8XRrj9StLkbOdBXJeW533JTcMfjbX1NA+BpHPy/eFGxIuS4g+QaHopVz585hyJAhpsdpaWlQKBS4cOGC2wvWEGTsPyt3Edym9IbtDM7WVlCXKnu1s1+Nmshgj/2ydHalek+f295NCahfr9YYW5w0kc61dvprCghf4sznxZsygku1LiD5DodafKqrqxEcbP7FpFKpoNM5tqyBvzh7pVzuIriRgMNnS+zsUf+XklRjeGqSGnbAK5uPiZpFNbxrMzyckoA+tYIAbxlkKTd3/wK21OJ0+VoFntuUA2uxk9Tdj3JqaJ8zZz4v3hRsSLEuIPkWhwIfQRAwduxYqNVq07aKigo8/fTTCAsLM23zhhXRvUGrmFC5i+A2JeVV2J5XhO4ivq+LtBXIPn0ZF69V4GSxe3M7/TW1Fe5NjjfdPA6dLcH7P5yx+7ovci5gf8EV0/gDbxlk6Q2kuClZGvytVCrrJTEEPNf9KIeG+Dlz5vPiTcGGO2c/km9yqKtrzJgxaNq0KSIjI03/Ro8ejWbNmpltoxqPp7ZGQ/ke/3D/b/j44G+i9n3li59NC2Su2nXareW4NznerOtmYJJG9GuN4w8WfZ3n0npWDY2nbkpDOsdj3ejuiK/TDebJ7kdPcnXdNG/lzOdFikWIneWudQHJdznU4rNhwwapytEgBQUqMf7ORKtJ+Bqq2kkB3cXarzDjF6qY7jTjIMp3v6ufCbr285YGWTa07oraPPkLWM5B357kTYN53c2Zz4s7Ui24k5wzL0l+XKtLYjOHJOH81Qp89ZNv/rrzBra+GGt/oQL2ZxIJAAQbO1kan9AQuytq8/RNyVoOpIakIc8ccvbz4m3Bhr8E4VQfAx8PGNAhjoGPBUoFLA52rbvd3hej8Qt1xv/9jKvl7hlobxyf4C25R6TmbTclX+dNg3ml4OznxduCDX8Iwqk+Bj4e8MPJP+QugteYdM+tKK+qxvs/nLE6w2flI93QOFzt8BdjqZuCHqBmfEJD7q6wxNtuSr7MmwbzSsXZzwuDDZIbAx+JZeYW4r9Hznv0nK6uHC6l1DaN8Y9Pj1p9XgFg4bZ8fD+9v+gbriO5ghQAFFZamozPG8cnNOTuCmt4U3IPf5k5xM8L+SKmW5aQ8YbsST1bR3tl0GOctQEBbk9k5miuoPF3JtYEQBbKCNwcn9DQuytIOpw5ROS9GPhISI4FOA+esZ1kUA61v+gvlVWKeo0jwYTYfaNCVFg7ujtmDkmymF247rRqf+iuIOlYy2LdUKfvE/kKdnVJiC0BNWoPeMw+fVnUa8QGE3qDgEvXxAVTqx/rjr63xgIQNz7BX7orSDocN0XkfRj4SMiXWgLcPS4oJkyFWfd1hCbC/Iu+V2IMNBFqFGktByuOBBOWppnbOmafW8zHItgbn+BtuUfIN3EcDJF3YVeXhIwtBr5AAPD/ujd32/GulOmgiQiut0BmVl4RKqoNFl9jL5jQGwRkn76MzTnnsSLrBJ62kBXX0WPa05C7K2pfz+zTl0UtQkpE5OvY4iMhY4vB0xvrr0/kje5s1wRpSXF46fOfcaXM9anhdbv6rOXEMYoMVeH1hzpZDCbEtu7U5Y48NA2xu6KhJ2UkIrKGgY/EBifHo0/rGOw7I36Wklxiw9SAAkhpGY2s/IvuOd6fxEw5D1EFWFx7y17AZM2soR0wtm+iWwIUX+yusLbMhr8kZSQisoSBj8Qycwu9PuhRoKa1ZeJHR9yW+RgAXvj0KGbf1wGRoUH49NBvdltrCksrsGrnSTyf1s60zZEcPXXFhqt9ulXGFdZadGYN7YAFW/MbTFLGhryGGhFJg4GPhPQGAVM/sZ6szxsYB+26M+AxKtJW4JmMHx16zfIdJ3GbJtzU4uBKSgBbg8v1BgH7fr385ywzAam3xKJPnfFIvspWi469+vClpIzsriMiZzDwkdDek5dQXuX+lcrdKS5CjYpqgySBj7Nqtzg4mxIg3sbMsMzcwnrreq3adRpRNsYY+Qp7y2yI5e2pGNhdR0TO4qwuCX165He5i2DR/+veAm+N7IqPxvfB4oc6e1XQA5hnbo5tpLazt2XWZnFl5hbi6Y2Wu/Suluvw9MYjyMx1bEFZb5od5a6kmd6cikFMcDdvSx5nqRGRRWzxkdDxIq3cRbDov0d+R0JMCL7MOY9vf/HOBVQvXqtAZm4h5n55zKHXKRXAqkct/9rXGwTM/dL+EiJzvzwmeoyLt3W3uNpS4wtJGf1xDTUicp8G2eKzevVqtG7dGsHBwejduzcOHDggSzkaqb03rly+46TXBj0AcOZSGSZsPGI10aE1qx7thiGdLQccBwquoEhrPzAo0laKWivM2N1S9yZs7G6x1HIkdeuQIy01vrqGFNdQIyJXNLjAZ9OmTZg6dSrmzJmDI0eOoEuXLkhPT8fFi65Pz3bUoI5xHj9nQxAVqsJHB845NCZFE6HGlLS20P0ZWFgKKNyx/pcxcPn8yO946fNch7pbMnMLccfinXj03X14/uMcPPruPtyxeKfDXWu2GJNmWgtbjIvFrhnlu0kZuYYaEbnCe5sknLRs2TKMHz8eTzzxBABg3bp12Lp1K95//33MmDHDo2V5ou8tWLTtuEfP2RBU6wUUldtv6WmkDsBfeiQgMiQIHx04h+U7Tpqes9Td5MiN0NK+jiRRrNvdInYwbt3p2SmtonH4bInpcbcW4TbPa2uZDWO5Zg3tgCGd45Ge7JtJGRvaGmqckk/kWQ0q8KmqqsLhw4cxc+ZM0zalUom0tDRkZ2dbfE1lZSUqK2/eZLXamnE5Op0OOp1rg34VADo0DcWvl8tcOo63UCsFs/9KRVetgzpAzH7V+HBfgelx7deUXL+ByR8dxvJHuiKtQ03LW7cW4WgZpUaxnZafuHA1urUIN6v/HfnFmLIpB0Kd89hzsbQMFZXhWLT1GIICLF83BYBFW49BX63Hkm9+MeuOUyqA2o1XLaPUmNQONj+bA26LxZpRXfD6tl8sdu0t3pYHBQxI6xCHHi0jAEQAAAz6ahi8exKiyeyht2HKphwAltdQmz30Nsnej/Hau/r9ANR8rurWkyYiGDPubW/63FJ97qwDco431oHYsigEQWgwUx8uXLiA5s2bY+/evUhNTTVtnzZtGnbv3o39+/fXe83cuXMxb968etszMjIQGhoqaXmJiIjIPcrLyzFq1CiUlpYiIiLC6n4NqsXHGTNnzsTUqVNNj7VaLRISEjBo0CCbF06sbblFePG/3p3EUCy1UsCCHgZklTZF1vHLkp4rOlSFq+U6t6wYHx2qwpxhHU2/oHfkF2Pul8dw9Yb5r4O6XUPGX94RwSr87V8HHTqnAkBcRDC+mXwXvjlWhGmf/eTam/iTsQ5WnQjFlufuttolojcISF+xx+pg7trlC1AqfKblwVI5o0NVGNapGfq1b4qUVtGSdxPpdDpkZWVh4MCBUKlUTh3D0frxdnqDgMNnS3DpeiViG6klrwd31AHZZ+t74e5bY7yuDow9NvY0qMAnNjYWAQEBKC4uNtteXFwMjab+GlAAoFaroVbXzxWjUqlcrszM3EI8t+kn1J8/49t+unAdlXrp3pNSAbwyNBnPfpzjlsCn6Fo1nsk4ahpHo1AGQKEMQKW+2ubrzpVU4pmMo3iib2uH3q9xz5lDOyJYHYSmkWFuv17nrlbix9+vWZ2ufej0ZZwtqYStz97ZkppjlN6owjMZR/+81jf3N75/bxnwnJlbaLGcxdeq8c+955BySyyC1UEeK48r3xGO1I+3T8mXM6WDO76nyTJrf2/G74U1o7oA8K46EFuOBjWrKygoCCkpKfj2229N2wwGA7799luzri9PEJszxhcVX3NsirmjDALQOLxmhlFMmPv+oOZtycPXP10QPU3eGHRtzrng0Hnqzo6yN9PKWbZmqYmdwVakrfCJZIANLWlhQ5mS70xKB/J+Yv7eXt/2iyeL5FYNKvABgKlTp+Ldd9/Fv/71L+Tn52PChAkoKyszzfLyFLE5Y8iyi9cqMDg5HvtmpiEmzPVf8cZZVq9stjwF3dbrLpdVISZMZTNwiQlTYfkjNdmwv5/e3+yXrnGmFWA9d44zbM1SEzuD7cr1StHJAOXkSNJCX9AQpuQ3tGCUbhLz9+bL97cGF/g88sgjWLp0KWbPno2uXbsiJycHmZmZiIvz7DgFb/+l5u2MX/hBgUq89mCy2457pcy5GQh9EmNMq5fXpvjz32sPdsKD3Zoj1cpCp4OT47F2tOXcOWtGdXO4RUgTYXu6tth8PmKDSrk/zw2lhcRIbP1485T8hhaM0k2+8nfkrAY1xsdo0qRJmDRpkqxl8OZfas5S1PmvVJQKIKVVtOnx4OR4rBnVHZM+OgK5fjx+nVuMqNCabrfa63xpHBjLMDg5HgOTLOfOUSoVVnPv1Ga89jPubW9z8KitfD61MzRHhogLfOT+PDeEFpLaxNaPNw9sbmjBKN3kK39HzmpwLT7eoldiDDQRDefDU/vLWerYwyAAh8+WmG0b0jke4+5o7fQxFQAau9hlVlquQ2m5DlPS2pkWea3brWVPgFKB1DaN8UBX89Yhay1Cde97cX9+psTMtLLVymQcg+QrLQ++Uk5HiKkfb9bQglG6Sczfmy/f3xpki483CFAqMPf+JDy98YjcRXELTWQwDPpqAJ7JcFf3V2JmbiH++d0Zp45l/ONd8EAyFmzNs5rx1x5jV9fHB8/h++n93fprXG8QEBkShGnpt+FKWRViGqmhibCcufmbzG2ij2urlQnwnZYHXymno+zVjzdraBm06SYxf28z7m2PqoLDMpTOdQx8JDQ4OR5T0tph+Y4TchfFZRU6PcorPZehs/avRFuDKMWo3R2lVEJUl5I1Uqz8bWs6cFCg0uw8zmRJNbYyWWNseahbBke68TzBV8rpKHv1460aajBKNez9vQ24LRZfF9g4gBdj4COxSf1vxTt7TqG8yiB3UVxSUi5uGQl3iAlTmf1KtDeI0p6l/68L+raNBWD9jzk+MhizhiYhr1CLVbtO2T2mK+MWaq/NdOZSmdkaY0Z11/CSmq+0PNQtZ2wjNSAAl8oqkX36sleWuSFrqMEo1bD1veBNS1U4ioGPxLLyinw+6PG0B7s2N7t5uTo48lKZec4eW3/M0WFBogIfZ8ctiF3o1NitNm9LHgYmaTxyM/eVlgdjOTNzC/GPT4/KkjiPbvKVoJmc4yvfC45g4COhhpzEUEppSRqzVpFLLiZMtBSkWPtjlnLcgrUV2q2RolutoRC72j15RkO8OZL71f5elzNAZuAjIX9OYhgRHAhthe0lIeoyBhUlZVW4Y/FOs1/ydVcpF8vRmT5SjVtwZZwSpwObs5c4z9MtZURkn5xLm9TF6ewS8ucb1pxhHR1Kymfc7/4u8ZiYUT8FvrP5e5wJUgYnx2P1qO6IrjP93ZVpxq6MU+J0YHNMnEfkW7xtaRMGPhLy5xtWwaXrGNkzwWK2Y0s0kcFYPaobvjxaaLNVxJEY5r7O8Q4FKXqDgOzTl7FgyzG8svlnXCmrMj0XE6bCrKEdnP5l4koQXFIm7dpovoaJ84h8hzcubcKuLgkZkxj6Y3fXql2nAcBituOaGVQdEB2mNuvrFdMqYhCAl4d0wOpdp3D1hu1ZBV/9VIj7OheKClbsDTouKdNhYsaPWKtUOBX8uBIEL9iaj/TkeHbb/ImJ84h8hyMttJ4aJ8bAR0IBSgUe6BqPd/Z4b7KDsKAAlFVJl5Sw9M+AZ0paO7SODbU5oE3sL/SmEWq8PqKT3YHCYsd6iBl07OrYEXuDpm3hAGdzTJxH5Du8sYWWXV0S0hsEfHnUc32XISolglWOVWnXhEiJSlPDeGP6+OA53Ne5mdVFPAHHfskPTo7H5LR2ds9tb6yHI4OOXRk7YmuFdjHYbXOTmNXuG1riPGM37Oac88g+fZkrnpPP8MYWWrb4SMjVxHtiJMWHo3uraFRU6fH9qcsOd6v9cFr6AaBimzId/SVfeqPKwl712QoanKmj2sdzZHqmtWRvYrDbxpw/Jc7zptkwRI7yxhZaBj4S8sSv9LzCa8grvCb5edzB3vVwZCp5Zm4h3v/hjKjz2goanKkj4/GcuSFZyjz8wic5KNZWes2Xgq/wh8R5zFdEvs4blzZhV5eE+CvdnJjrIWbFamP3lBj28vg4WkfG47kyPbP2Cu19b43F3Ps7ArDcBSYAmDW0Q4O6mbuTtdXuGwJvnA1D5Awx3+uexBYfCbkyoLUhcbTVwt4veUe6p+z9kuiVGIPw4EBcE5ls0Ti2xJ0J9Ox1gS3Ymg+lk7PJyHd542wYImd5UwstW3wkFKBU4P4u8T4b9ET/ORXdlY+ls02Ztn7Ji+2eGte3td1gIUCpQPeW0aKO169dLAYnx0uSQG9wcjxmDU2y+JxcSb5IXt44G4bIFd7SQsvAR0KZuYVY78VT2S0JDw7E3/q2xkfj++DQKwOxzkLzpC2N6izhXrcp0x2zU8R2T6UlaUTtd9efK7fbc2fbJgCkuSHpDQIWbLXcfcduDf/kjbNhiBoCdnVJxJW1meR0vaIaG344Y2qCNDZP7jt9GVM/PgzAes6fqFAVDryUhsNnSyw2Zbprdoq7Zwk8ntoaC7/Ot7kshlJRsx8gzQ1JbCvS4bMloo9Jvs0bZ8MQNQRs8ZGIJ6ayS8FS60KAUoG+bWMx9wHrg3AB4PWHOiEoUGmxKdOda7W4O49LUKAS4+9MtLnP+DsTERRY8+divCFZO7oCji+OKrZ16NJ1Ll/hL/wxXxGRJzDwkYgv97tbG6OS1iEOABAXYd6SER8ZjHU2RuZLMTvF3bMEZg5JwlN3JdZbC0ypAJ66KxEzh9wcfyPFDUls61BsI7XoY5Lv87bZMEQNAbu6JCJ1v/vQTnE4fPYqirQ3WwA0EWo82qsldHoBq3adcvkc1oK3bybfhR9/vyZ6ZL5Us1PcPUtg5pAkvDCoPf6TfQZnr5SjVUwoHk9tbWrpqXtudybQE9utkdIqGt/kO/jGyKd502wYooaAgY9EpJzK/sTtrTCoYzzSkipw5XolokJUuHpDh5hGamgiam6Onx353eWutkvXKrE557zpi9bIODJfLClnpzhaFnuCApUYd+ctovZ15w3JG5N8kfdw9+dcKo5kMieSCwMfidi6kbnqv0fOY8Pes6bHSgXMBubGRwYjuXmEzcAnKlSF0nKd1XIpFTX5Y2ofc/bQ25wqr6ODgb31y9Naudx1QxLTiqTT2V6RnkguXFqDfAUDHwkZb2Rzvzxm1iXlqrrJ9uoOjSksrbAZ9Dx1VyK6tYy2GZTVPWZRaQWmbMrB4l6Ol9eR2SlSfnm6ElB56kud3Rrki7i0BvkSBj4SG5wcj2O/l+Lt/52WuygAaoKML48WYtrgDhZbF+q2HhnV3qQ3CFA5cE6x3ThZeUWSfXm6ErjY+1KfnNYOrWND3RakiGlF0hsEHDp9mcEReVzdHxApraLdmsmcSGoMfCSWmVvoNUEPYD6QuG7rwqVrlWbdW5ZeCwCHz5agb7s4h85rrxtnYJIGdyzeKcmXpyu/RsXMSFu+44Rpm6ea9tNX7MHZkputiOxSIE+w9AMiJiwIV8qqrL6GS2uQt2HgIyFHFtP0NONA4tqtC5tzzot6rbO5ZGx142SfvizJzC97gYu9gMrRfExSN+3vyC+uOY+2ArUn07NLgaRm7QeEraCnNl9O8UENC/P4SMibkxhaGnDsiVwy1tZqkWrml6vrajl6PimXl9AbBLy+7RePn5fIHZnoubQGeQsGPhLyxl84trIKi8lIDAAprcQt6ukIqdYlcjWgcubL2plFSsU4UHDlz5Yez56XyJUfcc5kMieSkk8EPmfOnMG4ceOQmJiIkJAQtGnTBnPmzEFVlXkT608//YQ777wTwcHBSEhIwJIlS2QqcQ13/sJxx5hAe/lgxGQkNu7nblIsAwG4HlDZK5ct7g58uVo3ycXZzxRzUJE38onA55dffoHBYMA777yDY8eOYfny5Vi3bh1eeukl0z5arRaDBg1Cq1atcPjwYbzxxhuYO3cu1q9fL1u5U1pFuyVgAWB3Lam6woICoIkw75ISk+beWor8yBAVnunXxqEyOEKqdYlcDahslcsedzftc7VukovYz1RMmPl8Ty6tQd7IJwY3Dx48GIMHDzY9vuWWW3D8+HGsXbsWS5cuBQB8+OGHqKqqwvvvv4+goCB07NgROTk5WLZsGZ588klZyn34bInNFb/FiA5VYdFDnTA4OR6hQYFYvuOkqNe9+ZcuTueDMQ5CXrXzFDb8UICrN3S4ekOH1f87jSW9agbY3tu5hWtvzMp53bkMBOCejMjWymWNVKtm90qMgSYiGECZR89LJDYX1+4X78HhsyVMs0BezScCH0tKS0sRE3PzCz47Oxt33XUXgoKCTNvS09OxePFilJSUIDra8riUyspKVFbenKWk1WoBADqdzuUsuRdLy6AOEB/5aCKC8WC35jAYDAAU6JkYg56ta744dDodnrqzNT47dA7FNpqdlQpg6f/rggG3xcKgr0aPlhEAIgAABn01DHpxZdmRX4y1u45DAKAOqNmmVta8lxmf/gjg5qKl7jTgtlj0a3snDp8twaXrlYhtpEZKq2jTNXD2mGtGdcHr234xGyOjiQjGjHvbY8BtsXaPXbdcZy+XYfX/TlsNpmYPvc2h6y3W9PS20J3NQbDS/HMl9XnpJuNnxd+yaM8eehumbMoBYP0zrxD0Tn/nOMJf68CbeGMdiC2LQhAEn5sCcurUKaSkpGDp0qUYP348AGDQoEFITEzEO++8Y9ovLy8PHTt2RF5eHjp06GDxWHPnzsW8efPqbc/IyEBoaKg0b4CIiIjcqry8HKNGjUJpaSkiIiKs7idri8+MGTOwePFim/vk5+ejffv2psfnz5/H4MGD8fDDD5uCHlfMnDkTU6dONT3WarVISEjAoEGDbF44MfQGAekr9qBYa715OCpEhaBAJYqv1V5lvaYlonaLyo78Yiz6+herrT2WXuOsAwVX8Ld/Hay3Xa0UsKCHAbMOKVFpUOD9MT0tdqvsyC+22roiRSuRnPQGwWLrlFR0Oh2ysrIwIC0NR89f99h56SZjHQwcOBAqlSM5zBsGT3/mLfH3OvAG3lgHxh4be2QNfF544QWMHTvW5j633HJzpewLFy7gnnvuwe23315v0LJGo0FxcbHZNuNjjUZj9fhqtRpqdf28NCqVyuXKVAGYObQjJmw8AqB+87AAoOh6da0tNc6VVOKZjKOmQYGZuYWYkHG03n5GU9LaYlL/tm778rlUXo1KvfVjVRoUqNQrcKm8ut41yswtxDMZR/98r9bfU0OhAhzOYu0O6qAgWc5LN7njO8IXyfWZt8Rf68CbeFMdiC2HrLO6mjRpgvbt29v8Zxyzc/78efTr1w8pKSnYsGEDlErzoqempmLPnj1mfXxZWVm47bbbrI7v8QRrs6Q0kcGICrVcSbWT0VVVGzDj/362eY4P9p5xQ0lvcnb2kJjlHZhgj4iI5OQTg5uNQU+rVq2wdOlS/PHHH6bnjK05o0aNwrx58zBu3DhMnz4dubm5eOutt7B8+XK5im1iaakGg0HAY+/tt/oaYzK6f+09g6vltgdslZTrsO/Xy+h7a6xbyitmBoelKeCOZEnmmj1ERCQHnwh8srKycOrUKZw6dQotWphPozaOzY6MjMT27dsxceJEpKSkIDY2FrNnz5ZtKntddVfcFrsu1sEzl0Xtl33afYGPrSngRpamgDPBHhEReTufCHzGjh1rdywQAHTu3Bnfffed9AVygt4gmLX4xIaJW+8qNEhsFbm3+8hW7prlj3S1OE6HCfaIiMjb+UTg4+sycwvrBRAxYUEIDQpAeZXlJBfGhGAjurfAFzkX7J4j9Rb3tPbUVreLLjY0EJfy91mdmZXSKhoxYUFWV2tmgj0iIpIbAx+JZeYWYsLGI/XaY6wFB4B5RuHbb41FVKjK5jifqFAV+kg0ZqZ2F51Op8PX+Zb3MwZ3toIegGv2EBGRvHxirS5fZWuWky2117cJUCrw2vBkm/untW+KL49eQPbpy7LMmDIGd7YGNnPNHiIi8gZs8ZGQvVlOdUWFqrD60e7o06axqVUkM7cQC7ZaaWb503+PnMd/j9QMlo53YV0rZ4gJ7mLCVNj94j0ICmScTURE8uKdSEKOzl66Wq6DUqkwC3rstaTUVVhagQkbjyAzt9DmfnqDgOzTl7E557xLLUVigrsrZTocPlvi1PGJiIjciS0+EnJm9pIxWHK2m8xo3pY8DEzSWBxPY2mwtbMtRZzCTkREvoQtPhIyJgJ0ZCivMVhytJusttqJAuuy1opUJLKlyFp53bUfERGRlBj4SMiYCBCwtMKWubrZkN3RQlL3GFIsKWEvuLOW5ZmIiEgODHwkZm2tLktqT/U+c6nM5XPXbWVxZEkJsWwFd5zCTkRE3oaBjwcMTo7HrKEdbO6T0ioKldUGZJ++jK9yLmD5jpNOn89aK4tU43FsLcTKKexERORNOLjZA/QGwe6U9ENnr+LQ2Ry3ndNSK4uU43EsLcTaKzGGLT1ERORVGPh4gCsDlR1la3aWmFXXXVlSou5CrERERN6GgY8HSDmV+4nbW6FFdChiGqmhibDdymJr1XWOxyEiIn/AwMcDpJjK3TgsCAsfTHZ4/Iy1Vdc1Hs74TEREJAcGPh7QKzHG5qrljooJUyF75gCnl4DgeBwiIvJXDHw8IECpwKsPJOOZjCNuOd5rD3Zyed0rjschIiJ/xOnsHjKkczyeuivRpWMoFcCaUd1c6o5y1xpdJC3WExGRNNji40EzhyShS4sovLI5F1fKdA6/ftWj3TGks/NBjzvX6CLp2KqnAbfFylgyIiLfxxYfDxvSuRkOvjzQbkLD2qJCVVg32vWgx51rdJE07NXTjvximUpGRNQwMPCRQYBSgbF9E0UvYBqiCsDAJI3NfWx1jUixRpfYc5N4Yurp9W2/eLJIREQNDru6ZGLMqfP0RvsDno3rZ1kbjGyvC8uRNbocHfDM7jP3EVNPRVrPJMIkImqo2OIjo8HJ8fhb39ai9rWWBFFMF5ZUa3Sx+8y9pEx0SURENRj4yMxeF5aRpSSIYruwYhupnT6HNVJ3n/kjKRJdEhGROQY+MuuVGANNhPXAxNpK64C4rpHC0gpAgM3xRLbOYY0j3WckjnEtNVv1pIlgcERE5AoGPjLLyitCRbXB4nP21s9ypAtrZM8EqwuTWjqHvQHLUnWf+TPjuC8A9YIf4+MZ97b3aJmIiBoaDm6WkXGMjLXOoMhQFV5/qJPVQcJiu0YWbM23ulyGpTW6rA1Ynj30NofPze4bx9hbS23AbbH4ukDGAhIR+TgGPjKxNUbGyN40dmPXSFFphc3jWAt6pqS1w6T+t5q19FgLxopKKzBlUw4W9xJ3bgVqbtaOdJ9RDVtrqel0jie+JCKim9jVJRN7Y2QA+2NkbHWN2KMA8PHBc2bbxAxYNu4nplvGWhcd2WdcS+2Brs2R2qYxryMRkZsw8PEw49iZbSKnetsbI2PsGtFEmncpxYSpbL7O0uBjMQOWAeDw2RKb59ZEBmPt6O7M40NERF6HXV0eZGnsjD1ixshY6hop0tZ0TdlTO7ASOxD50vVKm+c2dssQERF5GwY+HmJvIHNdjo6RMXaNGGWfvizqdbUDK7EDkevmBap7blfoDQKDKCIikozPdXVVVlaia9euUCgUyMnJMXvup59+wp133ong4GAkJCRgyZIl8hSyDjEDmWtzxxgZMTlh6ubuEfMaAEhpFe1UmezJzC3EHYt34tF39+H5j3Pw6Lv7cMfincwATUREbuNzgc+0adPQrFmzetu1Wi0GDRqEVq1a4fDhw3jjjTcwd+5crF+/XoZSmhMzkLk2d4yRcWbwsZjXGPdzNy5/QUREnuBTgc+2bduwfft2LF26tN5zH374IaqqqvD++++jY8eOGDlyJJ577jksW7ZMhpKaEzt25q+prfDR+D74fnp/twwMHpikweS0dogMMR/obCuwsjVgefkjXV0ukyUNafkLrlRPROTdfGaMT3FxMcaPH48vvvgCoaGh9Z7Pzs7GXXfdhaCgINO29PR0LF68GCUlJYiOttw9U1lZicrKm4N1tVotAECn07ktZ0psaCDUAfZvgOkdmqBHywgY9NUw6F075478Yry+7RfTat7qACAqWIXH+rTEk3e1sZkTZsBtsejX9k4cPluCS9crEdtIjZRW0TDoq5FVALfnkjlQcAVXrt+AOsD6Pleu38C+Uxe9Oi9Q3WsO1CwxMePe9kjrEOeWcxivPfP5yId1ID/Wgfy8sQ7ElkUhCILX/yQVBAFDhgxB37598corr+DMmTNITEzEjz/+iK5duwIABg0ahMTERLzzzjum1+Xl5aFjx47Iy8tDhw4dLB577ty5mDdvXr3tGRkZFgMsIiIi8j7l5eUYNWoUSktLERERYXU/WVt8ZsyYgcWLF9vcJz8/H9u3b8e1a9cwc+ZMt5dh5syZmDp1qumxVqtFQkICBg0aZPPCOWpHfjGmbMqxmuV4+SNd3dIqoDcISF+xx6zVoe654iKC8c3kuxweq6PT6ZCVlYWBAwdCpbKdJ8gRBwqu4G//Omh3v/fH9PTKFh8pr3ldUtUBicc6kB/rQH7eWAfGHht7ZA18XnjhBYwdO9bmPrfccgt27tyJ7OxsqNXm06h79OiBxx57DP/617+g0WhQXFxs9rzxsUZjfdkHtVpd77gAoFKp3FqZ93ZugZzftXj3uwLUHvahVADj70zEvZ1buOU8h05fxtmSStjK5Xy2pBI//n7N6Sno7r42fW5tiphGIXaXv+hza1OvnNruiWtel7vrgBzHOpAf60B+3lQHYssha+DTpEkTNGnSxO5+K1euxKuvvmp6fOHCBaSnp2PTpk3o3bs3ACA1NRUvv/wydDqd6c1nZWXhtttuszq+x5Mycwuxfk9BvRu7IADr9xSgW8totwxo9sVV042zySZsPAIFzJfH8IXlL3zxmhMR+SufmNXVsmVLJCcnm/61a9cOANCmTRu0aFHTUjJq1CgEBQVh3LhxOHbsGDZt2oS33nrLrBtLLp6cteSrq6b78vIXvnrNiYj8kc/M6rInMjIS27dvx8SJE5GSkoLY2FjMnj0bTz75pNxFE7UGlnHdLFe7Qnx51XRfXf7Cl685EZG/8cnAp3Xr1rA0Ga1z58747rvvZCiRbZ7sCvH1biN3Ln/hKb5+zYmI/IlPdHX5Ok93hfhyt5Gv4jUnIvINPtni42vk6Arx1W4jX8ZrTkTk/Rj4eEDtrhBLBAD3d4l3+w3SF7uNfB2vORGRd2NXl4cMTo7Hk3clWn1+/Z4CLsRJREQkMQY+HqI3CPjyqO3AxlcW4iQiIvJVDHw8xJEp7URERCQNBj4ewuy+RERE8mPg4yHM7ktERCQ/Bj4eYpzSbm3elgJAPLP7EhERSYqBj4cYp7QD9dfwZnZfIiIiz2Dg40HM7ktERCQvJjD0MGb3JSIikg8DHxkwuy8REZE82NVFREREfoOBDxEREfkNBj5ERETkNxj4EBERkd9g4ENERER+g4EPERER+Q0GPkREROQ3GPgQERGR32DgQ0RERH6DgQ8RERH5DQY+RERE5DcY+BAREZHfYOBDREREfoOBDxEREfkNBj5ERETkNxj4EBERkd9g4ENERER+w6cCn61bt6J3794ICQlBdHQ0hg8fbvb8uXPnMHToUISGhqJp06Z48cUXUV1dLU9hiYiIyOsEyl0AsT777DOMHz8er732Gvr374/q6mrk5uaantfr9Rg6dCg0Gg327t2LwsJC/PWvf4VKpcJrr70mY8mJiIjIW/hE4FNdXY3nn38eb7zxBsaNG2fanpSUZPr/7du3Iy8vDzt27EBcXBy6du2KBQsWYPr06Zg7dy6CgoLkKDoRERF5EZ8IfI4cOYLz589DqVSiW7duKCoqQteuXfHGG28gOTkZAJCdnY1OnTohLi7O9Lr09HRMmDABx44dQ7du3Sweu7KyEpWVlabHWq0WAKDT6aDT6SR8V77HeD14XeTDOpAf60B+rAP5eWMdiC2LTwQ+v/76KwBg7ty5WLZsGVq3bo0333wT/fr1w4kTJxATE4OioiKzoAeA6XFRUZHVYy9atAjz5s2rt3379u0IDQ1147toOLKysuQugt9jHciPdSA/1oH8vKkOysvLRe0na+AzY8YMLF682OY++fn5MBgMAICXX34ZI0aMAABs2LABLVq0wKeffoqnnnrK6TLMnDkTU6dONT3WarVISEjAoEGDEBER4fRxGyKdToesrCwMHDgQKpVK7uL4JdaB/FgH8mMdyM8b68DYY2OPrIHPCy+8gLFjx9rc55ZbbkFhYSEA8zE9arUat9xyC86dOwcA0Gg0OHDggNlri4uLTc9Zo1aroVar621XqVSSV6beIOBAwRVcvFaBpuHB6JUYgwClQtJzuoMnrg3ZxjqQH+tAfqwD+XlTHYgth6yBT5MmTdCkSRO7+6WkpECtVuP48eO44447ANREm2fOnEGrVq0AAKmpqVi4cCEuXryIpk2bAqhpgouIiDALmLxFZm4h5m3JQ2FphWlbfGQw5gxLwuDkeBlLRkRE1HD5RB6fiIgIPP3005gzZw62b9+O48ePY8KECQCAhx9+GAAwaNAgJCUl4fHHH8fRo0fxzTff4JVXXsHEiRMttujIKTO3EBM2HjELegCgqLQCEzYeQWZuoUwlIyIiath8YnAzALzxxhsIDAzE448/jhs3bqB3797YuXMnoqOjAQABAQH46quvMGHCBKSmpiIsLAxjxozB/PnzZS65Ob1BwLwteRAsPCcAUACYtyUPA5M0PtHtRURE5Et8JvBRqVRYunQpli5danWfVq1a4euvv/ZgqRx3oOBKvZae2gQAhaUVOFBwBaltGnuuYERERH7AJ7q6GpKL16wHPc7sR0REROIx8PGwpuHBbt2PiIiIxGPg42G9EmMQHxkMa6N3FKiZ3dUrMcaTxSIiIvILDHw8LECpwJxhNdPr6wY/xsdzhiVxYDMREZEEGPjIYHByPNaO7g5NpHl3liYyGGtHd2ceHyIiIon4zKyuhmZwcjwGJml8MnMzERGRr2LgI6MApYJT1omIiDyIXV1ERETkNxj4EBERkd9g4ENERER+g4EPERER+Q0GPkREROQ3GPgQERGR32DgQ0RERH6DgQ8RERH5DQY+RERE5DeYubkOQRAAAFqtVuaSeB+dTofy8nJotVqoVCq5i+OXWAfyYx3Ij3UgP2+sA+N923gft4aBTx3Xrl0DACQkJMhcEiIiInLUtWvXEBkZafV5hWAvNPIzBoMBFy5cQHh4OBQKLhham1arRUJCAn777TdERETIXRy/xDqQH+tAfqwD+XljHQiCgGvXrqFZs2ZQKq2P5GGLTx1KpRItWrSQuxheLSIiwms+6P6KdSA/1oH8WAfy87Y6sNXSY8TBzUREROQ3GPgQERGR32DgQ6Kp1WrMmTMHarVa7qL4LdaB/FgH8mMdyM+X64CDm4mIiMhvsMWHiIiI/AYDHyIiIvIbDHyIiIjIbzDwISIiIr/BwIdsWrRoEXr27Inw8HA0bdoUw4cPx/Hjx+Uull97/fXXoVAoMHnyZLmL4nfOnz+P0aNHo3HjxggJCUGnTp1w6NAhuYvlN/R6PWbNmoXExESEhISgTZs2WLBggd21mch5e/bswbBhw9CsWTMoFAp88cUXZs8LgoDZs2cjPj4eISEhSEtLw8mTJ+UprEgMfMim3bt3Y+LEidi3bx+ysrKg0+kwaNAglJWVyV00v3Tw4EG888476Ny5s9xF8TslJSXo27cvVCoVtm3bhry8PLz55puIjo6Wu2h+Y/HixVi7di1WrVqF/Px8LF68GEuWLMHbb78td9EarLKyMnTp0gWrV6+2+PySJUuwcuVKrFu3Dvv370dYWBjS09NRUVHh4ZKKx+ns5JA//vgDTZs2xe7du3HXXXfJXRy/cv36dXTv3h1r1qzBq6++iq5du2LFihVyF8tvzJgxAz/88AO+++47uYvit+677z7ExcXhvffeM20bMWIEQkJCsHHjRhlL5h8UCgU+//xzDB8+HEBNa0+zZs3wwgsv4B//+AcAoLS0FHFxcfjggw8wcuRIGUtrHVt8yCGlpaUAgJiYGJlL4n8mTpyIoUOHIi0tTe6i+KUvv/wSPXr0wMMPP4ymTZuiW7duePfdd+Uull+5/fbb8e233+LEiRMAgKNHj+L777/HvffeK3PJ/FNBQQGKiorMvpMiIyPRu3dvZGdny1gy27hIKYlmMBgwefJk9O3bF8nJyXIXx698/PHHOHLkCA4ePCh3UfzWr7/+irVr12Lq1Kl46aWXcPDgQTz33HMICgrCmDFj5C6eX5gxYwa0Wi3at2+PgIAA6PV6LFy4EI899pjcRfNLRUVFAIC4uDiz7XFxcabnvBEDHxJt4sSJyM3Nxffffy93UfzKb7/9hueffx5ZWVkIDg6Wuzh+y2AwoEePHnjttdcAAN26dUNubi7WrVvHwMdDPvnkE3z44YfIyMhAx44dkZOTg8mTJ6NZs2asAxKNXV0kyqRJk/DVV19h165daNGihdzF8SuHDx/GxYsX0b17dwQGBiIwMBC7d+/GypUrERgYCL1eL3cR/UJ8fDySkpLMtnXo0AHnzp2TqUT+58UXX8SMGTMwcuRIdOrUCY8//jimTJmCRYsWyV00v6TRaAAAxcXFZtuLi4tNz3kjBj5kkyAImDRpEj7//HPs3LkTiYmJchfJ7wwYMAA///wzcnJyTP969OiBxx57DDk5OQgICJC7iH6hb9++9VI5nDhxAq1atZKpRP6nvLwcSqX5bSsgIAAGg0GmEvm3xMREaDQafPvtt6ZtWq0W+/fvR2pqqowls41dXWTTxIkTkZGRgc2bNyM8PNzUbxsZGYmQkBCZS+cfwsPD642pCgsLQ+PGjTnWyoOmTJmC22+/Ha+99hr+8pe/4MCBA1i/fj3Wr18vd9H8xrBhw7Bw4UK0bNkSHTt2xI8//ohly5bhb3/7m9xFa7CuX7+OU6dOmR4XFBQgJycHMTExaNmyJSZPnoxXX30Vbdu2RWJiImbNmoVmzZqZZn55JYHIBgAW/23YsEHuovm1u+++W3j++eflLobf2bJli5CcnCyo1Wqhffv2wvr16+Uukl/RarXC888/L7Rs2VIIDg4WbrnlFuHll18WKisr5S5ag7Vr1y6L94AxY8YIgiAIBoNBmDVrlhAXFyeo1WphwIABwvHjx+UttB3M40NERER+g2N8iIiIyG8w8CEiIiK/wcCHiIiI/AYDHyIiIvIbDHyIiIjIbzDwISIiIr/BwIeIiIj8BgMfIvIr//vf/6BQKHD16lW5i0JEMmDgQ0ReaezYsVAoFFAoFFCpVEhMTMS0adNQUVEh+hj9+vXD5MmTzbbdfvvtKCwsRGRkpJtLTES+gGt1EZHXGjx4MDZs2ACdTofDhw9jzJgxUCgUWLx4sdPHDAoK8uqVo4lIWmzxISKvpVarodFokJCQgOHDhyMtLQ1ZWVkAgMuXL+PRRx9F8+bNERoaik6dOuGjjz4yvXbs2LHYvXs33nrrLVPL0ZkzZ+p1dX3wwQeIiorCN998gw4dOqBRo0YYPHgwCgsLTceqrq7Gc889h6ioKDRu3BjTp0/HmDFjvHshRiKyiIEPEfmE3Nxc7N27F0FBQQCAiooKpKSkYOvWrcjNzcWTTz6Jxx9/HAcOHAAAvPXWW0hNTcX48eNRWFiIwsJCJCQkWDx2eXk5li5div/85z/Ys2cPzp07h3/84x+m5xcvXowPP/wQGzZswA8//ACtVosvvvhC8vdMRO7Hri4i8lpfffUVGjVqhOrqalRWVkKpVGLVqlUAgObNm5sFJ88++yy++eYbfPLJJ+jVqxciIyMRFBSE0NBQu11bOp0O69atQ5s2bQAAkyZNwvz5803Pv/3225g5cyYefPBBAMCqVavw9ddfu/vtEpEHMPAhIq91zz33YO3atSgrK8Py5csRGBiIESNGAAD0ej1ee+01fPLJJzh//jyqqqpQWVmJ0NBQh88TGhpqCnoAID4+HhcvXgQAlJaWori4GL169TI9HxAQgJSUFBgMBhffIRF5Gru6iMhrhYWF4dZbb0WXLl3w/vvvY//+/XjvvfcAAG+88QbeeustTJ8+Hbt27UJOTg7S09NRVVXl8HlUKpXZY4VCAUEQ3PIeiMi7MPAhIp+gVCrx0ksv4ZVXXsGNGzfwww8/4IEHHsDo0aPRpUsX3HLLLThx4oTZa4KCgqDX6106b2RkJOLi4nDw4EHTNr1ejyNHjrh0XCKSBwMfIvIZDz/8MAICArB69Wq0bdsWWVlZ2Lt3L/Lz8/HUU0+huLjYbP/WrVtj//79OHPmDC5duuR019Szzz6LRYsWYfPmzTh+/Dief/55lJSUQKFQuONtEZEHMfAhIp8RGBiISZMmYcmSJXjhhRfQvXt3pKeno1+/ftBoNPWml//jH/9AQEAAkpKS0KRJE5w7d86p806fPh2PPvoo/vrXvyI1NRWNGjVCeno6goOD3fCuiMiTFAI7somIHGIwGNChQwf85S9/wYIFC+QuDhE5gLO6iIjsOHv2LLZv3467774blZWVWLVqFQoKCjBq1Ci5i0ZEDmJXFxGRHUqlEh988AF69uyJvn374ueff8aOHTvQoUMHuYtGRA5iVxcRERH5Dbb4EBERkd9g4ENERER+g4EPERER+Q0GPkREROQ3GPgQERGR32DgQ0RERH6DgQ8RERH5DQY+RERE5DcY+BAREZHf+P/HcsXZeEX3iAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_sims.to_csv('all_sims.csv', index=False)\n",
        "files.download('all_sims.csv')"
      ],
      "metadata": {
        "id": "sh_4SVeXXq3x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "46a3fa4b-603f-4bc3-c8d6-927fb6a5bb9a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_29982b14-0bd8-4902-90b8-fef8a7954b47\", \"all_sims.csv\", 57431)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# correlation\n",
        "print(f'Correlation between rating and PL%: {all_sims[\"Rating\"].corr(all_sims[\"PL%\"])}')"
      ],
      "metadata": {
        "id": "EXYKzLhf76MC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2ca27c2-d182-452e-e944-cc5231e770e3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation between rating and PL%: 0.02110505703960252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# t-test\n",
        "# 1) get the baseline ETF return over the same time period from sim_start to end (June 9, 2025)\n",
        "qqq = yf.download('QQQ', start=sim_start, end=datetime.date(2025,6,10))\n",
        "etf_performance = round(float(((qqq['Close'].iloc[-1] - qqq['Close'].iloc[0]) / qqq['Close'].iloc[0]).values[0]), 5)\n",
        "# 2) run the t-test\n",
        "t_stat, p_val = stats.ttest_1samp(PLs, popmean=etf_performance, alternative='greater')\n",
        "print(\"t-statistic:\", t_stat)\n",
        "print(\"p-value:\", p_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMNrx3N4oefk",
        "outputId": "8c723348-ccaa-480c-885f-1982cefadb42"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-25-1498433146.py:3: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  qqq = yf.download('QQQ', start=sim_start, end=datetime.date(2025,6,10))\n",
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t-statistic: 0.6721774489145267\n",
            "p-value: 0.25917632867225254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "WLxKZ8mPBEM2",
        "LvO6cbmhvc8O",
        "tqxS6qGWOJHu",
        "93KHhZu8pNup"
      ],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
